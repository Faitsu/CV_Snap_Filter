{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_Final_Submission.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfjvqn9c4Wnr",
        "outputId": "8ff2251d-5a85-4b7b-e22f-53773a39be52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CV_Snap_Filter'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 66 (delta 6), reused 9 (delta 1), pack-reused 48\u001b[K\n",
            "Unpacking objects: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ssingh1997/CV_Snap_Filter.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "moPADCQ--Xn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import random\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model, load_model   # tensorflow.keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "IwizIErs5z3a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Imports"
      ],
      "metadata": {
        "id": "_YhrdKYN-bAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_zip = './CV_Snap_Filter/facial-keypoints-detection.zip'\n",
        "with zipfile.ZipFile(data_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ],
      "metadata": {
        "id": "wlyu-uFH580Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_zip = './training.zip'\n",
        "test_zip = './test.zip'\n",
        "\n",
        "with zipfile.ZipFile(training_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "with zipfile.ZipFile(test_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "train_data = pd.read_csv('training.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "lookup_id = pd.read_csv('IdLookupTable.csv')\n",
        "\n",
        "train_data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "hXVhlL7h6CXH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_images(data):\n",
        "  images = []\n",
        "  for i in range(0,data.shape[0]):\n",
        "      if i in data.index:\n",
        "        img = data['Image'][i].split(' ')\n",
        "        # print(len(img))\n",
        "        for i in range(len(img)):\n",
        "          if img[i] == '':\n",
        "            if i != 0 or i != len(img) - 1:\n",
        "              # print(i)\n",
        "              img[i] = (int(img[i-1]) + int(img[i+1])) / 2\n",
        "            elif i == 0:\n",
        "              img[i] = img[i+1]\n",
        "            else:\n",
        "              img[i] = img[i-1]\n",
        "        # print(img)\n",
        "        images.append(img)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "  return np.array(images, dtype='float')"
      ],
      "metadata": {
        "id": "lFwVY0qK6C4t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_labels(data):\n",
        "\n",
        "  labels_train = data.drop('Image',axis = 1)\n",
        "\n",
        "  labels = []\n",
        "  for i in range(0,len(labels_train)):\n",
        "      if i in data.index:\n",
        "          y = labels_train.iloc[i,:]\n",
        "          labels.append(y)\n",
        "\n",
        "  return np.array(labels, dtype = 'float')"
      ],
      "metadata": {
        "id": "HPbEg6Q38WrT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = create_images(train_data)\n",
        "X_train = X_train.reshape(-1, 96, 96, 1)\n",
        "\n",
        "y_train = create_labels(train_data)\n",
        "\n",
        "X_test = create_images(test_data)\n",
        "X_test = X_test.reshape(-1, 96, 96, 1)\n",
        "\n",
        "y_test = create_labels(test_data)\n"
      ],
      "metadata": {
        "id": "668xI1et67Nd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc-BzGKhBxKa",
        "outputId": "7f914807-343e-4942-9ef4-9d6e06ad225e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1783, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_landmarks(data):\n",
        "  landmarks_dict = {}\n",
        "  k=0\n",
        "  for i in tqdm(range(data.shape[0])):\n",
        "    if i in data.index:\n",
        "      landmarks_dict[k] = {\n",
        "          'left eye center': (data['left_eye_center_x'][i], data['left_eye_center_y'][i]),\n",
        "          'right eye center': (data['right_eye_center_x'][i], data['right_eye_center_y'][i]),\n",
        "\n",
        "          'left eye inner corner': (data['left_eye_inner_corner_x'][i], data['left_eye_inner_corner_y'][i]),\n",
        "          'left eye outer corner': (train_data['left_eye_outer_corner_x'][i], train_data['left_eye_outer_corner_y'][i]),\n",
        "\n",
        "          'right eye inner corner': (data['right_eye_inner_corner_x'][i], data['right_eye_inner_corner_y'][i]),\n",
        "          'right eye outer corner': (data['right_eye_outer_corner_x'][i], data['right_eye_outer_corner_y'][i]),\n",
        "\n",
        "          'left eyebrow inner end': (data['left_eyebrow_inner_end_x'][i], data['left_eyebrow_inner_end_y'][i]),\n",
        "          'left eyebrow outer end': (data['left_eyebrow_outer_end_x'][i], data['left_eyebrow_outer_end_y'][i]),\n",
        "\n",
        "          'right eyebrow inner end': (data['right_eyebrow_inner_end_x'][i], data['right_eyebrow_inner_end_y'][i]),\n",
        "          'right eyebrow outer end': (data['right_eyebrow_outer_end_x'][i], data['right_eyebrow_outer_end_y'][i]),\n",
        "\n",
        "          'nose tip': (data['nose_tip_x'][i], data['nose_tip_y'][i]),\n",
        "\n",
        "          'mouth left corner': (data['mouth_left_corner_x'][i], data['mouth_left_corner_y'][i]),\n",
        "          'mouth right corner': (data['mouth_right_corner_x'][i], data['mouth_right_corner_y'][i]),\n",
        "\n",
        "          'mouth center top lip': (data['mouth_center_top_lip_x'][i], data['mouth_center_top_lip_y'][i]),\n",
        "          'mouth center bottom lip': (data['mouth_center_bottom_lip_x'][i], data['mouth_center_bottom_lip_y'][i]),\n",
        "      }\n",
        "\n",
        "      k+=1\n",
        "      \n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  return landmarks_dict"
      ],
      "metadata": {
        "id": "IKIiiJYH7dFf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "landmarks_dict = get_landmarks(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlWGFe8t8MDo",
        "outputId": "a40e13e1-08a1-48ad-e42e-0b66d75de9bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2140/2140 [00:00<00:00, 5953.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentations"
      ],
      "metadata": {
        "id": "3ZmjF1_E-g9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rotation Helper for manual landmarking on face\n",
        "def rotation_helper(angle):\n",
        "    if(angle>=0 and angle <=90):\n",
        "        x=angle*(96/90)\n",
        "        if(angle>=0 and angle<=45):\n",
        "            y=-1*angle*(24/45)\n",
        "        else:\n",
        "            y=(angle-45)*(24/45)-24\n",
        "    elif(angle>=91 and angle<=180):\n",
        "        y=(angle-90)*(96/90)\n",
        "        if(angle>=91 and angle<=135):\n",
        "            x=(angle-90)*(24/45)+96\n",
        "        else:\n",
        "            x=-1*(angle-135)*(24/45)+120\n",
        "    elif(angle>=181 and angle<=270):\n",
        "        x=-1*(angle-180)*(96/90)+96\n",
        "        if(angle>=181 and angle<=225):\n",
        "            y=(angle-180)*(24/45)+96\n",
        "        else:\n",
        "            y=-1*(angle-225)*(24/45)+120\n",
        "    else:\n",
        "        y=-1*(angle-270)*(96/90)+96\n",
        "        if(angle>=271 and angle<=315):\n",
        "            x=-1*(angle-270)*(24/45)\n",
        "        else:\n",
        "            x=(angle-315)*(24/45)-24\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "UHecVYnK8OsN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Rotation and Scaling Transforms for augmenting images\n",
        "## Transformed Landmarks on the images Manually"
      ],
      "metadata": {
        "id": "96srppVJ-qSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def affine_transform(image,landmark):\n",
        "    rotation=random.randint(0,360)\n",
        "    translation_x=random.randint(1,5)\n",
        "    translation_y=random.randint(1,5)\n",
        "    scaling = 1\n",
        "#     print(rotation)\n",
        "#     print(translation_x)\n",
        "#     print(translation_y)\n",
        "#     print(scaling)\n",
        "    \n",
        "    new_img=T.functional.affine(image,angle=rotation,scale=scaling,shear=0,translate=[translation_x,translation_y])\n",
        "    delta_x,delta_y=rotation_helper(rotation)\n",
        "#     print(delta_x)\n",
        "#     print(delta_y)\n",
        "    new_landmark={}\n",
        "    rotation=rotation*(math.pi/180)\n",
        "    k=list(landmark.keys())\n",
        "    j=0\n",
        "    for i in list(landmark.values()):\n",
        "        new_x=i[0]*math.cos(rotation)-i[1]*math.sin(rotation)+translation_x+delta_x\n",
        "        new_y=i[0]*math.sin(rotation)+i[1]*math.cos(rotation)+translation_y+delta_y\n",
        "        v=(new_x,new_y)\n",
        "        key_dict=k[j]\n",
        "        new_landmark[key_dict]=v\n",
        "        j+=1\n",
        "    return new_img,new_landmark"
      ],
      "metadata": {
        "id": "R7mM9ypp-kOd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation using Affine Transforms\n",
        "def data_augmentation_transform_affine(images,landmarks):\n",
        "    new_images=[]\n",
        "    k=len(landmarks_dict)\n",
        "    for i in range(images.shape[0]):\n",
        "        for j in range(2):\n",
        "            orig_img=Image.fromarray(images[i].reshape(96,96))\n",
        "            new_img,new_landmark=affine_transform(orig_img,landmarks[i])\n",
        "            new_images.append(np.array(new_img).reshape(96,96,1))\n",
        "            landmarks[k]=new_landmark\n",
        "            k+=1\n",
        "    return new_images,landmarks"
      ],
      "metadata": {
        "id": "JDR8L2vd-vVZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_images1,new_landmarks1=data_augmentation_transform_affine(X_train,landmarks_dict)"
      ],
      "metadata": {
        "id": "z5j7yJ_H-w4B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Brightness and Sharpness Adjustment for augmenting Images"
      ],
      "metadata": {
        "id": "3WJg8bbb_AlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation using Intensity Transforms\n",
        "def data_augmentation_transform_brightness(images,landmarks):\n",
        "    new_images=[]\n",
        "    k=len(landmarks_dict)\n",
        "    for i in range(images.shape[0]):\n",
        "        orig_img=Image.fromarray(images[i].reshape(96,96))\n",
        "        orig_img=orig_img.convert('RGB')\n",
        "        #new_img1=T.functional.autocontrast(orig_img)\n",
        "        jitter = T.ColorJitter(brightness=0.8)\n",
        "        new_img1=jitter(orig_img)\n",
        "        new_img2=T.functional.adjust_sharpness(orig_img,2)\n",
        "        new_img1=new_img1.convert('L')\n",
        "        new_img2=new_img2.convert('L')\n",
        "        new_images.append(np.array(new_img1).reshape(96,96,1))\n",
        "        landmarks[k]=landmarks[i]\n",
        "        k+=1\n",
        "        new_images.append(np.array(new_img2).reshape(96,96,1))\n",
        "        landmarks[k]=landmarks[i]\n",
        "        k+=1\n",
        "    return new_images,landmarks\n"
      ],
      "metadata": {
        "id": "Ctsi6XGB_F2m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_images2,new_landmarks2=data_augmentation_transform_brightness(X_train,landmarks_dict)"
      ],
      "metadata": {
        "id": "Knit5pze_KM1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Data 5x After Augmentation"
      ],
      "metadata": {
        "id": "l2mb9pbI_dRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_images1=np.array(new_images1)\n",
        "X_train=np.concatenate((X_train,new_images1))\n",
        "new_images2=np.array(new_images2)\n",
        "X_train=np.concatenate((X_train,new_images2))\n",
        "\n",
        "y_train = []\n",
        "for face in landmarks_dict:\n",
        "  features_lst = []\n",
        "  features_lst.extend(landmarks_dict[face]['left eye center'])\n",
        "  features_lst.extend(landmarks_dict[face]['right eye center'])\n",
        "  features_lst.extend(landmarks_dict[face]['left eye inner corner'])\n",
        "  features_lst.extend(landmarks_dict[face]['left eye outer corner'])\n",
        "  features_lst.extend(landmarks_dict[face]['right eye inner corner'])\n",
        "  features_lst.extend(landmarks_dict[face]['right eye outer corner'])\n",
        "  features_lst.extend(landmarks_dict[face]['left eyebrow inner end'])\n",
        "  features_lst.extend(landmarks_dict[face]['left eyebrow outer end'])\n",
        "  features_lst.extend(landmarks_dict[face]['right eyebrow inner end'])\n",
        "  features_lst.extend(landmarks_dict[face]['right eyebrow outer end'])\n",
        "  features_lst.extend(landmarks_dict[face]['nose tip'])\n",
        "  features_lst.extend(landmarks_dict[face]['mouth left corner'])\n",
        "  features_lst.extend(landmarks_dict[face]['mouth right corner'])\n",
        "  features_lst.extend(landmarks_dict[face]['mouth center top lip'])\n",
        "  features_lst.extend(landmarks_dict[face]['mouth center bottom lip'])\n",
        "  y_train.append(features_lst)\n",
        "\n",
        "y_train = np.array(y_train)\n"
      ],
      "metadata": {
        "id": "xCg3gOzt_fuq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uGisckUAJ_K",
        "outputId": "cc548cce-0fe0-4b40-f36b-f0c3756c14af"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10130, 96, 96, 1), (10130, 30), (1783, 96, 96, 1), (1783, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Original Image in the intial training data\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.imshow(X_train[36].reshape(96,96),cmap='gray')\n",
        "\n",
        "xs = y_train[36][0::2]\n",
        "ys = y_train[36][1::2]\n",
        "plt.scatter(xs, ys, marker='x', color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "MvrsD30zBROJ",
        "outputId": "b22450d3-0120-4fb3-e496-8860653a7685"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAGdCAYAAAAi6BWhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29eZRe1Xnm+2xRCKTSLKEBjSU0gCRmIQsLgxlCY0yMCB6g3X1xgpeTLNOxuzvXcZLlm3XTK32TtXw7+HZz7dBgG/clHgIYCMY2BmNsMwgkMQmVjITmQkJjaUIMQvv+UV8VZz+qOs+3VcWpkur5/YPeOuc7Z+999jmb8z7nfd8QY4QxxhhTFQN6uwHGGGP6F154jDHGVIoXHmOMMZXihccYY0yleOExxhhTKV54jDHGVEq3Fp4QwlUhhN+FENaEEL7aU40yxhhz/BKONo4nhHACgFcB/B6AzQCeA3BjjHFlV79pbGyMI0eO7LD53CeccEJin3zyyYn9zjvvJPbevXtLt7/77ruJ/d577yW26vuAAQNKbYaPd9JJJ3X8u7GxMdnGfQ0hlB7r8OHDWedW8Plyt/f0/t1tT+75+xJ87brbFzUX1Fzr7vFzye0/79/Tc59paGhIbH4u8XPl0KFDHf8+cOBAsm3fvn1Zx+ZnzsCBAxOb+8L7Dxo0KLH5ucPPFfWMy6GlpQW7d+/udLAbOvtjnSwAsCbGuBYAQgg/AHAtgC4XnpEjR+KWW27psIsXCABGjBiR2LNmzUrsjRs3Jvajjz6a2Js2bUrsrVu3Jvbu3bsTmxcmnsCDBw9ObL6IfNH5Ik6fPr3j3/Pnz0+2jRo1qvRY3La33noLZfCiy/DxeQLyhOMbQk1wttXDTd1g/Htujzq/usFyH1Z8PH7YlD3M1IOVj5U7loz6nxQ+vtqf4ftWnZ/Px/1V+6uFhu8V1R++ljy3mDFjxiT2zJkzE5sXkx07dnT8e8mSJcm2J554IrFHjx6d2PzM4/9hnTx5cmJz24cOHZrYc+fOTexhw4YlNj9X1H2Zc99cf/31XW7rzvI2EUDxSb+59reEEMIXQghLQwhLefU3xhjT//jAPy6IMd4eY5wfY5zPq7cxxpj+R3dcbS0Aiu99k2p/65IYY/IarNwl/Br45ptvJja/NvLveX92R/H+J5544hHtLaJcIvwKX3SnsW+WUe4YfqVmd0d3dQHlWlOv2MoVxvDxi3oYcOR45epxarty3+T6usvcRcq1plxDPC9zNRB1LXneKnh/dV8pN69CabPqPubfM/x7pQ3v37+/9HhTp07t+PeQIUOSbStXpkrEtm3bEnvSpEmJPXv27MTmZx73lfvC14bHju9b9RxQbtZ66c4bz3MAZoYQmkIIAwHcAODBHmmVMcaY45ajfuOJMR4KIdwC4OcATgDw7RjjKz3WMmOMMccl3XG1Icb4MICHe6gtxhhj+gHdWnhyCSEkPsOy798B4ODBg4nNn0ezf3T79u2Jzb5Y9Umw0hGUBsT+16LNn2bzsdQnoTw2fG4+Hv9exc0o3YCPz7by2/N2tpWOoXzPjNIBlMbTXV2kOLdzP0Vn1LnUXChrWz3HU/cFf4LLc09pWrk6Qm4MXK6mxMdjnYRtvreL/T3llFOSbdOmTUtsfobt2rUrsffs2ZPY/Gn32LFjE5s/7eZnKOvmKkyAtVc1d+rFKXOMMcZUihceY4wxleKFxxhjTKVUqvEo2NfNmQ7Y3rx5c2Kzv5T9l+w7VmlPlKbDNqfUKfp+2Q+uci6x5pOjKXR2PKWZqBQ6StNRMU1K01GoOCgV19RdzUvl51LtyUHFwTBKg1GxG+r33Fd17VhHUHomayZqrvD+aqyVfqj0QJXSh9PUFHUafmaxxvP88893+VsgTb8DHJlSR+WzZJ2bg/h5LnBfVQqdnNRRyXHq2ssYY4zpIbzwGGOMqRQvPMYYYyqlUo0nxpj4Y1V+L/Y3su94586dic3+VP4GXfl2VU4p9iVz+/l7fj5/Ee6b0lxy0/rnajpK31JlE1ScTG6cD/uW1fnUtVLxCipnFaPiporHV/O6bJ50tn9u3rrceZ6rh+X2h1H9y61Jo8ZHzQV1vVRuuiL8zOK4Ho7D4VhF/n1ra2tic1kFHnvWiDh/JY8l943vA1Xfp0iZ3uM3HmOMMZXihccYY0yleOExxhhTKZXnaivznatYkVWrViX2li1bElvpAMpXnfu9vyqhW9xfxULk5pHLzd2mYi+4L6qvuZqO0pjY18z7qzgelf+M/fTqfNyf3Nr0Zb5vPreKQVL6ldK7mFzNh+euKrOu9DFur4qRyq2VlBuXpGJTVKlt1paLv+f7buTIkaX266+/ntisY7PN9Xr4fNw2Veo6R7tUlF0Hv/EYY4ypFC88xhhjKsULjzHGmEqpPI6n6B9VugXXH587d25iNzc3Jzb7XnP9lbn50ZROU/Ydu4qdUPsrlB9f5aFTGsgHncuN91f5uFR7VJ49pemo7WXXR52Lx1bFiyk9iud17lirvvPvc+JaOvt9bo0XNZcZdS+o2ldqvMs0Nx4bvq/GjRuX2OvWrUtsfiZxvR22hw8fntjc17fffjuxOe5nyJAhiZ1bO0o9xzqOU9dexhhjTA/hhccYY0yleOExxhhTKb2aq41h/yPvy/5Rri3B/lC2+fjs/+TjKd+3qj1Rr78T0H7o3JosufV2lN9bxbEoP73qn6r13t2xV3FKufVzlF5YtFVcS9lvgfx4s9x6PiomTF1bpbHwfdjd9uXWpmL4enD7eHvu+BZ/z3EyvC9rMvyMYw1n7969ic3Xas+ePYnNGhM/4zj3msrJyBxt3Sm/8RhjjKkULzzGGGMqxQuPMcaYSunVXG0HDx5MtrOvleuFq1oRqpa7qlGjdASVn4zPV+wfb1N1LXI1FCbXD56rAan2qPxfKu5HxT8wufm5GBVbojSwsuOr+LJcPY6pt8790R6ftytNhMdC5abLjWvKrbfDc0nlTVRzVcWkFfVJrn/D12rUqFGJzbnbWlpaElvVJOP6PFOmTElsrv+j9KzcWkf1zkW/8RhjjKkULzzGGGMqxQuPMcaYSqlc4yn6S1WczoQJExKb/ZvKN8z+xu7qBLmxH0XfMutZgwcPTuzc2j8qNkLF3Si/PveNbRVno87Hx2O/O8c/qNx2PH7dHR9GxdqUaWZ8Lp7Hyi+ucq0p7ZJRY6N+z+djDSU3Jk1pSLm1oBRqLinNh68fa9FF3Ybvcz7XsGHDElvNQ4bHcvr06aXH5+eQmjvqvs3NOdlx3Lr2MsYYY3oILzzGGGMqxQuPMcaYSqk8V1vRH6viF1asWJHYmzZtKt2f/ZesQ3CuNia3vo6q51P0h3Y3N5jSFJSmkhuroTQn9uUqfY1RGo3SRVQcDbeHdQgmt8YNby/zhat9FbkxSDwPeWx57qnaRYyqL8TXSh1faU7cv9x7h8/P51Pw+VXcUnF/jtfjecu52pTGwvV7hg4dWvp7fgaqea40GqWV1ovfeIwxxlSKFx5jjDGV4oXHGGNMpVQex1P0EbLvleNsdu3aldjd9Ueqmiwqv5nSNdjXW/R1q9xovF3lp+KxU7EHKuZJ+e1V7ERZ3Xkg3xesaicp2I+v+qM0M6VBlcXC5ObZU2Ol5o7qi8pxmKuBMNx+Pp7S93Lv89z8YiouSOXSY92Ga9wUx5/7zjq0ymunYqoYpUMrvS93npdpm2X3rN94jDHGVIoXHmOMMZXihccYY0ylVKrxMOwD5NoVra2tiZ2bq41RsRkqZ5Q6HvtDc3QNpbEov36u3qU0D+U3V356Ro21iu1Q+b1y6wOpuJ/c45XlJ1PXRsVu8Lly426Ufqj6ouJmcmKaAB3zpepudVePZNT4su6itN6cczOsF/Hv9+3bV7o/52ZTz6jcXGu58Wxd4TceY4wxleKFxxhjTKV44THGGFMpledqK/p72TfKsRtvvPFGYqs6Jsr/2Fl7ysit2ZKTQ6qnYzu6mw9MnY/93Kq2Ua4mlavZ5PqulW6iNB9GxVmVxYSpvrHGwLAGovrCKE0nd+wZVd9G/Z73VzkWVfydij1RmhPrjTz3y+aiGmvWtVV9HB5bjgviZyTXA1J59NR9q2ot1YvfeIwxxlSKFx5jjDGV4oXHGGNMpVSu8RT9pVwrgmuXK/8n+9lVrXaVk0r5U1V8QFkcT3frxKu2dDdORdVoYfj3vL+K81G53JRGpXzRKgZLxS+o3+fEOSlNQelb3c1VxsdnjUjNzdx6QEojUWOvYr7U/qo9am6p/ubMNd6XNRm+Fjz2Y8aMSWyeO/zMZJvzyqlnqNKpc2Mlu8JvPMYYYyrFC48xxphK8cJjjDGmUirVeAYMGICTTz65w1b5v9hm/yV/k86+Vv7+X+kSqlZG7jfrRX+n0lSU31n5zXNzu+XWIGFU7IT63p9t1V5GjVduHJPydRfnLXDkeJXN5dw8dbm50rhtjLqvuhurwTqF0uu4P2ou8flVDFlu3kOG7y3Wonm8+DlT3J/HgnOtqdhEvrYqnyW3jffn+1rN49w8d/XiNx5jjDGV4oXHGGNMpVReFqH4aqY+6+RXYuVaY1T6d97O7eluKWz+lLFId9P5MCr1vPpkV/WVt6uUNMqdpF7Ruf3qE9xc11pu/5WrUO1fJLdMgPq8me8LdTz16XtuSpzcT/1zbdV/NTcZdd/y9WEXfI7bW30Kr55RfK327t2b2Hv27ElsHnt2E+aWBWdUCIk/pzbGGNMn8cJjjDGmUrzwGGOMqZReLYvA/ktO4a18qZ0dPwf1SXLuJ8dluodKg6JS3qjPfZVfP1cD4vapT3q577mfUzNKJ2DftUp5o8onq0/7c69fcTxy57Hy8+emyGFyS2iokvC5oQA8V3huqZIcuWEOuZqP0kHUc6OoCfGxVMqc4cOHJzZ/Ts2aDn9OrTQdRs17prshJu34jccYY0yleOExxhhTKV54jDHGVEqlGk8IIfG3sm+UfbnK38nxC0xuenP2V7LmpHzTZalAcjUVpVcpv7qKrVCaCI8Njz3/XsVAKU2GUTqHgs+nyqyr0tlKZyjTjJT+xagSFqr0skrRo2KictMtcXtUuRKlP6przdeWyZ1bjCqrwO0rK4OutEXWbPjcw4YNK/09p8RR11KVbM8dG3UfdIXfeIwxxlSKFx5jjDGV4oXHGGNMpVQex1P0AbI/kHObnXHGGYm9YsWKxGb/qNJ0lC+cfbesa6hv3tn/WfTvKj+/shnlB2cNQ/WFfb/st1exDaq8M6Nyu+XGB6hYjdz2KV+2Ol8Z6twqPky1Jfc+6G6ePp5rSlfga6HKM+fmAcy9Nrmam4ppK46/0kJ57Fi3njBhQmLzfa/0trK2ATrGijna3GyM33iMMcZUihceY4wxlSIXnhDC5BDC4yGElSGEV0IIX6r9fVQI4RchhNW1/4784JtrjDHmWKcejecQgP8cY1weQhgKYFkI4RcAPgfgsRjj34cQvgrgqwD+Qh2s6GNU38ePHJmuZfPmzUvsrVu3JjbnLeL4AZUTKrcuCsP+27K+qrYpHSC3bbn5uRR8rZQOoHQH9k3z8VXuNUbFkijNS+koOfEPuddGlYZWsSE8lupaqLx8fD4Vk6bqbOXmRsstk54bx9Pde6EsryKPFWs4SpPhUtlcj+eUU05J7Nyy6mreH62Go5AjHmPcEmNcXvv3PgDNACYCuBbAXbXd7gKw+ANpoTHGmOOKrKU+hDANwLkAlgAYF2PcUtu0FcC4Hm2ZMcaY45K6F54QwhAA9wL4cowxed+Lbe9jnb6ThRC+EEJYGkJYeuDAgW411hhjzLFPXXE8IYQT0bbo3B1jvK/25zdCCBNijFtCCBMAbOvstzHG2wHcDgATJ06MRZ+iygHV2NiY2DNnzkzs5557LrFZ41G+W/avqtgVRsUnFHWE3HowvD/np1L1eljD4PPt378/sVVeOkbVTMnN+aRquTMc/8DnV+OtfOH8e5WrjTWkYv9ya/nwvFexE7l6Gs8lnju5MVsqvo23c34xpVExqn+5cT4qtkXdm2V6Io8F953h+5b3V2PPGtLQoUMTW91X6j5Uc0Edv+N3aofQ1rM7ATTHGP9bYdODAG6q/fsmAA/UdUZjjDH9mnreeBYB+PcAXg4hvFD7218B+HsAPwoh3AxgA4BPfzBNNMYYczwhF54Y428BdOU3ubxnm2OMMeZ4p/JcbUXfvPKVKr/7uHHph3S5udsY9k+qOiiqpktxf5XfKldTYJt/zxqOqvvBteA5f5aKe1FxPbxd9Vf5+Xmsuf18PhUXlBvnpHSAIqr+DaPiy9Tv1flUfRylP+ZqQPxRkcqRyORqZOq5oX6v5i7HKTHF7aydsmbDcTms7/H+XKOM71P1zOuufpcbM9UVTpljjDGmUrzwGGOMqRQvPMYYYyqlUo2HYf+g0gHYNz127NjEHj16dGJv25aGFm3cuDGxN23alNiqNoby+3N7i7oI9031Xfm9WQ/bsWNHYrPvmHM+sR97yJAhia180yqOh9vPvmuOL2BfNf+eY09yNTCla/D52PfNfn01V8vqTqnca0prZHJzkym/PcPt57FUcTNK/1NarxoPPr/KN6auPdu5OkeZtsvziLVYpb2yVjt16tTStufW+VLbc3PBdXmcuvYyxhhjeggvPMYYYyrFC48xxphKqVzjKfoIc/NljRo1KrFHjBiR2PyN++TJkxOb435YE2LNR+kC7OtlXaTo61V12lVNFtZodu3aldgqASv7jlkzYd/z9u3bE1tpPHwtlR+fNSVuD/uqeWz593ztVU0ajkvi9vP51fHYF192Lp5HKuef0nBUTBcfj+d1bq4ybg9ro6xbsM1zibXUXL1TaUB8rXiusF2m1QJH3itlMWGqbTxv+Nx8X/O5+Rk4bNiwxO5ujBa3X8VAqRyN7fiNxxhjTKV44THGGFMpXniMMcZUSuW52oo+ShW/wDbXF582bVpir1+/PrHZH8qaDvt2x4wZk9gbNmxIbK73w/5Z1gGKvmHlO2U/Mbed43JUvituK/vZ2a/OfWENSfm1p0yZUrr9d7/7Xenxxo8fn9hce4n7w7oIa0Ds6+ZrzRoRxxGxLsA6CR+/TK9U8WCq5gn3VcWRqFiOsvoxnW3Pbc+WLVsSe+vWraX7qzgfvlaqBg3bPDf4OTBp0qTEZm2YY9B4vMpq7HBflL6mcrmx5sP3DfeV7+vuxuHkxox1hd94jDHGVIoXnmMF/j+ROiOEjTGmr+GF5xjg0ieewPW//e37i02M+Mwzz+D3ly3r3YYZY8xRUKnGE0JIdB0V28L+SPZfsn+U/aGqfjgf79RTT01s9k2r7/vLdBLel+G+dvipY0TD/v24+KWXcPDgQdx1zjm46YUXcMXq1bhn4kSsWb0aCCE7roZ9xSNHjkzs2bNnJzb3fe3atYnNOaQY9pvztec4HhXfwDFZfDyOQ2ppaUls9tsrDYh1CD5+WQ0X1v7UtVGwHsXzWKHyf7FGwnE6rP9x/JuaC9xeHnseD1UXSz1HeDs/J7g/rJvw3OP28r1UFr/H2ibPBd7OY6nuA0bF3TBqu8pXWW+utl5NEmrqIATcf8kl2L9/P65evRpXr14NALhn4kTcNmMGUKeYZ4wxfQW72o4FQsBd55yT/MmLjjHmWMULz7FAjLjphReSP31xzRp/YGCMOSapPI6n6PNkf6Kq963yFvH3+fzNPPuulebDcUKqTgjrJGWxHKwZ7Ny5M7HXrVvXfhD86erVuHrTJvxowgR8Y9o0fGn9eny6pQUDBgzAN2fNAkI4QrPgHE5c/4bbw35tjstRNVn4WrCfns+vap7w8fl48+bNS+ympqbE5tpLzc3Nif3SSy8l9vLly0vby+fj2A/WHYq++Nz6M6zBsK3GnseW49OUVsn7c1/feOONxP7nf/7nxFZxNAzHrqj4OD4ez33uD/eXj8fjyfei0nxYnyxeb762PBd4O2s6nKOR5+HEiRMTO1fTYXo6rqcrrPH0dULAgYaGjkUHIeAb06ahoaEB+xsa7G4zxhxzeOE5Bvje9Ok4+Oab7y8yIXS86RiTTYzp3GHbmA8YazzHCvxg8IMiHwfh4uJf/hJX/OQnSUzYFQ8/jI889ljvNsz0Kyp/4yn6HNlXyvB29gWzrfIicWwG+3oZjuvZvHlzYrOv+bTTTkvsok7Afm/WIDgvHNceYr+7yv3GsQqsn7FfnH3NHMPEfed8XEqzKctnBej6ODx+S5cuTewOTawG++X/ZOtWDHzzTSy54QYgBNx4ww2YcdttODRkCNZ/7nNH6CS33nprYr9AH3dwe1kPLG7nseW4GL523BaOk3n66acTm/W8888/P7E77oMY8d7Onbjg5Zexe/dufH/BAtz47LNY0NyMn86ahRUvvwyEcMR9o3KpcYzWmWeemdisFzJ87ThGiuN4WHfguf76668nNsc9sX7Hv+c8fKy7sJZcpk3zM4LvK27L2Wefndh33313YrOOPGHChNK2qPo7CqXhqPN1hV1t5vgnRgx8803MffRRAMCS2qIz6d57sfn66/vPm08IuGfRIhw6dAhXNjfjytoHFz+dNQv/67zz/BZtKsMLjzn+CaHtTQfA3Ecf7ViANl9/PdZ88Yv964EbAr6/YEHHogPAi46pHGs8pn9QWHza6XeLDgDEiBuffTb5079fvrz/vPV1B2uEPUav5mpjfyD7jtkfyb5x9v2qOiGsGbHN7WH/par9XqbL/PrXv062rVq1KrHnzp2b2Kwh8Pf8PBbsl+fYAob3V/EDr732WmJzrIPyBXN/eCzZz87Xhv30fG1YF+D27dyxA4ufeCL525Rbb8XKz38eCOEIXeLqq69O7Ntuuy2xOfcb14oqouYpXyuunbRixYrEvuyyyxL761//emKzBnHPPfe0/SNGnP3d72JmczN+c/75+NdLL8XvP/44PrZsGU4cOBA/WrgQCOGIOBrVfqXVqmvLuc9YF+H9ee7wXGU9kOP/eH/WKzlOCQAuefxxnPTWW3jkqqtwyUc/CsSI02oa4c5rrjli/67OzXrWpz71qcRmfaksByBwpHbKeprSVhV8n/G152d0ca6U6T12tZnjnxix+IkncMkLL+CJc87B/Zdcgv+wbh2mP/ggALQtPv2BEPBuY2PHooMQ8K+XXoq3334bBwcO7H9vf/USI0566y0sfOYZAMDbl1yC0/7H/0g1Qo9dFl54zPFPCDh40kkdiw5C6FhsDjU29quHxspPfxrPLlmSxIS1v+mYLggBj1x1FQC0LT6XXgqgTSN87ZZbgB07erN1xyReeEy/4OcXXpj+n2n74tMfH7iOCcuntvi0v/UAaFt0PHZHRa/malOaiYpVYR+iqtPBvmr2n7Juwsfj2hcrV65MbK5RU/Q1r1mzJtl2xhlnJDb7dlmjyP0en/cvqxUEHKmRsObDugP7rlkzYt8wx1CxX5/jipjdu3cntoq94ONz+5966qnE5lxufD4+nsqvVpxLPI9UzBPHofC8vO666xKbx/YXv/hFYnMeutbW1sRmTaSsL52hasrwWHL/+b7i2BbWB7m9qr4Rjw9rsSpv4sMPPwzEiC9T7N2wv/kbPLF4MW648cbk708++WTHv1fXypi0w1rgggULEvuBBx5I7LFjxyb2jBkzEvvFF19MbO4764d8nzL8jOSxZZufycXzlz2j/MZjjDFl1BadG7ZuxQ/Gj8fWr3wFl9x/P85t/2CoFpRs6scLjzHGlBEC9p9wAn4wfjxunTIFN4SAJxYvBgC8PWiQF52jwAuPMcYI7pg06QiN8InFi4EQMK1XW3Zs0qtxPOyPVHl/VM4mlSeIfcXsg1S53vgbefa//uY3v0nsou94+vTppcfiXG2soagaLjw2rIHsoC9v+Pt+HnvOAbV+/frE5liLs846q7Q9nJuOz8f5vrj/3B++dirOiXUBVYNF1bjh7Xy+RYsWoSv4WnDcCPeVa66wPnfnnXcmNmuNvD9rPDx2uTVY+Fry+VRcEM9FzkvIx+drx/cCw+fja6fy7nE9op///OeJPX/+/MQu5lvjGCG+r6ZOnZrYHIPF8WWshT7yyCOJzdfm4osvTmyl8fAzUM0Fvg/rzQXnzAXGGGMqxQuPMcaYSvHCY3oe57QyxpRQ+ccFRZ8h+16Vf5B1DhU/wMfL9VeyL5w1Hc6vxrEgxfaxxlP2/TtwZF/ZN6v83KyRcBwLH59rCXEtItYBWLN5+eWXAQBfbm3FsMOH8V9POaVNiI0Rf71zJ/YAuLVQN4b9+ByfwJpMWYwUcGS8Ao8Hzw3WUThOR+kCrPlwe4q5+PjY6lpy3A/PDVW/hvUq1lC4rSqejucK3yect47nntJq2+dOO1xzhq8tt5fHi+OAePxUHS5Vf+cjH/lIYnOuvGIuvQ996EPJNs67x/clx/fx3OCxVvNa5VCst35OOyqOR52v4zhZZzWmjBgx7PBh/NG+ffjrnTs7Fp0/3LMHww4f9puPMQaAP6c2nOCwOwkPQ8Df1v5v9Y/27MEf1v7P8TvDh+Nvhw93vIMxBoDfePo1f/rGG/jK1q3vv4nEiJtXrMANVLIhi8Li087fjR7tRccY00GfytXGvl+Ga7Ko2AqV6411C/aNcw0a/t5/cS16uR3WcZ5++uku28J+dvY78/f6HAvBGobKp8U6QwAw+oQT8Jnt2zHwxBPx3UmT8MerVuH3N2zA/VOn4q2DB5PFgvt2RL2bdjtG/Fdq6/++ZQu+fuqpyfFYU1J63MgRI5Lf79yxI7H59yMKehJw5HgzPPd4vHlu8fFZByheP56nKp8WzwVuC8eGqJgiHhvOVaZoamoqPR7rbxz3wvbWrVsTe/PmzYnNudX4vuc4KHWt+Hg8/jw3+DnBc51jzm6kXG3FPIA81nwuzuV2VS0Ldjsc38djx3oW58VjvY3nGvdV3YdKw6k3jseutv5KCLi1Frz2ma1b8ZnahL5/6lT80+mnY8LRvKHUFp0/eftt/NOgQfhaYyP+y4ED+OODB3HSjh34uzFjjurN56pnnsGAvXvxzxdc0PHBwudXrsSBhgZ8f/bs/HYaY3oVu9r6M4XFp51/Ov30bmk8e0LAt046CV+r1bn5WmMj/mnQIOwdMODojhsjBr39Nq5sbsa/fe45IIibzksAACAASURBVEb82+eew7Xr1qHx0CF/sGDMMYjfePozMeLL9Cr/x6tWtS0+R8k/DBoExIiGQk6rrzU2Yji5puomBPz44ovxdm3xubL2yfoDTU24Y84ca0fHEj35IYs5pql84SnzAar63uwrZ82F4xXYn8nn5uPzN/Pst2d/Kvtr2bdc9CVzW/lcqkYL+1rLzgXoWJABIeBPV6/G9Vu34t7Jk3Hbaafhi2vW4PoNG/Dee+/he1QKmf3sp9PipOrec2wGt2cVfdDA8QgrJ07sWHQA4BtTpwIl9eS5/+zn52uv5gJrbtx+Hp9i7AtfK57n3FYeK96f40xU7jSet3ytWCPhvHus0XB/xo8fn9ic12/Tpk24ZccODD18GP9XIb7rL7dvx74BA/B/U/tmzpyZ2JyvjON+OK6J5x5fK84zqO413s56IOs4F1xwQce/ly1blmxjzeall15K7I997GOJzTFUqm6X0rt4LvC8V3nxcjWhrrCrrb8SAg40NODeyZPxzZkzgRBw24wZuHfSJOxvaOhb/ycaI/7k1VeTP31xzRq72T4IPoisEzFi6OHDuGn3bvzl9u0di85Nu3djaHfju5wl45jErrZ+zPemT3/f3VH7720zZgAhYKj+eTXEiD9dvRp/sGkT7psyBd+aNQt/8uqruL6WOaG9vab7/Ls1azDk0CE8ddZZHXPiE48/jpPGjcOzV1999AcOoe1NB8BNu3fjptqXV3eNHNn2d/q/8nr5THMzGt99F18bMqSjvX/e0oL9DQ24nTJvmL6F33j6O/zQ7msP8dqbWfuigxDwrVmz+uab2bFMjBhy6BCu27gRn3j88Y5F5yPLl2PgwYPdf5MoLD7tdLjdjrK9je++i2teew1/3tLSseh8dscODH3vPb/59HH6VBxPrq9V1ePh/fl8SkPimjmsE6h8asXz8285RxOj6lwo3y/3TdUeYngs2XfMvmAVG8J+cfZNl+kU/9+MGTj07rtA4Rh3zJ0LhIB2FY/7z/oejxf3j3UBjpVhXYVr5JTlM2MNh20eGxVfNmvWrMTmuB0V08Vj3T5v//v06Th8+DCuX74cH1m+HADw4PTp+P64cUAhNoVjwjimqdO5HiP+muJvvrJlC/525EiMFzVqOBalXW/74cKFaDjxRHx21Sp8tnbs+6dOxf87cSIGFcZf5UVUueDY5rnP91axng/X6Nq0aVNiP/zww4m9cOHCxGadmecKjw1fe75vczUa9Zw4WvzGY44N+vqb2fFAu6u1wJ21Bb5b1Badz+3Zg+8OH45pU6bg20OH4o/27cP/sXv30b+dhIC7zz8/+dPtZ5zhuXEM4IXHGNNGjG0fbRS4+ZVXesTNtnfAAHx3+PCOIOK/HTkS3x469Ojju2rt/Sx9NfaF5ma72Y4B/HGBMaZj0bl+82Y8OH067pw7Fze/8go+sXYtTmxowPfOPbdbbxL/ffToNG6nPadfCBhf/tMu2/vZZctw1apVuH/qVNx+xhn4QnMzFm/YgHfeeQf/T1OT33z6MJUuPCGExGfImoiqz6PictT+7N/kb9wZ9sXz77m9bLPfPwf+rarXw23lseW+8naOM2I/Nvu5+fysKakaLKq2O19LpeGomjIq5op1FI4jmkA6BOsaZbqAiqniseftb7zxRmlbGB5rHlsey/YYpMPbtuHhmTPxP2fNAmLE/zzjDMQYse+999Ba0LhY7+L+sUbDY83tYR2Dj9+pdhoCDg4ciJ+ffjp+smgRJoaAn0yciCHPPAMcPowJha/aWAdhVJwPa1bqXijGPfHYcI5Cjg9jTWjOnDmlbWEtkp9RHNvIY6/q66i5pJ7BXeE3HmMMAOCeefPa3kraBekQcMecOTgkkvf2Fj8++2wgRpxUeIv64cKFySJp+ibWeIwx73OsfcRxrLXXAPDCY4wxpmJ61dWmdAyG/ZEM+x9Zd1D1frg9fD4+PvuOy/ydKrZCfU/PbeGx4r6xn5p1BP6+n/3oPHZKH+PfM0rzUXFGKnaCj8e+bd7OOgLXhGFfPNtMWZyVmrcMazAcN7OGvjzjuTVu3LjEVnqU0pz42qr+8O8595zKi8eoeD/efgoFqiqNhrfzvcN6Its8HsUYPb5PrqYMEKxvsdbIzxjWjFTcjbrWfC0Yda35uVA8XlneNr/xGGOMqRQvPMYYYyrFC48xxphKqTxXW9HXzr5g9Y248jeyH599x+wL59gOdT6le7Avu3h81lS476pWEOtP/HvuO7dd6Wm8Px9P1e1Q/an3+/564eOpuiG8vaWlJbG5vwsWLEhsjutR9ZSKOoC6tkpjmTx5cmJvrZUpb2d3LdtzVzZrFsrvz2PH9yVvZ9Tc4bmoYrDUdj4+6yCskal6SEoD4tpLfLzt27d3/JvnCWs2XLuIz821jlSuNe4Lxwmpa6fuU1VvpziXSmuvlR7FGGOM6WG88BhjjKkULzzGGGMqpfJcbUV/aG5uM/ZFq1xq/A0918Bh3YV9ucqfyZoR1zMv9od9u3wu5WdXcUBKw1GxDwoV46Q0IkblhGL4WvB4cPvYD8/7c3sXLVpUejzWVdj3XjYeKkZJ6WfcF6591NramtisEan7itvH52OUhlMW2wHouCC2ef/cWJWyWkmdoeIJlb5YrKfEzyCeN8wOqlnEzw2lO48dOzaxWd9T+h3T09psO37jMcYYUyleeIwxxlRK3QtPCOGEEMLzIYSHanZTCGFJCGFNCOGHIYSB6hjGGGNMjsbzJQDNANoTSf0DgH+MMf4ghPAtADcD+GbZAWKMiY9R+RdVHiLOmcRxOay58P6s8bCvnGHfN/t22Z9azMPEvlvOn6W+z2ffLvuOVX0aFUvB5OZOU3Xt1fFVvR71e8W6desSm3OvTZkyJbFXrVqV2CpfF7e3ODeUPsbwvOJ5ym3nec9tU/FyKkYs99rztcytY6Xi+cpqH9XTPkb9nuH28e+L14/bzjFZrFPzc0Lln1R56viZ1GltowJqrJjc/dup640nhDAJwMcB3FGzA4DLANxT2+UuAIuPqgXGGGP6FfW62m4F8BUA7cvbaACtMcb25XczgImd/TCE8IUQwtIQwlL+PzdjjDH9D7nwhBCuAbAtxrjsaE4QY7w9xjg/xjhffaZpjDHm+KcejWcRgE+EEK4GcDLaNJ5vABgRQmiovfVMAtBScowOij5LpUPk5MMCjvRFc+wG1zlh/yrnTeKaLacW6rh31j4+X1NTU8e/ly1L12325aqxYF8s++EV7OtVsSPsu2UdgXUBpRkp1PGULsDj8frrryc294d97Vy7XuVP4+3siy+rMaP0Kc4ttm3btsTmeT99+vTE5r5wvi4VP6fiZJiyWkSA1mx4LvL+fJ+q46uYMKXh8PlUXBBT1BNVfBlv53OrWkV8PM4XycdXMVfqWqk6WsXt3arHE2P8yxjjpBjjNAA3APhljPGzAB4H8MnabjcBeEAdyxhjjOlOHM9fAPhPIYQ1aNN87uyZJhljjDmeyfKPxBh/BeBXtX+vBbCgbH9jjDGGqTxXW1l8BvsL2UfINuc7Y/+o+oqOY2k4PkLV9ymrtQ6kmhDrR5s3b07sqVOnlrZVjU1u7SLl11f5sXJRcTqsI6hYEL7WHIPFOgfnsCrm0wKO1HB4bjFqbhavB7dd+dW5LcV4MOBIzYdztzGsPbKGxKi5o/ZXugL3lzUrJnduq7yHKvaE9UyeawzfK6tXr+74N2su6lzqPuD4Pd4/Nzebeo58ULncnDLHGGNMpXjhMcYYUyleeIwxxlRKpRpPjLHu77wB7Ytlf6aKRWFfs8pfllt/nI9X9N/Onj072cZ+erbHjRtXeq7cejeMytGkapxwe/j3fC3492yz71rFcO3duzexORcb63esa7DfnnUVFeek6qIU28t9U352htvOfed4M47tUNvZVpqKitvJ1WR4u9IdGBVXw3NJxYypa8v7s15brN103XXXlR6bdWG+tuo+UrGJKgekqg3FqLpbxeOVXTe/8RhjjKkULzzGGGMqxQuPMcaYSqlU42Fy/Ynsq2V/Jvv1+Rt5pcmo+j+M8pcW/bWsR82YMSOxuf4Law4cD8DnZh1BtZVRGobKJafGTmlCjNJ01qxZk9js6+a8eqxjsG+a54q69ipPX7G/qu+qLXwu7gufm+tQscbDMU98PFXzhTUOpSOo2BQe69zaTIzKc6j0RkaN/5NPPpnYRU2OcwIeOHAgsXfv3p3Yu3btKj2X0uNULjg193JrETH1xvX4jccYY0yleOExxhhTKV54jDHGVEqvxvEoX676np41HtZRFEpnUL5ipXMU2//mm28m27g2Ovv1N27cmNg8VmPGjEnssrrvnbWdx0r5uVU+LuXb5fZzfi7+/WuvvZbY27dvT2zWcDgXG49Hrr6n5iZramVxPypmSs1DbhufW9UOmjRpUmLz3OK5wLnhcvW43FxvjJobKoYttz18fKXpcG0tzgt4zTXXdPyb7xPWKjdt2lTalgkTJiS2qvvU3VpF3Z2bPVaPxxhjjOlJvPAYY4ypFC88xhhjKqVX6/Go7/tVziYVK6Lq6fR0rYmy+AcVs8Tf+3N+rmKND+DI3GTsl2f9S+ULY786+7UZvnZKx+Dz7dixI7G5P8xZZ52V2KxxKd83a2xKv1N1TtiXXuZr52Mxap6rGCTVd45v4/umpaWl9HisnzFKQ1F59/h8HJfEczNXQ1K6Bs8FrsXEGk5zc3Ni/97v/V5iF+cm1wTjsWhsbOzytwBwwQUXJPby5csTm4+v4u1UrSJG5b9k1DO147h17WWMMcb0EF54jDHGVIoXHmOMMZXSq7namNwcSuxnZ9+sqhGjclKp9vDv+XxFf67SRJhRo0Yl9vz58xOb/c4cm8G+VpXziTUhVQue4b5znRGOw+Hjc1zOrFmzStvLmhVrOHx8tvna8fG5v9w/ngs8fsW5po7F14pzrTHcF9ZE1Fzj2BDWrzhvIGskEydOTGyVq401GtV/hvvX03DcE9fXWb9+fWJ/+MMfTmzOu8j52Ipw30877bTE5rHm5wDrdTw23BdGac25GhBjjccYY0yfxAuPMcaYSqk8ZU7R/VTva1k76vNodtfwJ7rs/mHXnHpNZfeOSiletNUns/wKrD5BbWpqSuwpU6YkNn+uvHPnzsRm1xSnZ1dpWLh9ynXF7eNrxddCjQ9/RsqpSHg7uyS4f3w+ZbObl49X9jm1+hyaUemPVBkF5T5h1xm7c1auXJnYnM6Iy7RziQrVPzUe6r5XpaxVShwOVeDnxLnnnpvY7B7j/Yvt5bYoly8/Q9ilzm7Y008/HTnkll1Xv1du1q7wG48xxphK8cJjjDGmUrzwGGOMqZTKP6cu8wGyL1d9dsl+e04zc9555yX2s88+m9hcEji3TALrHmWfU6tPTHPLCijNYurUqYk9e/bs0rby8dSn4ozyq7POwXqZ0jFYk2J73759Wcdju7up85ni59U8trllBhhuK98X/Dkv76/CDvg+WrBgQWJz2fENGzYktirbznOF26f0N547PL6so3Cpb75248ePT+yFCxcmNn9urlLwFOH7KEcXBo78tJuPx6mkeOxZ61T3gSqLoNpf7+fXfuMxxhhTKV54jDHGVIoXHmOMMZXSqylzVGxEbspu9n9yyV/21a5YsSKxOa0L+4LZf8rtZ1970Vet4lJU2e/c9D3s52ffLKd44bFnDYpRZQXYt8wajIpr4u3st+fj5epv3F9GjT9v5/EqHl9pFCqWg1F6mtIDeey4bzzvea7MmzcvsTmmjHUJjhHjuBc1t3k8lMbC9znrnVyChGPOeLxU/F7ZXFbXnlG6No8djy33Vd1XCt5faTpOmWOMMaZP4oXHGGNMpXjhMcYYUym9qvEoX7YqkavyBLEuwDmorrjiisRm/yv77Tdt2pTYzzzzTGKX+Z6Vn1ppFLy/0scY/r36Hl/tz7BfXOULU37yXF80x6bw3OH2qPgJ/r2yc8oxq315HvK5eF5y/i6eS2zztWI9kMsx8/m4fXxfcflmlWuNz8/t5bnN48EajXpO8HaOCVOakyo1Xmwfn1tdG9bT+FqpearicJSt7ruj1XQYv/EYY4ypFC88xhhjKsULjzHGmEqpVOMJIST+UhW/oPyHan+VX0v5/VXpbaYsjkeVTla+YPZz58YB5fil6/m98vUqvz7D5+f+qhosHLvBvnKOK+L2qfFT9XdyS5sXUbESSuPgXGPcd45PY5QGxMdTcS9qbnJ/ODccb1d6o8orqLarGDsVX1iml6oy5bm6Nee9Gz16dOnv1TNRxQPmarHF35c9v/3GY4wxplK88BhjjKkULzzGGGMqpVKNJ8ZYGg+i/J3qe3rlV+f9Vc4r3p9ja9hm/23xeLlxNEozURqR8uXmxu0ov7rSz5RGomJblO7BsSWq5ouqkcOxK9xejnXhOKLi+fjYnG9LzUuldbK+xdeG604pzYV/z/pYbgyUmsv8ez5fvTVeukLFrjCqVpPSQYoaGMcobdu2LbFZ32L27t2b2NOnT09sjplSWmquppSbm60sP2Vy3NJWGmOMMT2MFx5jjDGV4oXHGGNMpVSeq63oE1R+ffXNuNJFlAakfM3MsGHDEpv9/OxLL4N9pd0dC5Xfi/34rHGoOB6lnyk/P2smynes2sdjv3PnzsTm2BXVP6Uhcft5/JP2xoiGYr6u994DSmq0MKwLKD1K7c9jxXE4jPLjqzx8amwZFU+XU/+ms+Op54bSB1XcjtKwyo61ZcuWxOaYqTlz5iT2+eefX3q83JyHOW2v53zF3zuOx5iK+NBPf4qP/PjHQPtNFyMuuu8+LHj44d5tmDF9CC88xvQUMWLgwYM494knsOjee4EYsejee3HOr36FgQcPvr8YGdPP6dWyCMYcV4SA31x3HQDg3Mcfx9mPPw4AeOGjH8Vv/+APEnebMf2ZynO1FX2Y7BtWGkxuTqvcXG8M+zPZ/8p1ULi9xd8rv3SpZoAjNQaVT4rh4ymUn13FRuTGGTFlOaA6O76Kh2A/vtIFWDfh/Xk8i+P/LxdeiHOfeKLDfviKK4B9++o+F/eVt+8rHAs4cixGjRqV2KxNKg1G6W8Mt5fHmu8blUst975Umk6ujsHtVfszxblx5plnJtsuv/zyxF63bl1i833e1NSU2CqPHc/T3Po5art6bjlXmzG9QYz4+KOPJn+64uGH7WYzpoBdbcb0FLVFZ9HSpXh6wQL89Mor8bFHHsGFTz0FAHj06qvtbjMGXniM6TlCwFsnn4wn58/Hz6+8EggBP73ySpzQ0IC3Tz7Zi44xNSrP1VbmA8zNzcYoHUHZDPueOf5h7Nixib1mzZrELvpfVe4zla9L+cH5eCquR/mCVexCbk4o1b/cOvecz4th/Y11ETU+fD7WWfj37e2998wzgRhxYiHH1g8WLGhbdHbsAKDnAh+b285t5Vxtam6o+j5Kn8vNkchzl1H6JrdHjZ+ay0ovzM2TWJbHkMd63Lhxic21lHhes52r1TLqWqnnApOrf7VjjceYnoZvbr/pGJPghccYY0yleOExxhhTKZVrPEVtQNUfzyW3bkduvAD7Mzl2hOvztLa2dvyb/cK55MZWKD80k/N9PqDjhhjWhLg9rDMwXLteaTwqd1zuXGHdRekWxeOr2kB8bL4veF5xXA5rPCqeTeUoVPFxSlNR+qXan+cuzx0Vk9XdWBU115XmVdyfrw3XYuK+5fZF1QpSWmturjd17evFbzzGGGMqxQuPMcaYSvHCY4wxplJ6tR4Pkxtno/yfud//q9gS9i0PGTKk1N5Ri9sAdJwIo/qei8qLx5pJrp9b+fVVHJLyJbPGk6vP8firekV8fo7jUXFRxf4ozUKdW81L5dfntqprzSi/P/+ej6/ihlSMGO/P51MaEV8bVWsqV2vm9hS1X44nY3LrXKmYJEbNFYXShnO1547fZbXCGGOM6SZeeIwxxlSKFx5jjDGV0qtJQlVsi/Ils39U5ZhS8QpKE+Lzce62U045JbE3bNjQ8e/cOvXq+36lUSi9TPl6OXaErwVrLip/l9KMlI6gNKFcvz7PDe5vd+OAiu3jseK28rG5Jguj5rXKi1fWVuBIPYvbo+JqcvVMhq8dH19pYEozU+dT29XcLGo8qraP0mDUfaz0Kj6emjvquZB7vK7wG48xxphK8cJjjDGmUupaeEIII0II94QQVoUQmkMIF4YQRoUQfhFCWF3778gPurHGGGOOferVeL4B4Gcxxk+GEAYCGAzgrwA8FmP8+xDCVwF8FcBfqAOV+VOVr1ppOsr/yeRqSKq2PNfWKOoGqsaIqiGiaobk1s1gPzhrHNxX9uurWAqVe43Hju3GxsbEztW4lM7A10PNFTU3y2AtUNXLYU1F3Qfq2ufG6eTqDEpDyo0FYVTck7rWSt/je0v1R7WnWKdL6cZKI1HxcYzSShkVA6ZQ8XddId94QgjDAVwM4M7aid6JMbYCuBbAXbXd7gKwuP7mGmOM6a/U42prArAdwHdCCM+HEO4IITQCGBdj3FLbZyuAcZ39OITwhRDC0hDCUpVR2BhjzPFPPQtPA4DzAHwzxngugANoc6t1ENvetzp9R4sx3h5jnB9jnM8uB2OMMf2PejSezQA2xxiX1Ox70LbwvBFCmBBj3BJCmABgmzpQCCHxYSrfa+739Qr1Db3SUZQ/c+TI9PuKUaNGdfy7paWl9Le5MUeMijnqbj0gdTy2+e1W+d0ZpUmpmjFK/2NdgP+niDUnhs9XVq9H/Q+X0pty9T9G6QzqfByHxBoUx6ooTSknz11n7VNzUcXAKR1FxXBx/8pyNqp6N4rc+jlK/8vVgtW14LEu7l/WV/nGE2PcCmBTCGF27U+XA1gJ4EEAN9X+dhOAB9SxjDHGmHq/avsPAO6ufdG2FsAfom3R+lEI4WYAGwB8+oNpojHGmOOJuhaeGOMLAOZ3sunynm2OMcaY451ezdWm/JPK98v+SvX9vfL758YN8fnZ9z158uSOf7/++uulv82NHWC/OqM0EibXl8zH4/aV+X6BI8eK/ej8e96fz8/blS6gtvP48niwLsM6SDEuavDgwck2pSmoecjbeaxUfRsVg8XHV3pXbl4+pV/m6hLq2iqdQumVfH4eT9Z2i5peblxNvfVs6v19rgak2qvu63pxyhxjjDGV4oXHGGNMpXjhMcYYUyl9SuNRvlWlASl/pdJ4cmu4qJouRY3n1VdfTbZt25aGPam4ltxcbbn6Ffv5VVyQOh5rJEojUpqLitlSvnEVu8E2X0uO1VD9L/r5Wb/KzfuWex8ovU3lYlOaCOtbb775ZmKrGCmlKanccaqGjco/xnMzN86Hjz9mzJjELsvRqJ5Z3Y1NZNTcUr/P1ddUDFc7fuMxpqfhm/0oBVhjjle88BjTg1z+m9/gmscee3+xiRGXPvggPvzII73bMGP6EF54jOkpYsSgt9/GoqVLceXPfgbEiCt/9jOc/9vf4qSDB/3mY0yNSjWeGGPib1axJd3N1ZarGSl/qNIh2Nc9YsSIjn9PmjQp2cYaj4p9YNhvr+CxUHFAjNIVlI6hvv/n3G65dUJy54LSGXh8VH6xdn7woQ/hnXffxaXPPIOFzzwDAHhy/nw8tGgRsGtXaRvbUfVmVD0clbdOjcWBAwcSW2mZuXFIjNJ01FxXcTaqXo86P+s0rOmMG5cm5i/+PjcuR+WDzI2b4bFXMVlKo8mNseoKv/EY05OEgPsuuij500OXXw5kisbGHM944TGmJ4kRf/Db3yZ/SjQfY0zvfk5tzHFFbdG59MUX8evzzsODH/0oPvGrX+HipUsB+M3HmHYqX3iK/uXcb8SVZqN0ERUrw6j25egGM2bMSLb97ne/S2z2q6vv/VVfeLuK3VA6Av9eHV/l+2ptbU3sXaR/KN82j4fSZOrVaLo6X721mV4/cAD3T52Kb596KrB6Nb5+6qnY09qKA/v2oXnVqk7PpXKXsabCcTGcp05pOny83FpQPJZ836k4IKWVKp2Dz6c0LyY3doa127FjxyZ2Ucvl4+dqNrn5JNV9qDSb3JgqHruyumJlepTfeIzpQe6eOROIEQ3tD4wQcOe8eX7TMaaANR5jehpeZLzoGJPghccYY0ylVO5qK/oEla8295t15a9U51M5m9T5mGJsyimnnJJsmzZtWmK/+OKLic1+9FxU/R41tiofFtefUTVeWMPi37MG1NLSUrr/0KFDE3v8+PGJXcyTBxypa7DNfnseLz7/3r17E5vbXxw/Hovdu3cn9r59+1AG6188ltxWNc+5742NjYk9fPjw0uMp3YDnDqN0AxW3o+67Mt0BOPLe4vHj68Ga2mmnnZbYqmZNkdycgQqVR45R973SZlX+ymLMU9m5/MZjeh/nNjOmX+GFx/QqN6xahZtfeSXJbXbL2rX4szqj/I0xxx5eeEzvESMaDx3CJ9auxS1r13YsOp9qacHQw4f95mPMcUqlGk8IoVS7yPV3Kl+yQsUv8PlVfETZ8flcc+fOTezXXnstsTl2gP3yubCvVtVwUX1lv7+Kqeoq9uOeD38YJw0ciE+tWoVP1XSdB5qa8HchJF+D8XhwnXvu344dOxKbY1049oL90ezXV/WDWBcpu16qHozKW8eaz/79+0uPz7WEeOwY7iv/PjfHYs590hlKV2BUvB/PRZ77PNfmzJmT2KzX8u+L/Vd6FqP2z9W9uxOHA+hnYtnYlsVH+Y3H9C4h4O7585M/3TFnjj9B7g2stZmK8MJjepcY8dlaSpl2Pr9ypR96FfOZ5mb80csvJ1rbjc8+i2uff753G2aOS7zwmN6jtuj8m1Wr8EBTE37/4x/HA01NuHbdOvz1zp1efKoiRjS++y6uee21jsXnxmefxZXNzRj8zju+DqbHqbweT5nuoXI6dXa8IipnkzqfOp7Kd1bmy2Y/MNfwmD17dmIvpbcA5etVfnT2zXKNkdy+q3gBlQuuXQN5Z/BgPDpvHr4zfTpOCAHfhYVstQAAGYlJREFUOfNMDAgB4b33MHnKlI79WXPh8WxqakrsYcOGJTbH3XDsCmtCqiaNqmtSnHusuXDbOW6EY7w4RonbxhoPX1vWJLiezPDhw/Gvl12GQYMG4ZoVK3BNTW/85Zln4v5Fi3CyiBNSqFxuPB7qPlW51Xiuqzx9e/bsSWy+Xnxvcn94LhT7p+LbGKUB5dbLUZqMiqFS+5fVMnKuNtNn+dfzz2/7P+rt29v+UMtttocWCvMBEwJ+dOGFuHzFio4/3bNokbU284FgV5vpfZzbrPeJEZ9++unkT5988km72cwHgt94jOnv1Bady1eswGPz5uHeiy7CJ598Epe9/DIA1xEyPU/lGk/Rh8j+ylwNRnG09cDbya0HVNZ+9gNznMf555+f2Js2bUrsnTt3JjbHpai+Kt+s8qMrfYtR8QOq5gzHUgwePDixOZaF/fSTJk1KbPbbc663UaNGJbbqn8phVZznqsYJ54HjOBvuG9dy4jgb1re4b9z3kwcNwjuDB+NX55yDBz/yEZwQI3588cUIAwbgrYEDMYDmvZorKrcb6wg8lqxL8FxXGpN6TnCcFI//woULE3vixImJze0tq0WlNB3VVjUP1TNI7a+0YqVRlZ3fGo8xppSfLVzY5lYLoeO/9110ERACTtI/NyYLazzGmDastZmK8MJjjDGmUirP1Vb0z6r6N8o3Xs/5yo6fW39H6RQ5bWENg/308+bNS+xf//rXpW1RMUtMd2KSAK0Rqd+rXG7s12fdgtu7devWxGY/PudmmzVrVml7VH4yjqXh4xdjaTjOhvfd3v4peY3NmzcnNveN+84xYaxn8dixnpZ77VQOQ26fqt3Ec1WdnzUivjZKA+J7j2PEWANTukiOltzTudty42z4WpfFIHWGOn69z2i/8RhjjKkULzzGGGMqxQuPMcaYSqn8c+qijzC3Pjj7jpX/k/dX/lTeX51PUTxfbq119turOBdVL0b1XcVWsOai6gPxtVX1fFjjYZvzj7EfnsdP5TPj/o4ePTqxp0+fXtpejqviWJmirsF54vjarVy5MrF3796d2DwP+Vys6TBK81C51HJ1CDW3Ve2n3ByKKlaGUdrs8uXLE5tz6V122WWl7SnL46eeMWUxQZ3trzQWpQGpa5Ub51Ov3uU3HmOMMZXihccYY0yleOExxhhTKb1aj0fFnuTW5VC+7FzdQ5ETC6O+p+djcawHaxCsG6ixUvmzGBXjlFuLXfnllcaTOzc43xnrKuvXr0/slpaWxObYGR4/9vtz7rji+bZt25ZsYz85jwXrZ6yvqbHn/VWuM6UrqGuvdAPWdJjc+j65cT6sgbW2tiY2x01df/31if2Tn/wksTlGbPHixYldHB+ed0xurjalqeTW2+nufVsW11PWN7/xGGOMqRQvPMYYYyrFC48xxphK6VNlEdT3/LmaT+525d/M1T1y9lW51zjfVu7YMKwjqO/3le9YjY2KtWBNh/vLvmnWuFS+seHDhyc2+/057odjafh43N7XXnstsYu+eB4bzg3G10JpHjz2/HuOceLzKb892zxWSjdgm68Nj11uXj9GxbpwLSeuZ8RxN1OnTi1t37/8y78kNsdVXXjhhR3/Zn2NtUFuG7eF89ypa8Xk6thKr8t5BpfVEvIbjzHGmErxwmOMMaZSvPAYY4yplMrr8RR9guw7VfEDyt/IqN+rPES59c7LfM1Kk+Hv85csWZLYHGfCfn1VV4N9zcqvruJ8GB4r1gWUb1rVZGGNhseT4yVYs2lsbExs1pD4+Lm+8zKNibcpTYTHnseSNRKOWeK+Mrm50xiV10/plUrvVHn9OG8fz3XWtLje0erVqxN75syZpcc/55xzEvuBBx5I7Oeeey6xi/fatGnTkm2bNm1KbI7xYn1pzJgxic1joTQhpc0ySi/L0W4dx2OMMabP4IXHGGNMpXjhMcYYUyl9Ko4nt36OIje/lyK3Pk9xO/utuS1cA+TZZ59NbPZbDxkyJLFzczApVJ0P1iHY98z9ZVu1l2Gdg2MnWPPiOB+ux8O+cFVfSMV0McXxUpoOawp8bNbnWNPhuaDqw6i4GoXSrPhaKc1G1d9Rud5U3j/WR3nusibW3Nyc2Dy+kydPTmyea0899VTHv7ds2ZJsK8b4AMCOHTsS+6GHHkps1iLPPffcxJ40aVLp/qx98rxX2nB379uu8BuPMcaYSvHCY4wxplK88BhjjKmUPqXxKM1ExReo2hVMbj4xdb6yb+zfeOONZNu6desSe+XKlaXnYr+1yrWmcjwpcvUvvnY8FkofU9dKaVSsK3D9IvZ9s1+edRalSyjdpmwuq1xi3FbWGFSMlIqHy41XU5qLqqWkNB9GaVJKux0/fnxiP//886XnZ81sz549ic33Gs+tsryGa9euTbbxPGO96OKLL07sZcuWJfaPf/zjxGatc/bs2Yk9ffr0xOa5xX3jWkOsEeXEtzmOxxhjTJ/BC48xxphK8cJjjDGmUirVeA4fPpxoD92tLaG+/8/1Zav9Vc4ozgG1cePGjn9z7jDWYLjt7HtlP7nSwxi1v8o7pzQYHiseG/b7q9xuuf1Tc0nVN+LrwXQ5N2IEQnj/fDW7ODeVBqL0MB57dR+o46tcaeraK/2Pz8+/z40x47Hna8V59jjmbdeuXYnNc+3UU09NbB5/FQPG+xf7z3rY66+/ntibN28ubTvH6bCms379+sTm+D/WiCZMmJDYrDFxrjg+H/eH6wuxPtcVfuMx5ij55IoV+N+ef75tsQGAGPG5F1/Ep155pXcbZkwfxwuPMUdDjBj8zju4evXqjsXncy++iI+vWYPGd999fzEyxhxBn/qc2phjhhDwvVr6kqtXr8bVNTfrT2bMwHfPPhsDhFvXmP5Mry48KvYjF1XThVGaDh+vqNkAwIoVKxKbY0OKx+dj8bnYd8q+XtUX9qvnxpnkxu3k1nBR+hqj5gKfnzUx1X9V44Y1qq58198+88yORQcAvnv22YDQaFRMU3c1HN6urq2Ki1Fapzq+0vsYlWuOx5PjaliD4Ro4HLczdOjQ0vaxDsO537jmThF17Xhecu623bt3JzbrWdx3fm7wtWxtbU1s7gvnjGTNp6mpKbFZIypqp2X5D+1qM+ZoiRGfe+ml5E+fe/FFu9mMEdjVZszRUFt0rlmzBg/NmIG7zj67Q+MB0OaGs7vNmE7xwmPM0RAC3jzxRDw0Ywa+e9ZZCCG0udkAHDjxRC86xpRQ6cITQki0AP6eX33vr3zhqmYKH5/9nfxNOn9zz9/Mc3v4m/fidqUZKM1B5Q7LjbVQuoOC+87XiturYqzU75XNcI4p1R6eS3w9ePuhQ4fw0w99CIgRQ0PoGL97L7oICAGNtG8Rrq+TGxfDbVM6groPVC40VZuJf5+bd4+vDf9e1c9hjWb79u2Jzfc16xQ8XpyvjJ8TPP7cnrJ4RFVbiPvCfee+KPg5wRqQ0kZZ3+L6Qtz3cePGdfybNe8i1niM6Q68YPtNxxhJXQtPCOE/hhBeCSGsCCF8P4RwcgihKYSwJISwJoTwwxDCQH0kY4wx/R3pagshTATwZwDmxBgPhhB+BOAGAFcD+McY4w9CCN8CcDOAb9ZxvI5/8yuuSp3B+/MrLb8Sc6oM/lRRpX/gNDf82srp6stcFiotCbtDVFoT5SpTriwea+WeyS1HzOdXn9Dy2OaWQVD9UWUPlDsp9xPlMlcg/1aVuuax4WvJ7hLenz8v5rFSn0dzyphc1xyj0huxzePD7iJuD5cg4WvBaWO4vewiYrf4iBEjEpvHr3g85dLla6dc0ry/SqfE1573VyElfJ/xfb9z587ELo49uyyL1OtqawAwKITQAGAwgC0ALgNwT237XQAW13ksY4wx/Ri58MQYWwB8HcBGtC04ewAsA9AaY2xfPjcDmNjZ70MIXwghLA0hLFWJGI0xxhz/yIUnhDASwLUAmgCcCqARwFX1niDGeHuMcX6McX5ZJKsxxpj+QT2fU18BYF2McTsAhBDuA7AIwIgQQkPtrWcSgJaSYwBo818WfYwqjQn7O7dt25bYnMJGaTgK3p997azpsG6gPu8uolLC8Hb+PJjhRT23dHPu59XsV+fjqf4pzUfpf7nll5Uuoc6vNK8yzUfpbYwqk6DSLfHxVfqg3DAGpW+xJqJ0C6UJ8dxWc4e1Xb6Pi5/8AkfeW3xfq+dA2efquemFVIiJuq/4+FxWXWm16tozZfddWV/r0Xg2AlgYQhgc2kb4cgArATwO4JO1fW4C8EAdxzLGGNPPqUfjWYK2jwiWA3i59pvbAfwFgP8UQlgDYDSAOz/AdhpjjDlOqCtzQYzxbwD8Df15LYAFPd4iY4wxxzWVpsxpaGhI0nhzWdc9e/Yk9quvvprY7Ltl/6fSOdifmeuLZl1A+UOL/ljlR1ep7vmLQP5+nsv3MqyfMeznzi1RwWPDfnIVl6Q0HN6frw3HDHD7lcbFc4f9+ozSwIpzgc+lYrZUShm2eaxVzBafT5UdYHLvA0aVR+a5WhYnAxzZfy4lwGloVAl77g/PhZyPpFR8mXpGqfg/hdITc9MjqRirep8bTpljjDGmUrzwGGOMqRQvPMYYYyqlUo1n4MCBSalUTl/OZVg5RxT7ftnXyv5Q1kXYViWDlS6g0tMXz6fiRlRuM9ZglEak4lz49ypXWm4cDLeXfcXsd2c/OrdflS3ILb3N8Q0qdiY3nqFMJ8nVRFSshdIPVcyVyuWm4oZy9K7OUDqBimNifY+1YC4PzePBGg/Dc0WNR1nJ+1xUHI+ad+r8uWXR1e/r1aD8xmOMMaZSvPAYY4ypFC88xhhjKqVSjefgwYNYuXJlh62+5+eyqir/lvKF58amMHw+dbyif7QsxqezY6vv6dnvrNqqyiPzWKlrozQf9oNzbSMVy6LqC6lrrfQ3pSMwqr1McTxUX9gvr3IMKk2C+87HZ02HNRJVo0WNlcrFpvLqqVxsPNc4po3n7pQpUxJbldbmuaFiuspiW9R9rmKmuluSPleDUVop6+q5tZg62lXXXsYYY0wP4YXHGGNMpXjhMcYYUymVajxA6g9lfyD7UpVvlX3V7BtXOgmj4naU77ssxxO3Ndd3q2qsqHo6Kj8Vo3zRuTmbVH4xrnM/aNCgxFYaGaN85yreQcUx5fjOVYwV/1bFiai2cd84pkrl5etuPi6lMyi9TM0dbh9rPCNHjkzsCRMmJDZrQCqGTemLZc8x3qby3PG1U7ndVC42lWtNzT11vrI8emXPOL/xGGOMqRQvPMYYYyrFC48xxphKqVTjiTEm/lH1/T77CFVOKSZXd1A1X5S/lSm2V52Lj81927p1a2Jz3XdG5RrL1c8U6nt+1R7ld1exLyquiffnWBduv9KIlN+/TAfJ9bsrPz7DMVP79u1LbBVzpbRMRmk4jIoLUtop29xfrvOl6g/xePC9oeZGmYan9LNc7VLNBTVWSr/jvufODWs8xhhj+iReeIwxxlSKFx5jjDGVUnkcT9Hvp/z+7EtVOZ+Ur1jpLMp3q/JzlcWGqPo5qq0c56J8rbm5z9hmDYTJjZFSugL73VljYk2L8/jx2Cv9jfOTcXu4/7ydz8c5rIqovHI8dtx3jnlS9XR4f54L6tqquaL0ONYJlC7B94KaWxyHxO0bNmxYYufGQfH4KE0oJ++fiotRWql6Zqk8f3x+vlbquZSrhXaF33iMMcZUihceY4wxleKFxxhjTKVUqvGEEBIfooplUf7D3DxFyu+vYkdyczoV+8dt5X1VTBL7YlWuttxYDFWfR/nd1bVTuc1UfZ89e/YkNvv5Ve0m9turWI3cucO6SnF/vla8r9JolMajahFxX9V9p/RBVWOG28v619ChQ1GGqpfDcUnqeCrnoqr/w9dH6TTF7SomSaE0FZVDkfvG90lOTbHOzqd0+q7wG48xxphK8cJjjDGmUrzwGGOMqZTK43iK/mDOr6VqVag4H0blglPfvOfmC2OK/VH1XHLzYbHfWflqmdz9VawFw2Ol8o/lalL8e/b7q7x7Kledis3g7WUxZxwHwraKV1N6GGsoauzVdp5bKraD+8PtYV1B6R78HFDt4WtZprd19nsVp8TPCa4VVXYv58yTzo7FcN947HjsWe9T9wXbfF+p3HP14jceY4wxleKFxxhjTKV44THGGFMplWo8AwYMKM1ppXyryu/P8LmUhqRq4ih/ptKMiqjv33k75yprbW0t/b1C6WdKA1F+fhX3kqvPsW9axbIwvJ3jglSeP1U3pSwOS/ntmdwcgyreTJGrMzCs4XBcjap9xLaKexo5cmTpdkbFbKm6X0xO3r5cTYf3V5qO0rF5Lqj7SsUsMbnPnY7zHtWvjDHGmKPEC48xxphK8cJjjDGmUno1jkd9r59bjzxX01Hf96scTiofWREVx8Lbue0cO8C5ylhjUbEKjNIRuH3qfHwtVRyT8hWra6PymTEqlkXpLIqy/qi8fLl1oHLHluet0vNU+1jTUbnMFKoWk6oRo54D/BxR2jIfT82N4vnUvFL1dJSmw88FtpUurmoVMepaFvtTdg/4jccYY0yleOExxhhTKV54jDHGVErlGk/Rh6i+cVc6CMcHqJoy7PtW+bhUfjKlY5T1lc/NfWGbf69iDVTdDKWXqbFSvl72i7MvWfVPxWbk6nMqXkJpbKq/ObEv3dVslIaitEelWTC5udd47FStJRU7wuc/cOBAYqtccjx3eS4ePHiw9Hjd0azUPGetlmH9TWk66pnGehaTm89SPWO7wm88xhhjKsULjzHGmErxwmOMMaZSKtV4YoyJj5N9tSp/l/LdqroePRmLAeiaOsXfd/f7eG4L+4ZVzZLcnEoqdxn7ntkXrDQola+LYc1H6SDq2vBc4Pbn5itjir/nc6u2MupaqHgzpYcxrOGwjsBjxXNLaS5837PuMGzYsMRWOgijYrRUDsjce6VMD1Wajoox4rFX+lxuzTKlo/P2nGtfph36jccYY0yleOExxhhTKV54jDHGVErlGk/RR8j+QrYHDx6c2Ln5x5TvnP2fud/rs3+2rL65aovyK+fG8fD5VJ46pYmo2vF8PL52PFb8+7KaJp3ZPFdUHJDSdJSvXWlQZbEqubnXcuvr8LxT+3N7WK9TtY+UXqbq23DcDOd6UzFWKmZLxTUpfZHHT9XQKYuVUbWFeF7zWPC1UXNJxeko1Nira12vPuY3HmOMMZXihccYY0yleOExxhhTKZVrPEUfJPs7VZ4h/qadYX9qd+uaKF1AUTy/yj2mfKUqlkJ9r8+oHEtK71L5vcr0LuDI8VD5vlTteBXHpPrD463qqDBlOoDSbFScjtqfj69yGKoYLx4bPr+Kn2Odga8Nz2X+Pc8NFRfEtqppo/qn9EQVJ1S0Vd0qPhdrOqpWkmqb6rvSWpWmwzhXmzHGmD6JFx5jjDGV4oXHGGNMpYTcvETdOlkI2wFsADAGwI7KTnx84bE7ejx23cPjd/T0x7GbGmM8pbMNlS48HScNYWmMcX7lJz4O8NgdPR677uHxO3o8dil2tRljjKkULzzGGGMqpbcWntt76bzHAx67o8dj1z08fkePx65Ar2g8xhhj+i92tRljjKkULzzGGGMqpdKFJ4RwVQjhdyGENSGEr1Z57mOREMLkEMLjIYSVIYRXQghfqv19VAjhFyGE1bX/juzttvZVQggnhBCeDyE8VLObQghLanPwhyGEgeoY/ZEQwogQwj0hhFUhhOYQwoWed/URQviPtft1RQjh+yGEkz3vUipbeEIIJwC4DcDHAMwBcGMIYU5V5z9GOQTgP8cY5wBYCOCLtTH7KoDHYowzATxWs03nfAlAc8H+BwD/GGOcAWA3gJt7pVV9n28A+FmM8XQAZ6NtDD3vBCGEiQD+DMD8GOM8ACcAuAGedwlVvvEsALAmxrg2xvgOgB8AuLbC8x9zxBi3xBiX1/69D203/0S0jdtdtd3uArC4d1rYtwkhTALwcQB31OwA4DIA99R28dh1QghhOICLAdwJADHGd2KMrfC8q5cGAINCCA0ABgPYAs+7hCoXnokANhXszbW/mToIIUwDcC6AJQDGxRi31DZtBTCul5rV17kVwFcAtNdYGA2gNcbYnvvdc7BzmgBsB/CdmpvyjhBCIzzvJDHGFgBfB7ARbQvOHgDL4HmX4I8LjgFCCEMA3AvgyzHGvcVtse17eH8TT4QQrgGwLca4rLfbcgzSAOA8AN+MMZ4L4ADIreZ51zk13etatC3epwJoBHBVrzaqD1LlwtMCYHLBnlT7mykhhHAi2hadu2OM99X+/EYIYUJt+wQA23qrfX2YRQA+EUJYjza37mVo0y1G1FwggOdgV2wGsDnGuKRm34O2hcjzTnMFgHUxxu0xxncB3Ie2ueh5V6DKhec5ADNrX3cMRJvg9mCF5z/mqGkSdwJojjH+t8KmBwHcVPv3TQAeqLptfZ0Y41/GGCfFGKehba79Msb4WQCPA/hkbTePXSfEGLcC2BRCmF370+UAVsLzrh42AlgYQhhcu3/bx87zrkDVZRGuRpvf/QQA344x/l1lJz8GCSFcBOA3AF7G+zrFX6FN5/kRgCloKzPx6Rjjrl5p5DFACOGjAP48xnhNCGE62t6ARgF4HsC/izGW1yXvh4QQzkHbRxkDAawF8Ido+x9VzztBCOH/BPAZtH2V+jyAz6NN0/G8q+GUOcYYYyrFHxcYY4ypFC88xhhjKsULjzHGmErxwmOMMaZSvPAYY4ypFC88xhhjKsULjzHGmEr5/wFdnPVkPgh0nQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformed image from the original image with landmarks transformed along with the image\n",
        "#Test for new affine transformed images\n",
        "#Checking whether landmarks are properly applied for the transformed images\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.imshow(X_train[2099].reshape(96,96),cmap='gray')\n",
        "\n",
        "xs = y_train[2099][0::2]\n",
        "ys = y_train[2099][1::2]\n",
        "plt.scatter(xs, ys, marker='x', color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vT_DzL9tIJ-g",
        "outputId": "3e96551c-4917-44ad-ef72-e40628af8df9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "  model_input = keras.Input((96, 96, 1))\n",
        "  res_net = layers.ZeroPadding2D((3, 3))(model_input)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=64, kernel_size=7, strides=2, name='convBlock1')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm1')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "  res_net = layers.MaxPool2D(pool_size=3, strides=2)(res_net)\n",
        "\n",
        "\n",
        "  # FIRST RES BLOCK \n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=64, kernel_size=1, strides=1, name ='resBlock2ConvA')(res_net)\n",
        "  # res_net = layers.MaxPool2D(pool_size=2)(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm2ConvA')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', name ='resBlock2ConvB')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm2ConvB')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=1, strides=1, padding='same', name ='resBlock2ConvC')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm2ConvC')(res_net)\n",
        "\n",
        "  res_net_copy1 = layers.Conv2D(256, kernel_size=1, strides=1, name='resBlock2Copy')(res_net_copy1)\n",
        "  res_net_copy1 = layers.BatchNormalization(axis=3, name='batchNorm2Copy')(res_net_copy1)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=64, kernel_size=1, strides=1, name ='resBlock2IdentityConv1A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm2IdentityConv1A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', name ='resBlock2IdentityConv1B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm2IdentityConv1B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=1, strides=1, padding='same', name ='resBlock2IdentityConv1C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm2IdentityConv1C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=64, kernel_size=1, strides=1, name ='resBlock2IdentityConv2A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm2IdentityConv2A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', name ='resBlock2IdentityConv2B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm2IdentityConv2B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=1, strides=1, padding='same', name ='resBlock2IdentityConv2C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm2IdentityConv2C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "\n",
        "  # SECOND RES BLOCK\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=128, kernel_size=1, strides=1, name ='resBlock3ConvA')(res_net)\n",
        "  # res_net = layers.MaxPool2D(pool_size=2)(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3ConvA')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', name ='resBlock3ConvB')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3ConvB')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=512, kernel_size=1, strides=1, padding='same', name ='resBlock3ConvC')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3ConvC')(res_net)\n",
        "\n",
        "  res_net_copy1 = layers.Conv2D(512, kernel_size=1, strides=1, name='resBlock3Copy')(res_net_copy1)\n",
        "  res_net_copy1 = layers.BatchNormalization(axis=3, name='batchNorm3Copy')(res_net_copy1)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=128, kernel_size=1, strides=1, name ='resBlock3IdentityConv1A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3IdentityConv1A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', name ='resBlock3IdentityConv1B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3IdentityConv1B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=512, kernel_size=1, strides=1, padding='same', name ='resBlock3IdentityConv1C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3IdentityConv1C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=128, kernel_size=1, strides=1, name ='resBlock3IdentityConv2A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3IdentityConv2A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', name ='resBlock3IdentityConv2B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3IdentityConv2B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=512, kernel_size=1, strides=1, padding='same', name ='resBlock3IdentityConv2C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3IdentityConv2C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=128, kernel_size=1, strides=1, name ='resBlock3IdentityConv3A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3IdentityConv3A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', name ='resBlock3IdentityConv3B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3IdentityConv3B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=512, kernel_size=1, strides=1, padding='same', name ='resBlock3IdentityConv3C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm3IdentityConv3C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=1, strides=2, name ='resBlock4ConvA')(res_net)\n",
        "  # res_net = layers.MaxPool2D(pool_size=2)(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4ConvA')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', name ='resBlock4ConvB')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4ConvB')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=1024, kernel_size=1, strides=1, padding='same', name ='resBlock4ConvC')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4ConvC')(res_net)\n",
        "\n",
        "  res_net_copy1 = layers.Conv2D(1024, kernel_size=1, strides=2, name='resBlock4Copy')(res_net_copy1)\n",
        "  res_net_copy1 = layers.BatchNormalization(axis=3, name='batchNorm4Copy')(res_net_copy1)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=1, strides=1, name ='resBlock4IdentityConv4A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv4A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', name ='resBlock4IdentityConv4B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv4B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=1024, kernel_size=1, strides=1, padding='same', name ='resBlock4IdentityConv4C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv4C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=1, strides=1, name ='resBlock4IdentityConv5A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv5A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', name ='resBlock4IdentityConv5B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv5B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=1024, kernel_size=1, strides=1, padding='same', name ='resBlock4IdentityConv5C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv5C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=1, strides=1, name ='resBlock4IdentityConv6A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv6A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', name ='resBlock4IdentityConv6B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv6B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=1024, kernel_size=1, strides=1, padding='same', name ='resBlock4IdentityConv6C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv6C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=1, strides=1, name ='resBlock4IdentityConv7A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv7A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=1024, kernel_size=3, strides=1, padding='same', name ='resBlock4IdentityConv7B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv7B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=1024, kernel_size=1, strides=1, padding='same', name ='resBlock4IdentityConv7C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv7C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=1, strides=1, name ='resBlock4IdentityConv8A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv8A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', name ='resBlock4IdentityConv8B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv8B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=1024, kernel_size=1, strides=1, padding='same', name ='resBlock4IdentityConv8C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm4IdentityConv8C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=512, kernel_size=1, strides=2, name ='resBlock5ConvA')(res_net)\n",
        "  # res_net = layers.MaxPool2D(pool_size=2)(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm5ConvA')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', name ='resBlock5ConvB')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm5ConvB')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=2048, kernel_size=1, strides=1, padding='same', name ='resBlock5ConvC')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm5ConvC')(res_net)\n",
        "\n",
        "  res_net_copy1 = layers.Conv2D(2048, kernel_size=1, strides=2, name='resBlock5Copy')(res_net_copy1)\n",
        "  res_net_copy1 = layers.BatchNormalization(axis=3, name='batchNorm5Copy')(res_net_copy1)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=512, kernel_size=1, strides=1, name ='resBlock5IdentityConv9A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm5IdentityConv9A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', name ='resBlock5IdentityConv9B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm5IdentityConv9B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=2048, kernel_size=1, strides=1, padding='same', name ='resBlock5IdentityConv9C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm5IdentityConv9C')(res_net)\n",
        "\n",
        "  res_net = layers.Add()([res_net, res_net_copy1])\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_copy1 = res_net\n",
        "\n",
        "  res_net = layers.Conv2D(filters=512, kernel_size=1, strides=1, name ='resBlock5IdentityConv10A')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm5IdentityConv10A')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', name ='resBlock5IdentityConv10B')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm5IdentityConv10B')(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net = layers.Conv2D(filters=2048, kernel_size=1, strides=1, padding='same', name ='resBlock5IdentityConv10C')(res_net)\n",
        "  res_net = layers.BatchNormalization(axis=3, name='batchNorm5IdentityConv10C')(res_net)\n",
        "\n",
        "  res_net = layers.AveragePooling2D(pool_size=2, name='AveragePooling')(res_net)\n",
        "  res_net = layers.Flatten()(res_net)\n",
        "\n",
        "\n",
        "  res_net = layers.Dense(512)(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "  # res_net = layers.Dropout(0.2)(res_net)\n",
        "\n",
        "\n",
        "  res_net = layers.Dense(30)(res_net)\n",
        "  res_net = layers.ReLU()(res_net)\n",
        "\n",
        "  res_net_model = Model(model_input, res_net)\n",
        "  print(res_net_model.summary())\n",
        "  return res_net_model\n",
        "\n"
      ],
      "metadata": {
        "id": "nO-QtWCFIMiV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_net50 = get_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdVACOGuJaD4",
        "outputId": "835c5c65-58d5-439a-825e-aaeffde83aa5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 96, 96, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 102, 102, 1)  0          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " convBlock1 (Conv2D)            (None, 48, 48, 64)   3200        ['zero_padding2d[0][0]']         \n",
            "                                                                                                  \n",
            " batchNorm1 (BatchNormalization  (None, 48, 48, 64)  256         ['convBlock1[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 48, 48, 64)   0           ['batchNorm1[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 23, 23, 64)   0           ['re_lu[0][0]']                  \n",
            "                                                                                                  \n",
            " resBlock2ConvA (Conv2D)        (None, 23, 23, 64)   4160        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batchNorm2ConvA (BatchNormaliz  (None, 23, 23, 64)  256         ['resBlock2ConvA[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 23, 23, 64)   0           ['batchNorm2ConvA[0][0]']        \n",
            "                                                                                                  \n",
            " resBlock2ConvB (Conv2D)        (None, 23, 23, 64)   36928       ['re_lu_1[0][0]']                \n",
            "                                                                                                  \n",
            " batchNorm2ConvB (BatchNormaliz  (None, 23, 23, 64)  256         ['resBlock2ConvB[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 23, 23, 64)   0           ['batchNorm2ConvB[0][0]']        \n",
            "                                                                                                  \n",
            " resBlock2ConvC (Conv2D)        (None, 23, 23, 256)  16640       ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " resBlock2Copy (Conv2D)         (None, 23, 23, 256)  16640       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batchNorm2ConvC (BatchNormaliz  (None, 23, 23, 256)  1024       ['resBlock2ConvC[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " batchNorm2Copy (BatchNormaliza  (None, 23, 23, 256)  1024       ['resBlock2Copy[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 23, 23, 256)  0           ['batchNorm2ConvC[0][0]',        \n",
            "                                                                  'batchNorm2Copy[0][0]']         \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 23, 23, 256)  0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " resBlock2IdentityConv1A (Conv2  (None, 23, 23, 64)  16448       ['re_lu_3[0][0]']                \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm2IdentityConv1A (Batc  (None, 23, 23, 64)  256         ['resBlock2IdentityConv1A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 23, 23, 64)   0           ['batchNorm2IdentityConv1A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock2IdentityConv1B (Conv2  (None, 23, 23, 64)  36928       ['re_lu_4[0][0]']                \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm2IdentityConv1B (Batc  (None, 23, 23, 64)  256         ['resBlock2IdentityConv1B[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 23, 23, 64)   0           ['batchNorm2IdentityConv1B[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock2IdentityConv1C (Conv2  (None, 23, 23, 256)  16640      ['re_lu_5[0][0]']                \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm2IdentityConv1C (Batc  (None, 23, 23, 256)  1024       ['resBlock2IdentityConv1C[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 23, 23, 256)  0           ['batchNorm2IdentityConv1C[0][0]'\n",
            "                                                                 , 're_lu_3[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 23, 23, 256)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " resBlock2IdentityConv2A (Conv2  (None, 23, 23, 64)  16448       ['re_lu_6[0][0]']                \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm2IdentityConv2A (Batc  (None, 23, 23, 64)  256         ['resBlock2IdentityConv2A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 23, 23, 64)   0           ['batchNorm2IdentityConv2A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock2IdentityConv2B (Conv2  (None, 23, 23, 64)  36928       ['re_lu_7[0][0]']                \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm2IdentityConv2B (Batc  (None, 23, 23, 64)  256         ['resBlock2IdentityConv2B[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 23, 23, 64)   0           ['batchNorm2IdentityConv2B[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock2IdentityConv2C (Conv2  (None, 23, 23, 256)  16640      ['re_lu_8[0][0]']                \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm2IdentityConv2C (Batc  (None, 23, 23, 256)  1024       ['resBlock2IdentityConv2C[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 23, 23, 256)  0           ['batchNorm2IdentityConv2C[0][0]'\n",
            "                                                                 , 're_lu_6[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 23, 23, 256)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " resBlock3ConvA (Conv2D)        (None, 23, 23, 128)  32896       ['re_lu_9[0][0]']                \n",
            "                                                                                                  \n",
            " batchNorm3ConvA (BatchNormaliz  (None, 23, 23, 128)  512        ['resBlock3ConvA[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 23, 23, 128)  0           ['batchNorm3ConvA[0][0]']        \n",
            "                                                                                                  \n",
            " resBlock3ConvB (Conv2D)        (None, 23, 23, 128)  147584      ['re_lu_10[0][0]']               \n",
            "                                                                                                  \n",
            " batchNorm3ConvB (BatchNormaliz  (None, 23, 23, 128)  512        ['resBlock3ConvB[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 23, 23, 128)  0           ['batchNorm3ConvB[0][0]']        \n",
            "                                                                                                  \n",
            " resBlock3ConvC (Conv2D)        (None, 23, 23, 512)  66048       ['re_lu_11[0][0]']               \n",
            "                                                                                                  \n",
            " resBlock3Copy (Conv2D)         (None, 23, 23, 512)  131584      ['re_lu_9[0][0]']                \n",
            "                                                                                                  \n",
            " batchNorm3ConvC (BatchNormaliz  (None, 23, 23, 512)  2048       ['resBlock3ConvC[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " batchNorm3Copy (BatchNormaliza  (None, 23, 23, 512)  2048       ['resBlock3Copy[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 23, 23, 512)  0           ['batchNorm3ConvC[0][0]',        \n",
            "                                                                  'batchNorm3Copy[0][0]']         \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 23, 23, 512)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " resBlock3IdentityConv1A (Conv2  (None, 23, 23, 128)  65664      ['re_lu_12[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm3IdentityConv1A (Batc  (None, 23, 23, 128)  512        ['resBlock3IdentityConv1A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 23, 23, 128)  0           ['batchNorm3IdentityConv1A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock3IdentityConv1B (Conv2  (None, 23, 23, 128)  147584     ['re_lu_13[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm3IdentityConv1B (Batc  (None, 23, 23, 128)  512        ['resBlock3IdentityConv1B[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 23, 23, 128)  0           ['batchNorm3IdentityConv1B[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock3IdentityConv1C (Conv2  (None, 23, 23, 512)  66048      ['re_lu_14[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm3IdentityConv1C (Batc  (None, 23, 23, 512)  2048       ['resBlock3IdentityConv1C[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 23, 23, 512)  0           ['batchNorm3IdentityConv1C[0][0]'\n",
            "                                                                 , 're_lu_12[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 23, 23, 512)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " resBlock3IdentityConv2A (Conv2  (None, 23, 23, 128)  65664      ['re_lu_15[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm3IdentityConv2A (Batc  (None, 23, 23, 128)  512        ['resBlock3IdentityConv2A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 23, 23, 128)  0           ['batchNorm3IdentityConv2A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock3IdentityConv2B (Conv2  (None, 23, 23, 128)  147584     ['re_lu_16[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm3IdentityConv2B (Batc  (None, 23, 23, 128)  512        ['resBlock3IdentityConv2B[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 23, 23, 128)  0           ['batchNorm3IdentityConv2B[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock3IdentityConv2C (Conv2  (None, 23, 23, 512)  66048      ['re_lu_17[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm3IdentityConv2C (Batc  (None, 23, 23, 512)  2048       ['resBlock3IdentityConv2C[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 23, 23, 512)  0           ['batchNorm3IdentityConv2C[0][0]'\n",
            "                                                                 , 're_lu_15[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 23, 23, 512)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " resBlock3IdentityConv3A (Conv2  (None, 23, 23, 128)  65664      ['re_lu_18[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm3IdentityConv3A (Batc  (None, 23, 23, 128)  512        ['resBlock3IdentityConv3A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 23, 23, 128)  0           ['batchNorm3IdentityConv3A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock3IdentityConv3B (Conv2  (None, 23, 23, 128)  147584     ['re_lu_19[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm3IdentityConv3B (Batc  (None, 23, 23, 128)  512        ['resBlock3IdentityConv3B[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 23, 23, 128)  0           ['batchNorm3IdentityConv3B[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock3IdentityConv3C (Conv2  (None, 23, 23, 512)  66048      ['re_lu_20[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm3IdentityConv3C (Batc  (None, 23, 23, 512)  2048       ['resBlock3IdentityConv3C[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 23, 23, 512)  0           ['batchNorm3IdentityConv3C[0][0]'\n",
            "                                                                 , 're_lu_18[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 23, 23, 512)  0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " resBlock4ConvA (Conv2D)        (None, 12, 12, 256)  131328      ['re_lu_21[0][0]']               \n",
            "                                                                                                  \n",
            " batchNorm4ConvA (BatchNormaliz  (None, 12, 12, 256)  1024       ['resBlock4ConvA[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4ConvA[0][0]']        \n",
            "                                                                                                  \n",
            " resBlock4ConvB (Conv2D)        (None, 12, 12, 256)  590080      ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " batchNorm4ConvB (BatchNormaliz  (None, 12, 12, 256)  1024       ['resBlock4ConvB[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4ConvB[0][0]']        \n",
            "                                                                                                  \n",
            " resBlock4ConvC (Conv2D)        (None, 12, 12, 1024  263168      ['re_lu_23[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " resBlock4Copy (Conv2D)         (None, 12, 12, 1024  525312      ['re_lu_21[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batchNorm4ConvC (BatchNormaliz  (None, 12, 12, 1024  4096       ['resBlock4ConvC[0][0]']         \n",
            " ation)                         )                                                                 \n",
            "                                                                                                  \n",
            " batchNorm4Copy (BatchNormaliza  (None, 12, 12, 1024  4096       ['resBlock4Copy[0][0]']          \n",
            " tion)                          )                                                                 \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 12, 12, 1024  0           ['batchNorm4ConvC[0][0]',        \n",
            "                                )                                 'batchNorm4Copy[0][0]']         \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)                (None, 12, 12, 1024  0           ['add_7[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv4A (Conv2  (None, 12, 12, 256)  262400     ['re_lu_24[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv4A (Batc  (None, 12, 12, 256)  1024       ['resBlock4IdentityConv4A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4IdentityConv4A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv4B (Conv2  (None, 12, 12, 256)  590080     ['re_lu_25[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv4B (Batc  (None, 12, 12, 256)  1024       ['resBlock4IdentityConv4B[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4IdentityConv4B[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv4C (Conv2  (None, 12, 12, 1024  263168     ['re_lu_26[0][0]']               \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv4C (Batc  (None, 12, 12, 1024  4096       ['resBlock4IdentityConv4C[0][0]']\n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 12, 12, 1024  0           ['batchNorm4IdentityConv4C[0][0]'\n",
            "                                )                                , 're_lu_24[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_27 (ReLU)                (None, 12, 12, 1024  0           ['add_8[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv5A (Conv2  (None, 12, 12, 256)  262400     ['re_lu_27[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv5A (Batc  (None, 12, 12, 256)  1024       ['resBlock4IdentityConv5A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4IdentityConv5A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv5B (Conv2  (None, 12, 12, 256)  590080     ['re_lu_28[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv5B (Batc  (None, 12, 12, 256)  1024       ['resBlock4IdentityConv5B[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4IdentityConv5B[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv5C (Conv2  (None, 12, 12, 1024  263168     ['re_lu_29[0][0]']               \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv5C (Batc  (None, 12, 12, 1024  4096       ['resBlock4IdentityConv5C[0][0]']\n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 12, 12, 1024  0           ['batchNorm4IdentityConv5C[0][0]'\n",
            "                                )                                , 're_lu_27[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)                (None, 12, 12, 1024  0           ['add_9[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv6A (Conv2  (None, 12, 12, 256)  262400     ['re_lu_30[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv6A (Batc  (None, 12, 12, 256)  1024       ['resBlock4IdentityConv6A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4IdentityConv6A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv6B (Conv2  (None, 12, 12, 256)  590080     ['re_lu_31[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv6B (Batc  (None, 12, 12, 256)  1024       ['resBlock4IdentityConv6B[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_32 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4IdentityConv6B[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv6C (Conv2  (None, 12, 12, 1024  263168     ['re_lu_32[0][0]']               \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv6C (Batc  (None, 12, 12, 1024  4096       ['resBlock4IdentityConv6C[0][0]']\n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 12, 12, 1024  0           ['batchNorm4IdentityConv6C[0][0]'\n",
            "                                )                                , 're_lu_30[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_33 (ReLU)                (None, 12, 12, 1024  0           ['add_10[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv7A (Conv2  (None, 12, 12, 256)  262400     ['re_lu_33[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv7A (Batc  (None, 12, 12, 256)  1024       ['resBlock4IdentityConv7A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_34 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4IdentityConv7A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv7B (Conv2  (None, 12, 12, 1024  2360320    ['re_lu_34[0][0]']               \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv7B (Batc  (None, 12, 12, 1024  4096       ['resBlock4IdentityConv7B[0][0]']\n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " re_lu_35 (ReLU)                (None, 12, 12, 1024  0           ['batchNorm4IdentityConv7B[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv7C (Conv2  (None, 12, 12, 1024  1049600    ['re_lu_35[0][0]']               \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv7C (Batc  (None, 12, 12, 1024  4096       ['resBlock4IdentityConv7C[0][0]']\n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 12, 12, 1024  0           ['batchNorm4IdentityConv7C[0][0]'\n",
            "                                )                                , 're_lu_33[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_36 (ReLU)                (None, 12, 12, 1024  0           ['add_11[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv8A (Conv2  (None, 12, 12, 256)  262400     ['re_lu_36[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv8A (Batc  (None, 12, 12, 256)  1024       ['resBlock4IdentityConv8A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_37 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4IdentityConv8A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv8B (Conv2  (None, 12, 12, 256)  590080     ['re_lu_37[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv8B (Batc  (None, 12, 12, 256)  1024       ['resBlock4IdentityConv8B[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_38 (ReLU)                (None, 12, 12, 256)  0           ['batchNorm4IdentityConv8B[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock4IdentityConv8C (Conv2  (None, 12, 12, 1024  263168     ['re_lu_38[0][0]']               \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " batchNorm4IdentityConv8C (Batc  (None, 12, 12, 1024  4096       ['resBlock4IdentityConv8C[0][0]']\n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 12, 12, 1024  0           ['batchNorm4IdentityConv8C[0][0]'\n",
            "                                )                                , 're_lu_36[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_39 (ReLU)                (None, 12, 12, 1024  0           ['add_12[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " resBlock5ConvA (Conv2D)        (None, 6, 6, 512)    524800      ['re_lu_39[0][0]']               \n",
            "                                                                                                  \n",
            " batchNorm5ConvA (BatchNormaliz  (None, 6, 6, 512)   2048        ['resBlock5ConvA[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " re_lu_40 (ReLU)                (None, 6, 6, 512)    0           ['batchNorm5ConvA[0][0]']        \n",
            "                                                                                                  \n",
            " resBlock5ConvB (Conv2D)        (None, 6, 6, 512)    2359808     ['re_lu_40[0][0]']               \n",
            "                                                                                                  \n",
            " batchNorm5ConvB (BatchNormaliz  (None, 6, 6, 512)   2048        ['resBlock5ConvB[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " re_lu_41 (ReLU)                (None, 6, 6, 512)    0           ['batchNorm5ConvB[0][0]']        \n",
            "                                                                                                  \n",
            " resBlock5ConvC (Conv2D)        (None, 6, 6, 2048)   1050624     ['re_lu_41[0][0]']               \n",
            "                                                                                                  \n",
            " resBlock5Copy (Conv2D)         (None, 6, 6, 2048)   2099200     ['re_lu_39[0][0]']               \n",
            "                                                                                                  \n",
            " batchNorm5ConvC (BatchNormaliz  (None, 6, 6, 2048)  8192        ['resBlock5ConvC[0][0]']         \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " batchNorm5Copy (BatchNormaliza  (None, 6, 6, 2048)  8192        ['resBlock5Copy[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 6, 6, 2048)   0           ['batchNorm5ConvC[0][0]',        \n",
            "                                                                  'batchNorm5Copy[0][0]']         \n",
            "                                                                                                  \n",
            " re_lu_42 (ReLU)                (None, 6, 6, 2048)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " resBlock5IdentityConv9A (Conv2  (None, 6, 6, 512)   1049088     ['re_lu_42[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm5IdentityConv9A (Batc  (None, 6, 6, 512)   2048        ['resBlock5IdentityConv9A[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_43 (ReLU)                (None, 6, 6, 512)    0           ['batchNorm5IdentityConv9A[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock5IdentityConv9B (Conv2  (None, 6, 6, 512)   2359808     ['re_lu_43[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm5IdentityConv9B (Batc  (None, 6, 6, 512)   2048        ['resBlock5IdentityConv9B[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " re_lu_44 (ReLU)                (None, 6, 6, 512)    0           ['batchNorm5IdentityConv9B[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resBlock5IdentityConv9C (Conv2  (None, 6, 6, 2048)  1050624     ['re_lu_44[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batchNorm5IdentityConv9C (Batc  (None, 6, 6, 2048)  8192        ['resBlock5IdentityConv9C[0][0]']\n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 6, 6, 2048)   0           ['batchNorm5IdentityConv9C[0][0]'\n",
            "                                                                 , 're_lu_42[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_45 (ReLU)                (None, 6, 6, 2048)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " resBlock5IdentityConv10A (Conv  (None, 6, 6, 512)   1049088     ['re_lu_45[0][0]']               \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " batchNorm5IdentityConv10A (Bat  (None, 6, 6, 512)   2048        ['resBlock5IdentityConv10A[0][0]'\n",
            " chNormalization)                                                ]                                \n",
            "                                                                                                  \n",
            " re_lu_46 (ReLU)                (None, 6, 6, 512)    0           ['batchNorm5IdentityConv10A[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " resBlock5IdentityConv10B (Conv  (None, 6, 6, 512)   2359808     ['re_lu_46[0][0]']               \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " batchNorm5IdentityConv10B (Bat  (None, 6, 6, 512)   2048        ['resBlock5IdentityConv10B[0][0]'\n",
            " chNormalization)                                                ]                                \n",
            "                                                                                                  \n",
            " re_lu_47 (ReLU)                (None, 6, 6, 512)    0           ['batchNorm5IdentityConv10B[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " resBlock5IdentityConv10C (Conv  (None, 6, 6, 2048)  1050624     ['re_lu_47[0][0]']               \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " batchNorm5IdentityConv10C (Bat  (None, 6, 6, 2048)  8192        ['resBlock5IdentityConv10C[0][0]'\n",
            " chNormalization)                                                ]                                \n",
            "                                                                                                  \n",
            " AveragePooling (AveragePooling  (None, 3, 3, 2048)  0           ['batchNorm5IdentityConv10C[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 18432)        0           ['AveragePooling[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          9437696     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " re_lu_48 (ReLU)                (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 30)           15390       ['re_lu_48[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_49 (ReLU)                (None, 30)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 35,594,270\n",
            "Trainable params: 35,539,614\n",
            "Non-trainable params: 54,656\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os \n",
        "# os.environ['TF_KERAS'] = '1'\n",
        "\n",
        "# adam = tensorflow.keras.optimizers.Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
        "# save the best model with least validation loss\n",
        "res_net50.compile(loss = \"mean_squared_error\", optimizer = 'adam', metrics = ['accuracy', 'mse'])\n",
        "checkpoint = ModelCheckpoint(filepath = \"Best_weights.hdf5\", save_best_only=True)\n",
        "# Train the model\n",
        "history = res_net50.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=0.05, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIyxl5mhJkxk",
        "outputId": "eba19701-3b54-44ad-90cc-54ce332da34e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "97/97 [==============================] - 37s 201ms/step - loss: 206.3972 - accuracy: 0.4371 - mse: 206.3972 - val_loss: 798.9311 - val_accuracy: 0.1755 - val_mse: 798.9311\n",
            "Epoch 2/500\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 29.7346 - accuracy: 0.6900 - mse: 29.7346 - val_loss: 172.1685 - val_accuracy: 0.4477 - val_mse: 172.1685\n",
            "Epoch 3/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 16.5557 - accuracy: 0.7331 - mse: 16.5557 - val_loss: 35.7060 - val_accuracy: 0.4458 - val_mse: 35.7060\n",
            "Epoch 4/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 9.7538 - accuracy: 0.7745 - mse: 9.7538 - val_loss: 14.2096 - val_accuracy: 0.4438 - val_mse: 14.2096\n",
            "Epoch 5/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 8.0300 - accuracy: 0.7822 - mse: 8.0300 - val_loss: 15.1421 - val_accuracy: 0.4675 - val_mse: 15.1421\n",
            "Epoch 6/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 8.2308 - accuracy: 0.7835 - mse: 8.2308 - val_loss: 13.6486 - val_accuracy: 0.5286 - val_mse: 13.6486\n",
            "Epoch 7/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 6.5415 - accuracy: 0.7977 - mse: 6.5415 - val_loss: 12.6487 - val_accuracy: 0.4852 - val_mse: 12.6487\n",
            "Epoch 8/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 5.1963 - accuracy: 0.8110 - mse: 5.1963 - val_loss: 8.8475 - val_accuracy: 0.5917 - val_mse: 8.8475\n",
            "Epoch 9/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 4.2943 - accuracy: 0.8234 - mse: 4.2943 - val_loss: 10.8723 - val_accuracy: 0.5207 - val_mse: 10.8723\n",
            "Epoch 10/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 4.7254 - accuracy: 0.8247 - mse: 4.7254 - val_loss: 5.1366 - val_accuracy: 0.5819 - val_mse: 5.1366\n",
            "Epoch 11/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 3.4440 - accuracy: 0.8413 - mse: 3.4440 - val_loss: 4.7874 - val_accuracy: 0.5700 - val_mse: 4.7874\n",
            "Epoch 12/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 3.1655 - accuracy: 0.8453 - mse: 3.1655 - val_loss: 6.7896 - val_accuracy: 0.5542 - val_mse: 6.7896\n",
            "Epoch 13/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 3.1255 - accuracy: 0.8469 - mse: 3.1255 - val_loss: 8.3520 - val_accuracy: 0.5325 - val_mse: 8.3520\n",
            "Epoch 14/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.7509 - accuracy: 0.8526 - mse: 2.7509 - val_loss: 6.9676 - val_accuracy: 0.5424 - val_mse: 6.9676\n",
            "Epoch 15/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 2.6537 - accuracy: 0.8566 - mse: 2.6537 - val_loss: 4.3017 - val_accuracy: 0.6351 - val_mse: 4.3017\n",
            "Epoch 16/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.3649 - accuracy: 0.8611 - mse: 2.3649 - val_loss: 4.8088 - val_accuracy: 0.6982 - val_mse: 4.8088\n",
            "Epoch 17/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 2.2165 - accuracy: 0.8682 - mse: 2.2165 - val_loss: 4.0298 - val_accuracy: 0.7002 - val_mse: 4.0298\n",
            "Epoch 18/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 2.1708 - accuracy: 0.8732 - mse: 2.1708 - val_loss: 3.7716 - val_accuracy: 0.6647 - val_mse: 3.7716\n",
            "Epoch 19/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.0738 - accuracy: 0.8706 - mse: 2.0738 - val_loss: 4.3439 - val_accuracy: 0.6982 - val_mse: 4.3439\n",
            "Epoch 20/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.8891 - accuracy: 0.8804 - mse: 1.8891 - val_loss: 3.4700 - val_accuracy: 0.6726 - val_mse: 3.4700\n",
            "Epoch 21/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.7828 - accuracy: 0.8798 - mse: 1.7828 - val_loss: 3.3282 - val_accuracy: 0.7416 - val_mse: 3.3282\n",
            "Epoch 22/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.2958 - accuracy: 0.8809 - mse: 2.2958 - val_loss: 5.8269 - val_accuracy: 0.6252 - val_mse: 5.8269\n",
            "Epoch 23/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 2.7808 - accuracy: 0.8719 - mse: 2.7808 - val_loss: 2.8785 - val_accuracy: 0.7140 - val_mse: 2.8785\n",
            "Epoch 24/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.6348 - accuracy: 0.8923 - mse: 1.6348 - val_loss: 3.2890 - val_accuracy: 0.7081 - val_mse: 3.2890\n",
            "Epoch 25/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.7281 - accuracy: 0.8895 - mse: 1.7281 - val_loss: 2.6951 - val_accuracy: 0.7002 - val_mse: 2.6951\n",
            "Epoch 26/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.6463 - accuracy: 0.8934 - mse: 1.6463 - val_loss: 2.8934 - val_accuracy: 0.7692 - val_mse: 2.8934\n",
            "Epoch 27/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.4756 - accuracy: 0.8936 - mse: 1.4756 - val_loss: 4.1626 - val_accuracy: 0.6903 - val_mse: 4.1626\n",
            "Epoch 28/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.8412 - accuracy: 0.8975 - mse: 1.8412 - val_loss: 4.1111 - val_accuracy: 0.7160 - val_mse: 4.1111\n",
            "Epoch 29/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 1.5706 - accuracy: 0.8991 - mse: 1.5706 - val_loss: 2.1952 - val_accuracy: 0.7456 - val_mse: 2.1952\n",
            "Epoch 30/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.3564 - accuracy: 0.8939 - mse: 1.3564 - val_loss: 3.1966 - val_accuracy: 0.7101 - val_mse: 3.1966\n",
            "Epoch 31/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2008 - accuracy: 0.9153 - mse: 1.2008 - val_loss: 4.3963 - val_accuracy: 0.6726 - val_mse: 4.3963\n",
            "Epoch 32/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2803 - accuracy: 0.9037 - mse: 1.2803 - val_loss: 3.1522 - val_accuracy: 0.6647 - val_mse: 3.1522\n",
            "Epoch 33/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 1.1827 - accuracy: 0.9039 - mse: 1.1827 - val_loss: 1.8916 - val_accuracy: 0.7712 - val_mse: 1.8916\n",
            "Epoch 34/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2158 - accuracy: 0.9047 - mse: 1.2158 - val_loss: 2.1271 - val_accuracy: 0.6154 - val_mse: 2.1271\n",
            "Epoch 35/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2177 - accuracy: 0.9043 - mse: 1.2177 - val_loss: 3.4248 - val_accuracy: 0.7613 - val_mse: 3.4248\n",
            "Epoch 36/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.3893 - accuracy: 0.9055 - mse: 1.3893 - val_loss: 3.5828 - val_accuracy: 0.7337 - val_mse: 3.5828\n",
            "Epoch 37/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2429 - accuracy: 0.9049 - mse: 1.2429 - val_loss: 2.2872 - val_accuracy: 0.7653 - val_mse: 2.2872\n",
            "Epoch 38/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.4962 - accuracy: 0.9095 - mse: 1.4962 - val_loss: 8.4457 - val_accuracy: 0.6607 - val_mse: 8.4457\n",
            "Epoch 39/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.3564 - accuracy: 0.9047 - mse: 1.3564 - val_loss: 2.6946 - val_accuracy: 0.7416 - val_mse: 2.6946\n",
            "Epoch 40/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.0729 - accuracy: 0.9194 - mse: 1.0729 - val_loss: 2.4122 - val_accuracy: 0.7712 - val_mse: 2.4122\n",
            "Epoch 41/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.1167 - accuracy: 0.9123 - mse: 1.1167 - val_loss: 1.8526 - val_accuracy: 0.7396 - val_mse: 1.8526\n",
            "Epoch 42/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.0210 - accuracy: 0.9113 - mse: 1.0210 - val_loss: 1.7254 - val_accuracy: 0.6746 - val_mse: 1.7254\n",
            "Epoch 43/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2918 - accuracy: 0.9170 - mse: 1.2918 - val_loss: 2.2082 - val_accuracy: 0.7456 - val_mse: 2.2082\n",
            "Epoch 44/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2481 - accuracy: 0.9172 - mse: 1.2481 - val_loss: 3.4735 - val_accuracy: 0.7909 - val_mse: 3.4735\n",
            "Epoch 45/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.9505 - accuracy: 0.9204 - mse: 0.9505 - val_loss: 1.4742 - val_accuracy: 0.7298 - val_mse: 1.4742\n",
            "Epoch 46/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.8856 - accuracy: 0.9234 - mse: 0.8856 - val_loss: 2.2633 - val_accuracy: 0.7751 - val_mse: 2.2633\n",
            "Epoch 47/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9508 - accuracy: 0.9239 - mse: 0.9508 - val_loss: 2.1242 - val_accuracy: 0.8087 - val_mse: 2.1242\n",
            "Epoch 48/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.0904 - accuracy: 0.9142 - mse: 1.0904 - val_loss: 3.3722 - val_accuracy: 0.7732 - val_mse: 3.3722\n",
            "Epoch 49/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.1103 - accuracy: 0.9193 - mse: 1.1103 - val_loss: 2.4507 - val_accuracy: 0.7140 - val_mse: 2.4507\n",
            "Epoch 50/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.9852 - accuracy: 0.9228 - mse: 0.9852 - val_loss: 1.7339 - val_accuracy: 0.7791 - val_mse: 1.7339\n",
            "Epoch 51/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.1057 - accuracy: 0.9219 - mse: 1.1057 - val_loss: 5.0309 - val_accuracy: 0.7633 - val_mse: 5.0309\n",
            "Epoch 52/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.0508 - accuracy: 0.9235 - mse: 1.0508 - val_loss: 2.7985 - val_accuracy: 0.7239 - val_mse: 2.7985\n",
            "Epoch 53/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2786 - accuracy: 0.9222 - mse: 1.2786 - val_loss: 1.6522 - val_accuracy: 0.7239 - val_mse: 1.6522\n",
            "Epoch 54/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.8321 - accuracy: 0.9309 - mse: 0.8321 - val_loss: 1.3675 - val_accuracy: 0.7337 - val_mse: 1.3675\n",
            "Epoch 55/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.7397 - accuracy: 0.9290 - mse: 0.7397 - val_loss: 1.2167 - val_accuracy: 0.7791 - val_mse: 1.2167\n",
            "Epoch 56/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.8610 - accuracy: 0.9273 - mse: 0.8610 - val_loss: 1.4986 - val_accuracy: 0.6805 - val_mse: 1.4986\n",
            "Epoch 57/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9431 - accuracy: 0.9280 - mse: 0.9431 - val_loss: 1.9332 - val_accuracy: 0.8225 - val_mse: 1.9332\n",
            "Epoch 58/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.8990 - accuracy: 0.9229 - mse: 0.8990 - val_loss: 4.7202 - val_accuracy: 0.7890 - val_mse: 4.7202\n",
            "Epoch 59/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.6911 - accuracy: 0.9294 - mse: 0.6911 - val_loss: 1.3798 - val_accuracy: 0.8560 - val_mse: 1.3798\n",
            "Epoch 60/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.7422 - accuracy: 0.9308 - mse: 0.7422 - val_loss: 1.4316 - val_accuracy: 0.7890 - val_mse: 1.4316\n",
            "Epoch 61/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.7573 - accuracy: 0.9305 - mse: 0.7573 - val_loss: 1.8814 - val_accuracy: 0.7475 - val_mse: 1.8814\n",
            "Epoch 62/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.9095 - accuracy: 0.9342 - mse: 0.9095 - val_loss: 3.0570 - val_accuracy: 0.7890 - val_mse: 3.0570\n",
            "Epoch 63/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.9112 - accuracy: 0.9295 - mse: 0.9112 - val_loss: 1.8964 - val_accuracy: 0.7870 - val_mse: 1.8964\n",
            "Epoch 64/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.9218 - accuracy: 0.9258 - mse: 0.9218 - val_loss: 2.4164 - val_accuracy: 0.8107 - val_mse: 2.4164\n",
            "Epoch 65/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.8816 - accuracy: 0.9293 - mse: 0.8816 - val_loss: 1.3574 - val_accuracy: 0.8264 - val_mse: 1.3574\n",
            "Epoch 66/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9560 - accuracy: 0.9292 - mse: 0.9560 - val_loss: 1.3878 - val_accuracy: 0.7830 - val_mse: 1.3878\n",
            "Epoch 67/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.8248 - accuracy: 0.9293 - mse: 0.8248 - val_loss: 2.2549 - val_accuracy: 0.8107 - val_mse: 2.2549\n",
            "Epoch 68/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.7252 - accuracy: 0.9305 - mse: 0.7252 - val_loss: 1.4873 - val_accuracy: 0.7673 - val_mse: 1.4873\n",
            "Epoch 69/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.7197 - accuracy: 0.9356 - mse: 0.7197 - val_loss: 1.5453 - val_accuracy: 0.7613 - val_mse: 1.5453\n",
            "Epoch 70/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 63.5894 - accuracy: 0.6938 - mse: 63.5894 - val_loss: 3571981.7500 - val_accuracy: 0.0651 - val_mse: 3571981.7500\n",
            "Epoch 71/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 18.3520 - accuracy: 0.7271 - mse: 18.3520 - val_loss: 104.1119 - val_accuracy: 0.3866 - val_mse: 104.1119\n",
            "Epoch 72/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 10.4900 - accuracy: 0.7535 - mse: 10.4900 - val_loss: 14.5733 - val_accuracy: 0.5897 - val_mse: 14.5733\n",
            "Epoch 73/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 7.8268 - accuracy: 0.7696 - mse: 7.8268 - val_loss: 9.9585 - val_accuracy: 0.5030 - val_mse: 9.9585\n",
            "Epoch 74/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 6.1631 - accuracy: 0.7883 - mse: 6.1631 - val_loss: 9.6944 - val_accuracy: 0.5030 - val_mse: 9.6944\n",
            "Epoch 75/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 5.3957 - accuracy: 0.7924 - mse: 5.3957 - val_loss: 8.1821 - val_accuracy: 0.5286 - val_mse: 8.1821\n",
            "Epoch 76/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 4.8517 - accuracy: 0.8006 - mse: 4.8517 - val_loss: 10.1483 - val_accuracy: 0.5404 - val_mse: 10.1483\n",
            "Epoch 77/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 4.4805 - accuracy: 0.8035 - mse: 4.4805 - val_loss: 7.0732 - val_accuracy: 0.5621 - val_mse: 7.0732\n",
            "Epoch 78/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 4.3403 - accuracy: 0.8091 - mse: 4.3403 - val_loss: 7.3308 - val_accuracy: 0.5187 - val_mse: 7.3308\n",
            "Epoch 79/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 3.8842 - accuracy: 0.8190 - mse: 3.8842 - val_loss: 6.1291 - val_accuracy: 0.5187 - val_mse: 6.1291\n",
            "Epoch 80/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 3.5955 - accuracy: 0.8232 - mse: 3.5955 - val_loss: 6.6073 - val_accuracy: 0.5976 - val_mse: 6.6073\n",
            "Epoch 81/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 3.3779 - accuracy: 0.8280 - mse: 3.3779 - val_loss: 5.4261 - val_accuracy: 0.5740 - val_mse: 5.4261\n",
            "Epoch 82/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 3.2078 - accuracy: 0.8311 - mse: 3.2078 - val_loss: 5.1979 - val_accuracy: 0.5266 - val_mse: 5.1979\n",
            "Epoch 83/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 3.0004 - accuracy: 0.8337 - mse: 3.0004 - val_loss: 5.5933 - val_accuracy: 0.5128 - val_mse: 5.5933\n",
            "Epoch 84/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.8609 - accuracy: 0.8403 - mse: 2.8609 - val_loss: 4.5416 - val_accuracy: 0.6292 - val_mse: 4.5416\n",
            "Epoch 85/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.7141 - accuracy: 0.8442 - mse: 2.7141 - val_loss: 5.2890 - val_accuracy: 0.6469 - val_mse: 5.2890\n",
            "Epoch 86/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.5953 - accuracy: 0.8494 - mse: 2.5953 - val_loss: 4.2306 - val_accuracy: 0.5523 - val_mse: 4.2306\n",
            "Epoch 87/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.4765 - accuracy: 0.8473 - mse: 2.4765 - val_loss: 4.7789 - val_accuracy: 0.5562 - val_mse: 4.7789\n",
            "Epoch 88/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.4011 - accuracy: 0.8579 - mse: 2.4011 - val_loss: 3.4764 - val_accuracy: 0.6706 - val_mse: 3.4764\n",
            "Epoch 89/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.2805 - accuracy: 0.8566 - mse: 2.2805 - val_loss: 3.3783 - val_accuracy: 0.6213 - val_mse: 3.3783\n",
            "Epoch 90/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.3620 - accuracy: 0.8524 - mse: 2.3620 - val_loss: 3.9297 - val_accuracy: 0.5720 - val_mse: 3.9297\n",
            "Epoch 91/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 2.1310 - accuracy: 0.8552 - mse: 2.1310 - val_loss: 3.1104 - val_accuracy: 0.6331 - val_mse: 3.1104\n",
            "Epoch 92/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.9919 - accuracy: 0.8616 - mse: 1.9919 - val_loss: 3.7556 - val_accuracy: 0.5641 - val_mse: 3.7556\n",
            "Epoch 93/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.0973 - accuracy: 0.8621 - mse: 2.0973 - val_loss: 3.5199 - val_accuracy: 0.5976 - val_mse: 3.5199\n",
            "Epoch 94/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.9384 - accuracy: 0.8656 - mse: 1.9384 - val_loss: 3.8455 - val_accuracy: 0.6746 - val_mse: 3.8455\n",
            "Epoch 95/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 2.0224 - accuracy: 0.8599 - mse: 2.0224 - val_loss: 3.9310 - val_accuracy: 0.6095 - val_mse: 3.9310\n",
            "Epoch 96/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.8576 - accuracy: 0.8683 - mse: 1.8576 - val_loss: 3.3599 - val_accuracy: 0.6331 - val_mse: 3.3599\n",
            "Epoch 97/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.7964 - accuracy: 0.8695 - mse: 1.7964 - val_loss: 3.0879 - val_accuracy: 0.6469 - val_mse: 3.0879\n",
            "Epoch 98/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.6784 - accuracy: 0.8703 - mse: 1.6784 - val_loss: 2.6461 - val_accuracy: 0.6667 - val_mse: 2.6461\n",
            "Epoch 99/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.8260 - accuracy: 0.8763 - mse: 1.8260 - val_loss: 3.6077 - val_accuracy: 0.6884 - val_mse: 3.6077\n",
            "Epoch 100/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.7602 - accuracy: 0.8755 - mse: 1.7602 - val_loss: 2.7004 - val_accuracy: 0.6568 - val_mse: 2.7004\n",
            "Epoch 101/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.6185 - accuracy: 0.8761 - mse: 1.6185 - val_loss: 3.2611 - val_accuracy: 0.7258 - val_mse: 3.2611\n",
            "Epoch 102/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.4744 - accuracy: 0.8765 - mse: 1.4744 - val_loss: 2.7891 - val_accuracy: 0.7120 - val_mse: 2.7891\n",
            "Epoch 103/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.4103 - accuracy: 0.8860 - mse: 1.4103 - val_loss: 3.3637 - val_accuracy: 0.6193 - val_mse: 3.3637\n",
            "Epoch 104/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.5969 - accuracy: 0.8804 - mse: 1.5969 - val_loss: 3.6891 - val_accuracy: 0.6903 - val_mse: 3.6891\n",
            "Epoch 105/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.5273 - accuracy: 0.8853 - mse: 1.5273 - val_loss: 2.6699 - val_accuracy: 0.6785 - val_mse: 2.6699\n",
            "Epoch 106/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.4528 - accuracy: 0.8916 - mse: 1.4528 - val_loss: 2.4289 - val_accuracy: 0.7377 - val_mse: 2.4289\n",
            "Epoch 107/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.3998 - accuracy: 0.8851 - mse: 1.3998 - val_loss: 2.8469 - val_accuracy: 0.6489 - val_mse: 2.8469\n",
            "Epoch 108/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.3073 - accuracy: 0.8947 - mse: 1.3073 - val_loss: 2.1305 - val_accuracy: 0.6943 - val_mse: 2.1305\n",
            "Epoch 109/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2963 - accuracy: 0.8881 - mse: 1.2963 - val_loss: 3.0324 - val_accuracy: 0.6686 - val_mse: 3.0324\n",
            "Epoch 110/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.3170 - accuracy: 0.8898 - mse: 1.3170 - val_loss: 2.2821 - val_accuracy: 0.7179 - val_mse: 2.2821\n",
            "Epoch 111/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.1938 - accuracy: 0.8988 - mse: 1.1938 - val_loss: 2.4286 - val_accuracy: 0.6765 - val_mse: 2.4286\n",
            "Epoch 112/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.2374 - accuracy: 0.8995 - mse: 1.2374 - val_loss: 2.9965 - val_accuracy: 0.7140 - val_mse: 2.9965\n",
            "Epoch 113/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.3838 - accuracy: 0.8961 - mse: 1.3838 - val_loss: 3.7939 - val_accuracy: 0.7495 - val_mse: 3.7939\n",
            "Epoch 114/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.3765 - accuracy: 0.8923 - mse: 1.3765 - val_loss: 2.0601 - val_accuracy: 0.7179 - val_mse: 2.0601\n",
            "Epoch 115/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.2017 - accuracy: 0.8938 - mse: 1.2017 - val_loss: 2.2198 - val_accuracy: 0.6864 - val_mse: 2.2198\n",
            "Epoch 116/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.0765 - accuracy: 0.9064 - mse: 1.0765 - val_loss: 1.9000 - val_accuracy: 0.7653 - val_mse: 1.9000\n",
            "Epoch 117/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 1.0521 - accuracy: 0.9037 - mse: 1.0521 - val_loss: 1.9335 - val_accuracy: 0.7278 - val_mse: 1.9335\n",
            "Epoch 118/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 1.0452 - accuracy: 0.9037 - mse: 1.0452 - val_loss: 2.2098 - val_accuracy: 0.7732 - val_mse: 2.2098\n",
            "Epoch 119/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9927 - accuracy: 0.9117 - mse: 0.9927 - val_loss: 1.7170 - val_accuracy: 0.7673 - val_mse: 1.7170\n",
            "Epoch 120/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9983 - accuracy: 0.9141 - mse: 0.9983 - val_loss: 1.6369 - val_accuracy: 0.7318 - val_mse: 1.6369\n",
            "Epoch 121/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9790 - accuracy: 0.9071 - mse: 0.9790 - val_loss: 1.9984 - val_accuracy: 0.6233 - val_mse: 1.9984\n",
            "Epoch 122/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9914 - accuracy: 0.9095 - mse: 0.9914 - val_loss: 1.9295 - val_accuracy: 0.7988 - val_mse: 1.9295\n",
            "Epoch 123/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.8884 - accuracy: 0.9179 - mse: 0.8884 - val_loss: 1.4570 - val_accuracy: 0.7692 - val_mse: 1.4570\n",
            "Epoch 124/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9188 - accuracy: 0.9167 - mse: 0.9188 - val_loss: 1.8204 - val_accuracy: 0.6903 - val_mse: 1.8204\n",
            "Epoch 125/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9333 - accuracy: 0.9155 - mse: 0.9333 - val_loss: 2.2444 - val_accuracy: 0.7377 - val_mse: 2.2444\n",
            "Epoch 126/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9928 - accuracy: 0.9148 - mse: 0.9928 - val_loss: 1.5734 - val_accuracy: 0.6923 - val_mse: 1.5734\n",
            "Epoch 127/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.8992 - accuracy: 0.9145 - mse: 0.8992 - val_loss: 2.0213 - val_accuracy: 0.7416 - val_mse: 2.0213\n",
            "Epoch 128/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.9422 - accuracy: 0.9181 - mse: 0.9422 - val_loss: 1.3322 - val_accuracy: 0.7988 - val_mse: 1.3322\n",
            "Epoch 129/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.8180 - accuracy: 0.9233 - mse: 0.8180 - val_loss: 1.4117 - val_accuracy: 0.7574 - val_mse: 1.4117\n",
            "Epoch 130/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.7472 - accuracy: 0.9243 - mse: 0.7472 - val_loss: 1.3815 - val_accuracy: 0.8323 - val_mse: 1.3815\n",
            "Epoch 131/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.9337 - accuracy: 0.9162 - mse: 0.9337 - val_loss: 2.0273 - val_accuracy: 0.7318 - val_mse: 2.0273\n",
            "Epoch 132/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.8544 - accuracy: 0.9187 - mse: 0.8544 - val_loss: 2.5130 - val_accuracy: 0.7515 - val_mse: 2.5130\n",
            "Epoch 133/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.7828 - accuracy: 0.9219 - mse: 0.7828 - val_loss: 1.3677 - val_accuracy: 0.8284 - val_mse: 1.3677\n",
            "Epoch 134/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.7560 - accuracy: 0.9222 - mse: 0.7560 - val_loss: 1.2207 - val_accuracy: 0.6489 - val_mse: 1.2207\n",
            "Epoch 135/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.7693 - accuracy: 0.9263 - mse: 0.7693 - val_loss: 1.3899 - val_accuracy: 0.7495 - val_mse: 1.3899\n",
            "Epoch 136/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.8175 - accuracy: 0.9285 - mse: 0.8175 - val_loss: 1.6934 - val_accuracy: 0.8383 - val_mse: 1.6934\n",
            "Epoch 137/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.8226 - accuracy: 0.9239 - mse: 0.8226 - val_loss: 1.2606 - val_accuracy: 0.7732 - val_mse: 1.2606\n",
            "Epoch 138/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.7621 - accuracy: 0.9253 - mse: 0.7621 - val_loss: 2.6253 - val_accuracy: 0.7771 - val_mse: 2.6253\n",
            "Epoch 139/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.7366 - accuracy: 0.9263 - mse: 0.7366 - val_loss: 1.3969 - val_accuracy: 0.7357 - val_mse: 1.3969\n",
            "Epoch 140/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.8239 - accuracy: 0.9209 - mse: 0.8239 - val_loss: 1.7985 - val_accuracy: 0.7239 - val_mse: 1.7985\n",
            "Epoch 141/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.7695 - accuracy: 0.9219 - mse: 0.7695 - val_loss: 1.2092 - val_accuracy: 0.8521 - val_mse: 1.2092\n",
            "Epoch 142/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.6696 - accuracy: 0.9290 - mse: 0.6696 - val_loss: 1.5643 - val_accuracy: 0.8245 - val_mse: 1.5643\n",
            "Epoch 143/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.8328 - accuracy: 0.9273 - mse: 0.8328 - val_loss: 1.3668 - val_accuracy: 0.7416 - val_mse: 1.3668\n",
            "Epoch 144/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.8231 - accuracy: 0.9256 - mse: 0.8231 - val_loss: 1.3728 - val_accuracy: 0.8047 - val_mse: 1.3728\n",
            "Epoch 145/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.7789 - accuracy: 0.9259 - mse: 0.7789 - val_loss: 1.2574 - val_accuracy: 0.7830 - val_mse: 1.2574\n",
            "Epoch 146/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.6860 - accuracy: 0.9285 - mse: 0.6860 - val_loss: 1.4313 - val_accuracy: 0.7515 - val_mse: 1.4313\n",
            "Epoch 147/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.7928 - accuracy: 0.9236 - mse: 0.7928 - val_loss: 1.0550 - val_accuracy: 0.7968 - val_mse: 1.0550\n",
            "Epoch 148/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.7235 - accuracy: 0.9249 - mse: 0.7235 - val_loss: 4.9018 - val_accuracy: 0.7594 - val_mse: 4.9018\n",
            "Epoch 149/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.8655 - accuracy: 0.9269 - mse: 0.8655 - val_loss: 1.1651 - val_accuracy: 0.7613 - val_mse: 1.1651\n",
            "Epoch 150/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.6671 - accuracy: 0.9348 - mse: 0.6671 - val_loss: 1.4229 - val_accuracy: 0.7692 - val_mse: 1.4229\n",
            "Epoch 151/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.7294 - accuracy: 0.9320 - mse: 0.7294 - val_loss: 1.1628 - val_accuracy: 0.8047 - val_mse: 1.1628\n",
            "Epoch 152/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.6878 - accuracy: 0.9296 - mse: 0.6878 - val_loss: 1.1506 - val_accuracy: 0.8442 - val_mse: 1.1506\n",
            "Epoch 153/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.6136 - accuracy: 0.9295 - mse: 0.6136 - val_loss: 2.3550 - val_accuracy: 0.7613 - val_mse: 2.3550\n",
            "Epoch 154/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.5790 - accuracy: 0.9382 - mse: 0.5790 - val_loss: 1.5532 - val_accuracy: 0.8087 - val_mse: 1.5532\n",
            "Epoch 155/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.6013 - accuracy: 0.9317 - mse: 0.6013 - val_loss: 0.8980 - val_accuracy: 0.8757 - val_mse: 0.8980\n",
            "Epoch 156/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.6295 - accuracy: 0.9357 - mse: 0.6295 - val_loss: 1.2036 - val_accuracy: 0.7890 - val_mse: 1.2036\n",
            "Epoch 157/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.6853 - accuracy: 0.9304 - mse: 0.6853 - val_loss: 2.0158 - val_accuracy: 0.7949 - val_mse: 2.0158\n",
            "Epoch 158/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.5594 - accuracy: 0.9328 - mse: 0.5594 - val_loss: 0.8404 - val_accuracy: 0.8422 - val_mse: 0.8404\n",
            "Epoch 159/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.5707 - accuracy: 0.9422 - mse: 0.5707 - val_loss: 0.9144 - val_accuracy: 0.7811 - val_mse: 0.9144\n",
            "Epoch 160/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.6221 - accuracy: 0.9353 - mse: 0.6221 - val_loss: 1.6592 - val_accuracy: 0.8067 - val_mse: 1.6592\n",
            "Epoch 161/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.5152 - accuracy: 0.9319 - mse: 0.5152 - val_loss: 0.9623 - val_accuracy: 0.8028 - val_mse: 0.9623\n",
            "Epoch 162/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4985 - accuracy: 0.9448 - mse: 0.4985 - val_loss: 0.8743 - val_accuracy: 0.7850 - val_mse: 0.8743\n",
            "Epoch 163/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.5388 - accuracy: 0.9422 - mse: 0.5388 - val_loss: 0.8002 - val_accuracy: 0.8521 - val_mse: 0.8002\n",
            "Epoch 164/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.5080 - accuracy: 0.9384 - mse: 0.5080 - val_loss: 1.2685 - val_accuracy: 0.8008 - val_mse: 1.2685\n",
            "Epoch 165/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4963 - accuracy: 0.9417 - mse: 0.4963 - val_loss: 2.4558 - val_accuracy: 0.8008 - val_mse: 2.4558\n",
            "Epoch 166/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.5475 - accuracy: 0.9419 - mse: 0.5475 - val_loss: 1.0546 - val_accuracy: 0.8185 - val_mse: 1.0546\n",
            "Epoch 167/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.5736 - accuracy: 0.9399 - mse: 0.5736 - val_loss: 1.3262 - val_accuracy: 0.7771 - val_mse: 1.3262\n",
            "Epoch 168/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4802 - accuracy: 0.9415 - mse: 0.4802 - val_loss: 2.0818 - val_accuracy: 0.8126 - val_mse: 2.0818\n",
            "Epoch 169/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.6499 - accuracy: 0.9293 - mse: 0.6499 - val_loss: 0.8910 - val_accuracy: 0.8166 - val_mse: 0.8910\n",
            "Epoch 170/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4506 - accuracy: 0.9471 - mse: 0.4506 - val_loss: 0.8422 - val_accuracy: 0.8560 - val_mse: 0.8422\n",
            "Epoch 171/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.4471 - accuracy: 0.9420 - mse: 0.4471 - val_loss: 0.7364 - val_accuracy: 0.7909 - val_mse: 0.7364\n",
            "Epoch 172/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4008 - accuracy: 0.9492 - mse: 0.4008 - val_loss: 0.9960 - val_accuracy: 0.7554 - val_mse: 0.9960\n",
            "Epoch 173/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4551 - accuracy: 0.9474 - mse: 0.4551 - val_loss: 1.3753 - val_accuracy: 0.8560 - val_mse: 1.3753\n",
            "Epoch 174/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.5118 - accuracy: 0.9367 - mse: 0.5118 - val_loss: 1.3025 - val_accuracy: 0.8107 - val_mse: 1.3025\n",
            "Epoch 175/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4621 - accuracy: 0.9393 - mse: 0.4621 - val_loss: 0.8731 - val_accuracy: 0.8659 - val_mse: 0.8731\n",
            "Epoch 176/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.5818 - accuracy: 0.9423 - mse: 0.5818 - val_loss: 1.6823 - val_accuracy: 0.7751 - val_mse: 1.6823\n",
            "Epoch 177/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.5954 - accuracy: 0.9409 - mse: 0.5954 - val_loss: 1.0344 - val_accuracy: 0.8600 - val_mse: 1.0344\n",
            "Epoch 178/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4405 - accuracy: 0.9431 - mse: 0.4405 - val_loss: 1.1339 - val_accuracy: 0.8245 - val_mse: 1.1339\n",
            "Epoch 179/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4680 - accuracy: 0.9475 - mse: 0.4680 - val_loss: 0.9287 - val_accuracy: 0.8639 - val_mse: 0.9287\n",
            "Epoch 180/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.5130 - accuracy: 0.9417 - mse: 0.5130 - val_loss: 0.7493 - val_accuracy: 0.8205 - val_mse: 0.7493\n",
            "Epoch 181/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4196 - accuracy: 0.9477 - mse: 0.4196 - val_loss: 0.8061 - val_accuracy: 0.7751 - val_mse: 0.8061\n",
            "Epoch 182/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4049 - accuracy: 0.9463 - mse: 0.4049 - val_loss: 0.9411 - val_accuracy: 0.8600 - val_mse: 0.9411\n",
            "Epoch 183/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4290 - accuracy: 0.9471 - mse: 0.4290 - val_loss: 0.7821 - val_accuracy: 0.7949 - val_mse: 0.7821\n",
            "Epoch 184/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4326 - accuracy: 0.9489 - mse: 0.4326 - val_loss: 0.7500 - val_accuracy: 0.8166 - val_mse: 0.7500\n",
            "Epoch 185/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3871 - accuracy: 0.9463 - mse: 0.3871 - val_loss: 1.1912 - val_accuracy: 0.8402 - val_mse: 1.1912\n",
            "Epoch 186/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4713 - accuracy: 0.9463 - mse: 0.4713 - val_loss: 0.7554 - val_accuracy: 0.8067 - val_mse: 0.7554\n",
            "Epoch 187/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3811 - accuracy: 0.9516 - mse: 0.3811 - val_loss: 1.3317 - val_accuracy: 0.8639 - val_mse: 1.3317\n",
            "Epoch 188/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4349 - accuracy: 0.9501 - mse: 0.4349 - val_loss: 1.1492 - val_accuracy: 0.8757 - val_mse: 1.1492\n",
            "Epoch 189/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4008 - accuracy: 0.9494 - mse: 0.4008 - val_loss: 0.9020 - val_accuracy: 0.8679 - val_mse: 0.9020\n",
            "Epoch 190/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4093 - accuracy: 0.9493 - mse: 0.4093 - val_loss: 0.8281 - val_accuracy: 0.7890 - val_mse: 0.8281\n",
            "Epoch 191/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.3496 - accuracy: 0.9590 - mse: 0.3496 - val_loss: 0.7018 - val_accuracy: 0.8540 - val_mse: 0.7018\n",
            "Epoch 192/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3770 - accuracy: 0.9543 - mse: 0.3770 - val_loss: 1.2137 - val_accuracy: 0.8422 - val_mse: 1.2137\n",
            "Epoch 193/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3885 - accuracy: 0.9465 - mse: 0.3885 - val_loss: 0.7289 - val_accuracy: 0.8718 - val_mse: 0.7289\n",
            "Epoch 194/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3312 - accuracy: 0.9494 - mse: 0.3312 - val_loss: 0.8930 - val_accuracy: 0.8659 - val_mse: 0.8930\n",
            "Epoch 195/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.3907 - accuracy: 0.9488 - mse: 0.3907 - val_loss: 0.5462 - val_accuracy: 0.8698 - val_mse: 0.5462\n",
            "Epoch 196/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4388 - accuracy: 0.9498 - mse: 0.4388 - val_loss: 0.7426 - val_accuracy: 0.8501 - val_mse: 0.7426\n",
            "Epoch 197/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4814 - accuracy: 0.9471 - mse: 0.4814 - val_loss: 0.9746 - val_accuracy: 0.8481 - val_mse: 0.9746\n",
            "Epoch 198/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4291 - accuracy: 0.9479 - mse: 0.4291 - val_loss: 0.7217 - val_accuracy: 0.8402 - val_mse: 0.7217\n",
            "Epoch 199/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3671 - accuracy: 0.9568 - mse: 0.3671 - val_loss: 0.6875 - val_accuracy: 0.7712 - val_mse: 0.6875\n",
            "Epoch 200/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3811 - accuracy: 0.9519 - mse: 0.3811 - val_loss: 0.6548 - val_accuracy: 0.8540 - val_mse: 0.6548\n",
            "Epoch 201/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4024 - accuracy: 0.9506 - mse: 0.4024 - val_loss: 1.4532 - val_accuracy: 0.7949 - val_mse: 1.4532\n",
            "Epoch 202/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3358 - accuracy: 0.9512 - mse: 0.3358 - val_loss: 0.5925 - val_accuracy: 0.8797 - val_mse: 0.5925\n",
            "Epoch 203/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3401 - accuracy: 0.9517 - mse: 0.3401 - val_loss: 0.9445 - val_accuracy: 0.8659 - val_mse: 0.9445\n",
            "Epoch 204/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.3633 - accuracy: 0.9440 - mse: 0.3633 - val_loss: 0.5256 - val_accuracy: 0.8935 - val_mse: 0.5256\n",
            "Epoch 205/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2885 - accuracy: 0.9584 - mse: 0.2885 - val_loss: 0.5941 - val_accuracy: 0.8402 - val_mse: 0.5941\n",
            "Epoch 206/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3621 - accuracy: 0.9530 - mse: 0.3621 - val_loss: 0.6076 - val_accuracy: 0.9034 - val_mse: 0.6076\n",
            "Epoch 207/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3890 - accuracy: 0.9553 - mse: 0.3890 - val_loss: 0.7760 - val_accuracy: 0.7949 - val_mse: 0.7760\n",
            "Epoch 208/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3261 - accuracy: 0.9550 - mse: 0.3261 - val_loss: 0.9573 - val_accuracy: 0.8343 - val_mse: 0.9573\n",
            "Epoch 209/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4155 - accuracy: 0.9498 - mse: 0.4155 - val_loss: 1.1950 - val_accuracy: 0.8817 - val_mse: 1.1950\n",
            "Epoch 210/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.2889 - accuracy: 0.9591 - mse: 0.2889 - val_loss: 0.5065 - val_accuracy: 0.8856 - val_mse: 0.5065\n",
            "Epoch 211/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2940 - accuracy: 0.9553 - mse: 0.2940 - val_loss: 0.5696 - val_accuracy: 0.8856 - val_mse: 0.5696\n",
            "Epoch 212/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2856 - accuracy: 0.9566 - mse: 0.2856 - val_loss: 0.7760 - val_accuracy: 0.8915 - val_mse: 0.7760\n",
            "Epoch 213/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2897 - accuracy: 0.9618 - mse: 0.2897 - val_loss: 0.7224 - val_accuracy: 0.8501 - val_mse: 0.7224\n",
            "Epoch 214/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.2513 - accuracy: 0.9623 - mse: 0.2513 - val_loss: 0.4634 - val_accuracy: 0.8856 - val_mse: 0.4634\n",
            "Epoch 215/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2739 - accuracy: 0.9574 - mse: 0.2739 - val_loss: 0.5829 - val_accuracy: 0.8442 - val_mse: 0.5829\n",
            "Epoch 216/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2986 - accuracy: 0.9588 - mse: 0.2986 - val_loss: 0.6465 - val_accuracy: 0.8580 - val_mse: 0.6465\n",
            "Epoch 217/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2775 - accuracy: 0.9590 - mse: 0.2775 - val_loss: 0.5769 - val_accuracy: 0.8560 - val_mse: 0.5769\n",
            "Epoch 218/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2983 - accuracy: 0.9567 - mse: 0.2983 - val_loss: 0.5420 - val_accuracy: 0.8639 - val_mse: 0.5420\n",
            "Epoch 219/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2709 - accuracy: 0.9583 - mse: 0.2709 - val_loss: 0.8043 - val_accuracy: 0.8580 - val_mse: 0.8043\n",
            "Epoch 220/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2809 - accuracy: 0.9571 - mse: 0.2809 - val_loss: 0.5919 - val_accuracy: 0.8540 - val_mse: 0.5919\n",
            "Epoch 221/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2894 - accuracy: 0.9603 - mse: 0.2894 - val_loss: 0.5715 - val_accuracy: 0.8698 - val_mse: 0.5715\n",
            "Epoch 222/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3477 - accuracy: 0.9565 - mse: 0.3477 - val_loss: 0.5560 - val_accuracy: 0.8777 - val_mse: 0.5560\n",
            "Epoch 223/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3154 - accuracy: 0.9572 - mse: 0.3154 - val_loss: 0.5500 - val_accuracy: 0.8876 - val_mse: 0.5500\n",
            "Epoch 224/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3599 - accuracy: 0.9533 - mse: 0.3599 - val_loss: 0.6005 - val_accuracy: 0.8402 - val_mse: 0.6005\n",
            "Epoch 225/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3537 - accuracy: 0.9581 - mse: 0.3537 - val_loss: 0.7106 - val_accuracy: 0.8540 - val_mse: 0.7106\n",
            "Epoch 226/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3961 - accuracy: 0.9546 - mse: 0.3961 - val_loss: 0.6700 - val_accuracy: 0.8363 - val_mse: 0.6700\n",
            "Epoch 227/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.4231 - accuracy: 0.9422 - mse: 0.4231 - val_loss: 0.5544 - val_accuracy: 0.7791 - val_mse: 0.5544\n",
            "Epoch 228/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.2859 - accuracy: 0.9578 - mse: 0.2859 - val_loss: 0.4296 - val_accuracy: 0.8797 - val_mse: 0.4296\n",
            "Epoch 229/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2503 - accuracy: 0.9632 - mse: 0.2503 - val_loss: 0.6255 - val_accuracy: 0.8540 - val_mse: 0.6255\n",
            "Epoch 230/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2601 - accuracy: 0.9605 - mse: 0.2601 - val_loss: 0.4877 - val_accuracy: 0.8994 - val_mse: 0.4877\n",
            "Epoch 231/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2882 - accuracy: 0.9601 - mse: 0.2882 - val_loss: 0.6028 - val_accuracy: 0.8245 - val_mse: 0.6028\n",
            "Epoch 232/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2486 - accuracy: 0.9634 - mse: 0.2486 - val_loss: 0.7180 - val_accuracy: 0.8639 - val_mse: 0.7180\n",
            "Epoch 233/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3106 - accuracy: 0.9599 - mse: 0.3106 - val_loss: 0.6784 - val_accuracy: 0.8600 - val_mse: 0.6784\n",
            "Epoch 234/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2660 - accuracy: 0.9620 - mse: 0.2660 - val_loss: 0.4998 - val_accuracy: 0.8915 - val_mse: 0.4998\n",
            "Epoch 235/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2640 - accuracy: 0.9609 - mse: 0.2640 - val_loss: 0.4609 - val_accuracy: 0.9172 - val_mse: 0.4609\n",
            "Epoch 236/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.2638 - accuracy: 0.9568 - mse: 0.2638 - val_loss: 0.4210 - val_accuracy: 0.8521 - val_mse: 0.4210\n",
            "Epoch 237/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2976 - accuracy: 0.9567 - mse: 0.2976 - val_loss: 0.9746 - val_accuracy: 0.8600 - val_mse: 0.9746\n",
            "Epoch 238/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.2424 - accuracy: 0.9625 - mse: 0.2424 - val_loss: 0.4068 - val_accuracy: 0.8935 - val_mse: 0.4068\n",
            "Epoch 239/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2506 - accuracy: 0.9636 - mse: 0.2506 - val_loss: 0.4748 - val_accuracy: 0.8738 - val_mse: 0.4748\n",
            "Epoch 240/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2177 - accuracy: 0.9616 - mse: 0.2177 - val_loss: 0.9494 - val_accuracy: 0.9014 - val_mse: 0.9494\n",
            "Epoch 241/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3353 - accuracy: 0.9607 - mse: 0.3353 - val_loss: 0.6539 - val_accuracy: 0.8402 - val_mse: 0.6539\n",
            "Epoch 242/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2475 - accuracy: 0.9566 - mse: 0.2475 - val_loss: 0.4926 - val_accuracy: 0.8698 - val_mse: 0.4926\n",
            "Epoch 243/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2687 - accuracy: 0.9627 - mse: 0.2687 - val_loss: 0.4671 - val_accuracy: 0.8718 - val_mse: 0.4671\n",
            "Epoch 244/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2630 - accuracy: 0.9594 - mse: 0.2630 - val_loss: 0.5117 - val_accuracy: 0.8994 - val_mse: 0.5117\n",
            "Epoch 245/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2162 - accuracy: 0.9648 - mse: 0.2162 - val_loss: 0.4664 - val_accuracy: 0.9053 - val_mse: 0.4664\n",
            "Epoch 246/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2193 - accuracy: 0.9621 - mse: 0.2193 - val_loss: 0.4609 - val_accuracy: 0.8304 - val_mse: 0.4609\n",
            "Epoch 247/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2522 - accuracy: 0.9633 - mse: 0.2522 - val_loss: 0.6186 - val_accuracy: 0.8738 - val_mse: 0.6186\n",
            "Epoch 248/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2898 - accuracy: 0.9577 - mse: 0.2898 - val_loss: 0.5662 - val_accuracy: 0.8560 - val_mse: 0.5662\n",
            "Epoch 249/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2476 - accuracy: 0.9594 - mse: 0.2476 - val_loss: 0.4385 - val_accuracy: 0.9014 - val_mse: 0.4385\n",
            "Epoch 250/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1972 - accuracy: 0.9662 - mse: 0.1972 - val_loss: 0.4610 - val_accuracy: 0.8619 - val_mse: 0.4610\n",
            "Epoch 251/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3060 - accuracy: 0.9626 - mse: 0.3060 - val_loss: 0.6246 - val_accuracy: 0.8304 - val_mse: 0.6246\n",
            "Epoch 252/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2483 - accuracy: 0.9618 - mse: 0.2483 - val_loss: 0.6351 - val_accuracy: 0.8442 - val_mse: 0.6351\n",
            "Epoch 253/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2112 - accuracy: 0.9654 - mse: 0.2112 - val_loss: 1.1484 - val_accuracy: 0.8343 - val_mse: 1.1484\n",
            "Epoch 254/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.3028 - accuracy: 0.9658 - mse: 0.3028 - val_loss: 1.3291 - val_accuracy: 0.8856 - val_mse: 1.3291\n",
            "Epoch 255/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.3036 - accuracy: 0.9597 - mse: 0.3036 - val_loss: 0.3660 - val_accuracy: 0.8856 - val_mse: 0.3660\n",
            "Epoch 256/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1701 - accuracy: 0.9670 - mse: 0.1701 - val_loss: 0.4262 - val_accuracy: 0.9014 - val_mse: 0.4262\n",
            "Epoch 257/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2082 - accuracy: 0.9683 - mse: 0.2082 - val_loss: 0.4221 - val_accuracy: 0.9112 - val_mse: 0.4221\n",
            "Epoch 258/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2122 - accuracy: 0.9669 - mse: 0.2122 - val_loss: 0.4741 - val_accuracy: 0.8698 - val_mse: 0.4741\n",
            "Epoch 259/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2425 - accuracy: 0.9647 - mse: 0.2425 - val_loss: 0.3710 - val_accuracy: 0.8777 - val_mse: 0.3710\n",
            "Epoch 260/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1946 - accuracy: 0.9676 - mse: 0.1946 - val_loss: 0.4764 - val_accuracy: 0.8935 - val_mse: 0.4764\n",
            "Epoch 261/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2126 - accuracy: 0.9662 - mse: 0.2126 - val_loss: 0.4328 - val_accuracy: 0.8974 - val_mse: 0.4328\n",
            "Epoch 262/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.2127 - accuracy: 0.9661 - mse: 0.2127 - val_loss: 0.3530 - val_accuracy: 0.8679 - val_mse: 0.3530\n",
            "Epoch 263/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2037 - accuracy: 0.9686 - mse: 0.2037 - val_loss: 0.4735 - val_accuracy: 0.8501 - val_mse: 0.4735\n",
            "Epoch 264/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2111 - accuracy: 0.9636 - mse: 0.2111 - val_loss: 0.5691 - val_accuracy: 0.8935 - val_mse: 0.5691\n",
            "Epoch 265/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2209 - accuracy: 0.9656 - mse: 0.2209 - val_loss: 0.7055 - val_accuracy: 0.8639 - val_mse: 0.7055\n",
            "Epoch 266/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2314 - accuracy: 0.9627 - mse: 0.2314 - val_loss: 0.4180 - val_accuracy: 0.9014 - val_mse: 0.4180\n",
            "Epoch 267/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2468 - accuracy: 0.9602 - mse: 0.2468 - val_loss: 0.5428 - val_accuracy: 0.8698 - val_mse: 0.5428\n",
            "Epoch 268/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2894 - accuracy: 0.9612 - mse: 0.2894 - val_loss: 0.4739 - val_accuracy: 0.8895 - val_mse: 0.4739\n",
            "Epoch 269/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2386 - accuracy: 0.9664 - mse: 0.2386 - val_loss: 0.4755 - val_accuracy: 0.8935 - val_mse: 0.4755\n",
            "Epoch 270/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2165 - accuracy: 0.9643 - mse: 0.2165 - val_loss: 0.3772 - val_accuracy: 0.9014 - val_mse: 0.3772\n",
            "Epoch 271/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2257 - accuracy: 0.9654 - mse: 0.2257 - val_loss: 0.4924 - val_accuracy: 0.8836 - val_mse: 0.4924\n",
            "Epoch 272/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2309 - accuracy: 0.9628 - mse: 0.2309 - val_loss: 1.5947 - val_accuracy: 0.8895 - val_mse: 1.5947\n",
            "Epoch 273/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.1980 - accuracy: 0.9624 - mse: 0.1980 - val_loss: 0.3285 - val_accuracy: 0.8876 - val_mse: 0.3285\n",
            "Epoch 274/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.1950 - accuracy: 0.9679 - mse: 0.1950 - val_loss: 0.2894 - val_accuracy: 0.8639 - val_mse: 0.2894\n",
            "Epoch 275/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1796 - accuracy: 0.9652 - mse: 0.1796 - val_loss: 0.7074 - val_accuracy: 0.8955 - val_mse: 0.7074\n",
            "Epoch 276/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1815 - accuracy: 0.9698 - mse: 0.1815 - val_loss: 0.4022 - val_accuracy: 0.8757 - val_mse: 0.4022\n",
            "Epoch 277/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1682 - accuracy: 0.9683 - mse: 0.1682 - val_loss: 0.4312 - val_accuracy: 0.8698 - val_mse: 0.4312\n",
            "Epoch 278/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2060 - accuracy: 0.9624 - mse: 0.2060 - val_loss: 0.4005 - val_accuracy: 0.8817 - val_mse: 0.4005\n",
            "Epoch 279/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1815 - accuracy: 0.9656 - mse: 0.1815 - val_loss: 0.4500 - val_accuracy: 0.8679 - val_mse: 0.4500\n",
            "Epoch 280/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1729 - accuracy: 0.9666 - mse: 0.1729 - val_loss: 0.4283 - val_accuracy: 0.8836 - val_mse: 0.4283\n",
            "Epoch 281/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1579 - accuracy: 0.9679 - mse: 0.1579 - val_loss: 0.7190 - val_accuracy: 0.8738 - val_mse: 0.7190\n",
            "Epoch 282/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2181 - accuracy: 0.9600 - mse: 0.2181 - val_loss: 0.4064 - val_accuracy: 0.9132 - val_mse: 0.4064\n",
            "Epoch 283/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1809 - accuracy: 0.9636 - mse: 0.1809 - val_loss: 0.3376 - val_accuracy: 0.8856 - val_mse: 0.3376\n",
            "Epoch 284/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1805 - accuracy: 0.9665 - mse: 0.1805 - val_loss: 0.3604 - val_accuracy: 0.8600 - val_mse: 0.3604\n",
            "Epoch 285/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2374 - accuracy: 0.9617 - mse: 0.2374 - val_loss: 0.4150 - val_accuracy: 0.8008 - val_mse: 0.4150\n",
            "Epoch 286/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2321 - accuracy: 0.9672 - mse: 0.2321 - val_loss: 0.5747 - val_accuracy: 0.8895 - val_mse: 0.5747\n",
            "Epoch 287/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1868 - accuracy: 0.9698 - mse: 0.1868 - val_loss: 0.6947 - val_accuracy: 0.8797 - val_mse: 0.6947\n",
            "Epoch 288/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1766 - accuracy: 0.9676 - mse: 0.1766 - val_loss: 0.3561 - val_accuracy: 0.8817 - val_mse: 0.3561\n",
            "Epoch 289/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2266 - accuracy: 0.9658 - mse: 0.2266 - val_loss: 0.6925 - val_accuracy: 0.8895 - val_mse: 0.6925\n",
            "Epoch 290/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2429 - accuracy: 0.9645 - mse: 0.2429 - val_loss: 0.4662 - val_accuracy: 0.8895 - val_mse: 0.4662\n",
            "Epoch 291/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1963 - accuracy: 0.9684 - mse: 0.1963 - val_loss: 0.4423 - val_accuracy: 0.8659 - val_mse: 0.4423\n",
            "Epoch 292/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1744 - accuracy: 0.9682 - mse: 0.1744 - val_loss: 0.3826 - val_accuracy: 0.8856 - val_mse: 0.3826\n",
            "Epoch 293/500\n",
            "97/97 [==============================] - 17s 173ms/step - loss: 0.1491 - accuracy: 0.9720 - mse: 0.1491 - val_loss: 0.4746 - val_accuracy: 0.9014 - val_mse: 0.4746\n",
            "Epoch 294/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2293 - accuracy: 0.9670 - mse: 0.2293 - val_loss: 0.4796 - val_accuracy: 0.8442 - val_mse: 0.4796\n",
            "Epoch 295/500\n",
            "97/97 [==============================] - 18s 189ms/step - loss: 0.1570 - accuracy: 0.9697 - mse: 0.1570 - val_loss: 0.2863 - val_accuracy: 0.9053 - val_mse: 0.2863\n",
            "Epoch 296/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1569 - accuracy: 0.9729 - mse: 0.1569 - val_loss: 0.4096 - val_accuracy: 0.8935 - val_mse: 0.4096\n",
            "Epoch 297/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2043 - accuracy: 0.9688 - mse: 0.2043 - val_loss: 0.3821 - val_accuracy: 0.8856 - val_mse: 0.3821\n",
            "Epoch 298/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1880 - accuracy: 0.9690 - mse: 0.1880 - val_loss: 0.2965 - val_accuracy: 0.8876 - val_mse: 0.2965\n",
            "Epoch 299/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1708 - accuracy: 0.9672 - mse: 0.1708 - val_loss: 0.3163 - val_accuracy: 0.9211 - val_mse: 0.3163\n",
            "Epoch 300/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1501 - accuracy: 0.9697 - mse: 0.1501 - val_loss: 0.3365 - val_accuracy: 0.9132 - val_mse: 0.3365\n",
            "Epoch 301/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1938 - accuracy: 0.9680 - mse: 0.1938 - val_loss: 0.3727 - val_accuracy: 0.8462 - val_mse: 0.3727\n",
            "Epoch 302/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1847 - accuracy: 0.9680 - mse: 0.1847 - val_loss: 0.5656 - val_accuracy: 0.8777 - val_mse: 0.5656\n",
            "Epoch 303/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1802 - accuracy: 0.9676 - mse: 0.1802 - val_loss: 0.5610 - val_accuracy: 0.8876 - val_mse: 0.5610\n",
            "Epoch 304/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2687 - accuracy: 0.9650 - mse: 0.2687 - val_loss: 0.5568 - val_accuracy: 0.8994 - val_mse: 0.5568\n",
            "Epoch 305/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1595 - accuracy: 0.9677 - mse: 0.1595 - val_loss: 0.4022 - val_accuracy: 0.8659 - val_mse: 0.4022\n",
            "Epoch 306/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1795 - accuracy: 0.9660 - mse: 0.1795 - val_loss: 0.9992 - val_accuracy: 0.8876 - val_mse: 0.9992\n",
            "Epoch 307/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1720 - accuracy: 0.9723 - mse: 0.1720 - val_loss: 0.4907 - val_accuracy: 0.9172 - val_mse: 0.4907\n",
            "Epoch 308/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1473 - accuracy: 0.9703 - mse: 0.1473 - val_loss: 0.4113 - val_accuracy: 0.8777 - val_mse: 0.4113\n",
            "Epoch 309/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1846 - accuracy: 0.9700 - mse: 0.1846 - val_loss: 0.4107 - val_accuracy: 0.8738 - val_mse: 0.4107\n",
            "Epoch 310/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1544 - accuracy: 0.9678 - mse: 0.1544 - val_loss: 0.7723 - val_accuracy: 0.8580 - val_mse: 0.7723\n",
            "Epoch 311/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1797 - accuracy: 0.9678 - mse: 0.1797 - val_loss: 0.5420 - val_accuracy: 0.9132 - val_mse: 0.5420\n",
            "Epoch 312/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.1671 - accuracy: 0.9690 - mse: 0.1671 - val_loss: 0.2800 - val_accuracy: 0.8777 - val_mse: 0.2800\n",
            "Epoch 313/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1498 - accuracy: 0.9676 - mse: 0.1498 - val_loss: 0.3998 - val_accuracy: 0.9112 - val_mse: 0.3998\n",
            "Epoch 314/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2387 - accuracy: 0.9650 - mse: 0.2387 - val_loss: 0.4222 - val_accuracy: 0.9152 - val_mse: 0.4222\n",
            "Epoch 315/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1851 - accuracy: 0.9693 - mse: 0.1851 - val_loss: 0.4850 - val_accuracy: 0.9034 - val_mse: 0.4850\n",
            "Epoch 316/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.1715 - accuracy: 0.9669 - mse: 0.1715 - val_loss: 0.2751 - val_accuracy: 0.9053 - val_mse: 0.2751\n",
            "Epoch 317/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1397 - accuracy: 0.9699 - mse: 0.1397 - val_loss: 0.5521 - val_accuracy: 0.8955 - val_mse: 0.5521\n",
            "Epoch 318/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1363 - accuracy: 0.9730 - mse: 0.1363 - val_loss: 0.4976 - val_accuracy: 0.8955 - val_mse: 0.4976\n",
            "Epoch 319/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1607 - accuracy: 0.9725 - mse: 0.1607 - val_loss: 0.2938 - val_accuracy: 0.8935 - val_mse: 0.2938\n",
            "Epoch 320/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1705 - accuracy: 0.9694 - mse: 0.1705 - val_loss: 0.3515 - val_accuracy: 0.8659 - val_mse: 0.3515\n",
            "Epoch 321/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.1427 - accuracy: 0.9711 - mse: 0.1427 - val_loss: 0.2648 - val_accuracy: 0.9053 - val_mse: 0.2648\n",
            "Epoch 322/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1431 - accuracy: 0.9741 - mse: 0.1431 - val_loss: 0.2847 - val_accuracy: 0.9053 - val_mse: 0.2847\n",
            "Epoch 323/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1677 - accuracy: 0.9696 - mse: 0.1677 - val_loss: 0.2899 - val_accuracy: 0.8994 - val_mse: 0.2899\n",
            "Epoch 324/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.1398 - accuracy: 0.9688 - mse: 0.1398 - val_loss: 0.2431 - val_accuracy: 0.9191 - val_mse: 0.2431\n",
            "Epoch 325/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1778 - accuracy: 0.9664 - mse: 0.1778 - val_loss: 0.3675 - val_accuracy: 0.8718 - val_mse: 0.3675\n",
            "Epoch 326/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1464 - accuracy: 0.9694 - mse: 0.1464 - val_loss: 0.6483 - val_accuracy: 0.9231 - val_mse: 0.6483\n",
            "Epoch 327/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1442 - accuracy: 0.9732 - mse: 0.1442 - val_loss: 0.9520 - val_accuracy: 0.8797 - val_mse: 0.9520\n",
            "Epoch 328/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2051 - accuracy: 0.9696 - mse: 0.2051 - val_loss: 0.3861 - val_accuracy: 0.8856 - val_mse: 0.3861\n",
            "Epoch 329/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1657 - accuracy: 0.9692 - mse: 0.1657 - val_loss: 0.2497 - val_accuracy: 0.9349 - val_mse: 0.2497\n",
            "Epoch 330/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1774 - accuracy: 0.9736 - mse: 0.1774 - val_loss: 0.4518 - val_accuracy: 0.8481 - val_mse: 0.4518\n",
            "Epoch 331/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1798 - accuracy: 0.9710 - mse: 0.1798 - val_loss: 0.2682 - val_accuracy: 0.8836 - val_mse: 0.2682\n",
            "Epoch 332/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1339 - accuracy: 0.9735 - mse: 0.1339 - val_loss: 0.5299 - val_accuracy: 0.9014 - val_mse: 0.5299\n",
            "Epoch 333/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2336 - accuracy: 0.9699 - mse: 0.2336 - val_loss: 0.4975 - val_accuracy: 0.8974 - val_mse: 0.4975\n",
            "Epoch 334/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1853 - accuracy: 0.9698 - mse: 0.1853 - val_loss: 0.3307 - val_accuracy: 0.8738 - val_mse: 0.3307\n",
            "Epoch 335/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1329 - accuracy: 0.9717 - mse: 0.1329 - val_loss: 0.4497 - val_accuracy: 0.9073 - val_mse: 0.4497\n",
            "Epoch 336/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1797 - accuracy: 0.9680 - mse: 0.1797 - val_loss: 0.3153 - val_accuracy: 0.8974 - val_mse: 0.3153\n",
            "Epoch 337/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1263 - accuracy: 0.9708 - mse: 0.1263 - val_loss: 0.2770 - val_accuracy: 0.8777 - val_mse: 0.2770\n",
            "Epoch 338/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1147 - accuracy: 0.9763 - mse: 0.1147 - val_loss: 0.3979 - val_accuracy: 0.8698 - val_mse: 0.3979\n",
            "Epoch 339/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1177 - accuracy: 0.9735 - mse: 0.1177 - val_loss: 0.2938 - val_accuracy: 0.8876 - val_mse: 0.2938\n",
            "Epoch 340/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1459 - accuracy: 0.9688 - mse: 0.1459 - val_loss: 0.5017 - val_accuracy: 0.8994 - val_mse: 0.5017\n",
            "Epoch 341/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1531 - accuracy: 0.9724 - mse: 0.1531 - val_loss: 0.3246 - val_accuracy: 0.8777 - val_mse: 0.3246\n",
            "Epoch 342/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1774 - accuracy: 0.9678 - mse: 0.1774 - val_loss: 0.2524 - val_accuracy: 0.8895 - val_mse: 0.2524\n",
            "Epoch 343/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1418 - accuracy: 0.9720 - mse: 0.1418 - val_loss: 0.3524 - val_accuracy: 0.9073 - val_mse: 0.3524\n",
            "Epoch 344/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1531 - accuracy: 0.9691 - mse: 0.1531 - val_loss: 0.3072 - val_accuracy: 0.9132 - val_mse: 0.3072\n",
            "Epoch 345/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1429 - accuracy: 0.9703 - mse: 0.1429 - val_loss: 0.3625 - val_accuracy: 0.8915 - val_mse: 0.3625\n",
            "Epoch 346/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1421 - accuracy: 0.9726 - mse: 0.1421 - val_loss: 0.6175 - val_accuracy: 0.8994 - val_mse: 0.6175\n",
            "Epoch 347/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1558 - accuracy: 0.9723 - mse: 0.1558 - val_loss: 0.4108 - val_accuracy: 0.8915 - val_mse: 0.4108\n",
            "Epoch 348/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1393 - accuracy: 0.9715 - mse: 0.1393 - val_loss: 0.4700 - val_accuracy: 0.8777 - val_mse: 0.4700\n",
            "Epoch 349/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1652 - accuracy: 0.9710 - mse: 0.1652 - val_loss: 0.2780 - val_accuracy: 0.9073 - val_mse: 0.2780\n",
            "Epoch 350/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.2603 - accuracy: 0.9641 - mse: 0.2603 - val_loss: 0.4374 - val_accuracy: 0.9191 - val_mse: 0.4374\n",
            "Epoch 351/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1360 - accuracy: 0.9713 - mse: 0.1360 - val_loss: 0.4908 - val_accuracy: 0.9073 - val_mse: 0.4908\n",
            "Epoch 352/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1281 - accuracy: 0.9706 - mse: 0.1281 - val_loss: 0.3134 - val_accuracy: 0.9172 - val_mse: 0.3134\n",
            "Epoch 353/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1404 - accuracy: 0.9770 - mse: 0.1404 - val_loss: 0.2869 - val_accuracy: 0.8974 - val_mse: 0.2869\n",
            "Epoch 354/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.1498 - accuracy: 0.9719 - mse: 0.1498 - val_loss: 0.2371 - val_accuracy: 0.9034 - val_mse: 0.2371\n",
            "Epoch 355/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1185 - accuracy: 0.9732 - mse: 0.1185 - val_loss: 0.3017 - val_accuracy: 0.9073 - val_mse: 0.3017\n",
            "Epoch 356/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1697 - accuracy: 0.9720 - mse: 0.1697 - val_loss: 0.3040 - val_accuracy: 0.9172 - val_mse: 0.3040\n",
            "Epoch 357/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1207 - accuracy: 0.9705 - mse: 0.1207 - val_loss: 0.2608 - val_accuracy: 0.8974 - val_mse: 0.2608\n",
            "Epoch 358/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1169 - accuracy: 0.9747 - mse: 0.1169 - val_loss: 0.2474 - val_accuracy: 0.9132 - val_mse: 0.2474\n",
            "Epoch 359/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0976 - accuracy: 0.9746 - mse: 0.0976 - val_loss: 0.3227 - val_accuracy: 0.8994 - val_mse: 0.3227\n",
            "Epoch 360/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1373 - accuracy: 0.9745 - mse: 0.1373 - val_loss: 0.2929 - val_accuracy: 0.8994 - val_mse: 0.2929\n",
            "Epoch 361/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1352 - accuracy: 0.9767 - mse: 0.1352 - val_loss: 0.3344 - val_accuracy: 0.8738 - val_mse: 0.3344\n",
            "Epoch 362/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1161 - accuracy: 0.9735 - mse: 0.1161 - val_loss: 0.2539 - val_accuracy: 0.9073 - val_mse: 0.2539\n",
            "Epoch 363/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1196 - accuracy: 0.9734 - mse: 0.1196 - val_loss: 0.2513 - val_accuracy: 0.8876 - val_mse: 0.2513\n",
            "Epoch 364/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1646 - accuracy: 0.9719 - mse: 0.1646 - val_loss: 0.3348 - val_accuracy: 0.8974 - val_mse: 0.3348\n",
            "Epoch 365/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1183 - accuracy: 0.9740 - mse: 0.1183 - val_loss: 0.3209 - val_accuracy: 0.8817 - val_mse: 0.3209\n",
            "Epoch 366/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1159 - accuracy: 0.9730 - mse: 0.1159 - val_loss: 0.2500 - val_accuracy: 0.9053 - val_mse: 0.2500\n",
            "Epoch 367/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1154 - accuracy: 0.9746 - mse: 0.1154 - val_loss: 0.2987 - val_accuracy: 0.9329 - val_mse: 0.2987\n",
            "Epoch 368/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1358 - accuracy: 0.9740 - mse: 0.1358 - val_loss: 0.3196 - val_accuracy: 0.8915 - val_mse: 0.3196\n",
            "Epoch 369/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1462 - accuracy: 0.9710 - mse: 0.1462 - val_loss: 0.3129 - val_accuracy: 0.8856 - val_mse: 0.3129\n",
            "Epoch 370/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1802 - accuracy: 0.9682 - mse: 0.1802 - val_loss: 0.4216 - val_accuracy: 0.9053 - val_mse: 0.4216\n",
            "Epoch 371/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1665 - accuracy: 0.9733 - mse: 0.1665 - val_loss: 0.8561 - val_accuracy: 0.8915 - val_mse: 0.8561\n",
            "Epoch 372/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1789 - accuracy: 0.9725 - mse: 0.1789 - val_loss: 0.8328 - val_accuracy: 0.8915 - val_mse: 0.8328\n",
            "Epoch 373/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1885 - accuracy: 0.9681 - mse: 0.1885 - val_loss: 0.2698 - val_accuracy: 0.9152 - val_mse: 0.2698\n",
            "Epoch 374/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1303 - accuracy: 0.9717 - mse: 0.1303 - val_loss: 0.2705 - val_accuracy: 0.8836 - val_mse: 0.2705\n",
            "Epoch 375/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.1086 - accuracy: 0.9749 - mse: 0.1086 - val_loss: 0.2198 - val_accuracy: 0.9093 - val_mse: 0.2198\n",
            "Epoch 376/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1096 - accuracy: 0.9737 - mse: 0.1096 - val_loss: 0.3571 - val_accuracy: 0.9053 - val_mse: 0.3571\n",
            "Epoch 377/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1323 - accuracy: 0.9756 - mse: 0.1323 - val_loss: 0.8557 - val_accuracy: 0.9231 - val_mse: 0.8557\n",
            "Epoch 378/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1614 - accuracy: 0.9717 - mse: 0.1614 - val_loss: 0.3728 - val_accuracy: 0.8580 - val_mse: 0.3728\n",
            "Epoch 379/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1455 - accuracy: 0.9762 - mse: 0.1455 - val_loss: 0.5045 - val_accuracy: 0.8679 - val_mse: 0.5045\n",
            "Epoch 380/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1310 - accuracy: 0.9732 - mse: 0.1310 - val_loss: 0.2262 - val_accuracy: 0.8895 - val_mse: 0.2262\n",
            "Epoch 381/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1173 - accuracy: 0.9741 - mse: 0.1173 - val_loss: 0.3066 - val_accuracy: 0.8856 - val_mse: 0.3066\n",
            "Epoch 382/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1385 - accuracy: 0.9740 - mse: 0.1385 - val_loss: 0.3459 - val_accuracy: 0.8895 - val_mse: 0.3459\n",
            "Epoch 383/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1248 - accuracy: 0.9753 - mse: 0.1248 - val_loss: 0.2979 - val_accuracy: 0.9053 - val_mse: 0.2979\n",
            "Epoch 384/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1185 - accuracy: 0.9728 - mse: 0.1185 - val_loss: 0.2617 - val_accuracy: 0.8974 - val_mse: 0.2617\n",
            "Epoch 385/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1226 - accuracy: 0.9705 - mse: 0.1226 - val_loss: 0.4594 - val_accuracy: 0.9073 - val_mse: 0.4594\n",
            "Epoch 386/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1197 - accuracy: 0.9757 - mse: 0.1197 - val_loss: 0.2201 - val_accuracy: 0.9073 - val_mse: 0.2201\n",
            "Epoch 387/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1673 - accuracy: 0.9718 - mse: 0.1673 - val_loss: 0.4830 - val_accuracy: 0.8955 - val_mse: 0.4830\n",
            "Epoch 388/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1528 - accuracy: 0.9704 - mse: 0.1528 - val_loss: 0.3182 - val_accuracy: 0.9053 - val_mse: 0.3182\n",
            "Epoch 389/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1209 - accuracy: 0.9768 - mse: 0.1209 - val_loss: 0.2624 - val_accuracy: 0.9270 - val_mse: 0.2624\n",
            "Epoch 390/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1086 - accuracy: 0.9747 - mse: 0.1086 - val_loss: 0.2314 - val_accuracy: 0.9132 - val_mse: 0.2314\n",
            "Epoch 391/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1041 - accuracy: 0.9742 - mse: 0.1041 - val_loss: 0.3335 - val_accuracy: 0.8777 - val_mse: 0.3335\n",
            "Epoch 392/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1598 - accuracy: 0.9685 - mse: 0.1598 - val_loss: 0.2734 - val_accuracy: 0.9034 - val_mse: 0.2734\n",
            "Epoch 393/500\n",
            "97/97 [==============================] - 18s 187ms/step - loss: 0.1373 - accuracy: 0.9732 - mse: 0.1373 - val_loss: 0.2193 - val_accuracy: 0.8876 - val_mse: 0.2193\n",
            "Epoch 394/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1481 - accuracy: 0.9732 - mse: 0.1481 - val_loss: 0.3480 - val_accuracy: 0.9172 - val_mse: 0.3480\n",
            "Epoch 395/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1081 - accuracy: 0.9769 - mse: 0.1081 - val_loss: 0.2499 - val_accuracy: 0.9093 - val_mse: 0.2499\n",
            "Epoch 396/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.1343 - accuracy: 0.9746 - mse: 0.1343 - val_loss: 0.2974 - val_accuracy: 0.9290 - val_mse: 0.2974\n",
            "Epoch 397/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1152 - accuracy: 0.9746 - mse: 0.1152 - val_loss: 0.3132 - val_accuracy: 0.9112 - val_mse: 0.3132\n",
            "Epoch 398/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1471 - accuracy: 0.9733 - mse: 0.1471 - val_loss: 0.5281 - val_accuracy: 0.9053 - val_mse: 0.5281\n",
            "Epoch 399/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1810 - accuracy: 0.9734 - mse: 0.1810 - val_loss: 0.5730 - val_accuracy: 0.9310 - val_mse: 0.5730\n",
            "Epoch 400/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1270 - accuracy: 0.9741 - mse: 0.1270 - val_loss: 0.2304 - val_accuracy: 0.9349 - val_mse: 0.2304\n",
            "Epoch 401/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.1078 - accuracy: 0.9758 - mse: 0.1078 - val_loss: 0.2163 - val_accuracy: 0.8757 - val_mse: 0.2163\n",
            "Epoch 402/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1387 - accuracy: 0.9757 - mse: 0.1387 - val_loss: 0.3678 - val_accuracy: 0.9191 - val_mse: 0.3678\n",
            "Epoch 403/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1307 - accuracy: 0.9753 - mse: 0.1307 - val_loss: 0.6625 - val_accuracy: 0.9112 - val_mse: 0.6625\n",
            "Epoch 404/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1438 - accuracy: 0.9755 - mse: 0.1438 - val_loss: 0.5083 - val_accuracy: 0.9073 - val_mse: 0.5083\n",
            "Epoch 405/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1513 - accuracy: 0.9741 - mse: 0.1513 - val_loss: 0.2602 - val_accuracy: 0.9073 - val_mse: 0.2602\n",
            "Epoch 406/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1031 - accuracy: 0.9771 - mse: 0.1031 - val_loss: 0.3125 - val_accuracy: 0.9112 - val_mse: 0.3125\n",
            "Epoch 407/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1524 - accuracy: 0.9769 - mse: 0.1524 - val_loss: 0.2485 - val_accuracy: 0.8915 - val_mse: 0.2485\n",
            "Epoch 408/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0929 - accuracy: 0.9780 - mse: 0.0929 - val_loss: 0.3350 - val_accuracy: 0.9034 - val_mse: 0.3350\n",
            "Epoch 409/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0932 - accuracy: 0.9786 - mse: 0.0932 - val_loss: 0.2883 - val_accuracy: 0.8955 - val_mse: 0.2883\n",
            "Epoch 410/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.1112 - accuracy: 0.9739 - mse: 0.1112 - val_loss: 0.2040 - val_accuracy: 0.8994 - val_mse: 0.2040\n",
            "Epoch 411/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0790 - accuracy: 0.9777 - mse: 0.0790 - val_loss: 0.2305 - val_accuracy: 0.9132 - val_mse: 0.2305\n",
            "Epoch 412/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1010 - accuracy: 0.9788 - mse: 0.1010 - val_loss: 0.4099 - val_accuracy: 0.9093 - val_mse: 0.4099\n",
            "Epoch 413/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1053 - accuracy: 0.9740 - mse: 0.1053 - val_loss: 0.2891 - val_accuracy: 0.8619 - val_mse: 0.2891\n",
            "Epoch 414/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1182 - accuracy: 0.9740 - mse: 0.1182 - val_loss: 0.2790 - val_accuracy: 0.9093 - val_mse: 0.2790\n",
            "Epoch 415/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1231 - accuracy: 0.9752 - mse: 0.1231 - val_loss: 0.3118 - val_accuracy: 0.9073 - val_mse: 0.3118\n",
            "Epoch 416/500\n",
            "97/97 [==============================] - 18s 188ms/step - loss: 0.0908 - accuracy: 0.9741 - mse: 0.0908 - val_loss: 0.1978 - val_accuracy: 0.9073 - val_mse: 0.1978\n",
            "Epoch 417/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.0838 - accuracy: 0.9771 - mse: 0.0838 - val_loss: 0.1964 - val_accuracy: 0.9014 - val_mse: 0.1964\n",
            "Epoch 418/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1193 - accuracy: 0.9777 - mse: 0.1193 - val_loss: 0.4819 - val_accuracy: 0.8974 - val_mse: 0.4819\n",
            "Epoch 419/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1343 - accuracy: 0.9728 - mse: 0.1343 - val_loss: 0.3358 - val_accuracy: 0.9270 - val_mse: 0.3358\n",
            "Epoch 420/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1229 - accuracy: 0.9771 - mse: 0.1229 - val_loss: 0.2754 - val_accuracy: 0.9053 - val_mse: 0.2754\n",
            "Epoch 421/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0892 - accuracy: 0.9768 - mse: 0.0892 - val_loss: 0.2628 - val_accuracy: 0.9191 - val_mse: 0.2628\n",
            "Epoch 422/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.1144 - accuracy: 0.9785 - mse: 0.1144 - val_loss: 0.1922 - val_accuracy: 0.9152 - val_mse: 0.1922\n",
            "Epoch 423/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1124 - accuracy: 0.9763 - mse: 0.1124 - val_loss: 0.2042 - val_accuracy: 0.8915 - val_mse: 0.2042\n",
            "Epoch 424/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1006 - accuracy: 0.9772 - mse: 0.1006 - val_loss: 0.4513 - val_accuracy: 0.9231 - val_mse: 0.4513\n",
            "Epoch 425/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1332 - accuracy: 0.9738 - mse: 0.1332 - val_loss: 0.1997 - val_accuracy: 0.9152 - val_mse: 0.1997\n",
            "Epoch 426/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1190 - accuracy: 0.9750 - mse: 0.1190 - val_loss: 0.4078 - val_accuracy: 0.8955 - val_mse: 0.4078\n",
            "Epoch 427/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1065 - accuracy: 0.9777 - mse: 0.1065 - val_loss: 0.2470 - val_accuracy: 0.9034 - val_mse: 0.2470\n",
            "Epoch 428/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0977 - accuracy: 0.9764 - mse: 0.0977 - val_loss: 0.2030 - val_accuracy: 0.8935 - val_mse: 0.2030\n",
            "Epoch 429/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0870 - accuracy: 0.9786 - mse: 0.0870 - val_loss: 0.3194 - val_accuracy: 0.9093 - val_mse: 0.3194\n",
            "Epoch 430/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1299 - accuracy: 0.9752 - mse: 0.1299 - val_loss: 0.4179 - val_accuracy: 0.8915 - val_mse: 0.4179\n",
            "Epoch 431/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1112 - accuracy: 0.9771 - mse: 0.1112 - val_loss: 0.2901 - val_accuracy: 0.9152 - val_mse: 0.2901\n",
            "Epoch 432/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1206 - accuracy: 0.9779 - mse: 0.1206 - val_loss: 0.3519 - val_accuracy: 0.9132 - val_mse: 0.3519\n",
            "Epoch 433/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1106 - accuracy: 0.9751 - mse: 0.1106 - val_loss: 0.2867 - val_accuracy: 0.9290 - val_mse: 0.2867\n",
            "Epoch 434/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1280 - accuracy: 0.9759 - mse: 0.1280 - val_loss: 0.3396 - val_accuracy: 0.9250 - val_mse: 0.3396\n",
            "Epoch 435/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0990 - accuracy: 0.9750 - mse: 0.0990 - val_loss: 0.2296 - val_accuracy: 0.8974 - val_mse: 0.2296\n",
            "Epoch 436/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0741 - accuracy: 0.9780 - mse: 0.0741 - val_loss: 0.2801 - val_accuracy: 0.9231 - val_mse: 0.2801\n",
            "Epoch 437/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1013 - accuracy: 0.9793 - mse: 0.1013 - val_loss: 0.2267 - val_accuracy: 0.9290 - val_mse: 0.2267\n",
            "Epoch 438/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0891 - accuracy: 0.9768 - mse: 0.0891 - val_loss: 0.2330 - val_accuracy: 0.9191 - val_mse: 0.2330\n",
            "Epoch 439/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0959 - accuracy: 0.9786 - mse: 0.0959 - val_loss: 0.3421 - val_accuracy: 0.9112 - val_mse: 0.3421\n",
            "Epoch 440/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0887 - accuracy: 0.9738 - mse: 0.0887 - val_loss: 0.2084 - val_accuracy: 0.8876 - val_mse: 0.2084\n",
            "Epoch 441/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1078 - accuracy: 0.9777 - mse: 0.1078 - val_loss: 0.2111 - val_accuracy: 0.8797 - val_mse: 0.2111\n",
            "Epoch 442/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.0922 - accuracy: 0.9780 - mse: 0.0922 - val_loss: 0.1864 - val_accuracy: 0.9034 - val_mse: 0.1864\n",
            "Epoch 443/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1211 - accuracy: 0.9776 - mse: 0.1211 - val_loss: 0.2545 - val_accuracy: 0.9191 - val_mse: 0.2545\n",
            "Epoch 444/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1120 - accuracy: 0.9761 - mse: 0.1120 - val_loss: 0.3991 - val_accuracy: 0.8757 - val_mse: 0.3991\n",
            "Epoch 445/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0817 - accuracy: 0.9760 - mse: 0.0817 - val_loss: 0.2330 - val_accuracy: 0.9112 - val_mse: 0.2330\n",
            "Epoch 446/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0896 - accuracy: 0.9755 - mse: 0.0896 - val_loss: 0.4131 - val_accuracy: 0.9310 - val_mse: 0.4131\n",
            "Epoch 447/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.1388 - accuracy: 0.9738 - mse: 0.1388 - val_loss: 0.2312 - val_accuracy: 0.8836 - val_mse: 0.2312\n",
            "Epoch 448/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1803 - accuracy: 0.9713 - mse: 0.1803 - val_loss: 0.2945 - val_accuracy: 0.8560 - val_mse: 0.2945\n",
            "Epoch 449/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1563 - accuracy: 0.9710 - mse: 0.1563 - val_loss: 0.2880 - val_accuracy: 0.9250 - val_mse: 0.2880\n",
            "Epoch 450/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.1101 - accuracy: 0.9759 - mse: 0.1101 - val_loss: 0.1910 - val_accuracy: 0.9093 - val_mse: 0.1910\n",
            "Epoch 451/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0924 - accuracy: 0.9793 - mse: 0.0924 - val_loss: 0.2196 - val_accuracy: 0.9329 - val_mse: 0.2196\n",
            "Epoch 452/500\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.0773 - accuracy: 0.9792 - mse: 0.0773 - val_loss: 0.1794 - val_accuracy: 0.8738 - val_mse: 0.1794\n",
            "Epoch 453/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0803 - accuracy: 0.9809 - mse: 0.0803 - val_loss: 0.2026 - val_accuracy: 0.9250 - val_mse: 0.2026\n",
            "Epoch 454/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1224 - accuracy: 0.9787 - mse: 0.1224 - val_loss: 0.4149 - val_accuracy: 0.9053 - val_mse: 0.4149\n",
            "Epoch 455/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1416 - accuracy: 0.9717 - mse: 0.1416 - val_loss: 0.2858 - val_accuracy: 0.8994 - val_mse: 0.2858\n",
            "Epoch 456/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0991 - accuracy: 0.9755 - mse: 0.0991 - val_loss: 0.4622 - val_accuracy: 0.8955 - val_mse: 0.4622\n",
            "Epoch 457/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1035 - accuracy: 0.9778 - mse: 0.1035 - val_loss: 0.2219 - val_accuracy: 0.8994 - val_mse: 0.2219\n",
            "Epoch 458/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0996 - accuracy: 0.9799 - mse: 0.0996 - val_loss: 0.2058 - val_accuracy: 0.9310 - val_mse: 0.2058\n",
            "Epoch 459/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0986 - accuracy: 0.9761 - mse: 0.0986 - val_loss: 0.4519 - val_accuracy: 0.9053 - val_mse: 0.4519\n",
            "Epoch 460/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.1233 - accuracy: 0.9762 - mse: 0.1233 - val_loss: 0.3903 - val_accuracy: 0.9034 - val_mse: 0.3903\n",
            "Epoch 461/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1179 - accuracy: 0.9765 - mse: 0.1179 - val_loss: 0.4558 - val_accuracy: 0.9053 - val_mse: 0.4558\n",
            "Epoch 462/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1095 - accuracy: 0.9756 - mse: 0.1095 - val_loss: 0.2162 - val_accuracy: 0.9172 - val_mse: 0.2162\n",
            "Epoch 463/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1062 - accuracy: 0.9784 - mse: 0.1062 - val_loss: 0.5440 - val_accuracy: 0.9073 - val_mse: 0.5440\n",
            "Epoch 464/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.1054 - accuracy: 0.9779 - mse: 0.1054 - val_loss: 0.3466 - val_accuracy: 0.9231 - val_mse: 0.3466\n",
            "Epoch 465/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1113 - accuracy: 0.9765 - mse: 0.1113 - val_loss: 0.2019 - val_accuracy: 0.8856 - val_mse: 0.2019\n",
            "Epoch 466/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1019 - accuracy: 0.9762 - mse: 0.1019 - val_loss: 0.2418 - val_accuracy: 0.8974 - val_mse: 0.2418\n",
            "Epoch 467/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0838 - accuracy: 0.9747 - mse: 0.0838 - val_loss: 0.3912 - val_accuracy: 0.9329 - val_mse: 0.3912\n",
            "Epoch 468/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1053 - accuracy: 0.9767 - mse: 0.1053 - val_loss: 0.4626 - val_accuracy: 0.9053 - val_mse: 0.4626\n",
            "Epoch 469/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1067 - accuracy: 0.9756 - mse: 0.1067 - val_loss: 0.2274 - val_accuracy: 0.9211 - val_mse: 0.2274\n",
            "Epoch 470/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0955 - accuracy: 0.9760 - mse: 0.0955 - val_loss: 0.2283 - val_accuracy: 0.9329 - val_mse: 0.2283\n",
            "Epoch 471/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1030 - accuracy: 0.9800 - mse: 0.1030 - val_loss: 0.2500 - val_accuracy: 0.9034 - val_mse: 0.2500\n",
            "Epoch 472/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0891 - accuracy: 0.9755 - mse: 0.0891 - val_loss: 0.2873 - val_accuracy: 0.9132 - val_mse: 0.2873\n",
            "Epoch 473/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0779 - accuracy: 0.9832 - mse: 0.0779 - val_loss: 0.2726 - val_accuracy: 0.9191 - val_mse: 0.2726\n",
            "Epoch 474/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0739 - accuracy: 0.9795 - mse: 0.0739 - val_loss: 0.1827 - val_accuracy: 0.8856 - val_mse: 0.1827\n",
            "Epoch 475/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1051 - accuracy: 0.9756 - mse: 0.1051 - val_loss: 0.1822 - val_accuracy: 0.9093 - val_mse: 0.1822\n",
            "Epoch 476/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0801 - accuracy: 0.9804 - mse: 0.0801 - val_loss: 0.5321 - val_accuracy: 0.9093 - val_mse: 0.5321\n",
            "Epoch 477/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1211 - accuracy: 0.9747 - mse: 0.1211 - val_loss: 0.2797 - val_accuracy: 0.8797 - val_mse: 0.2797\n",
            "Epoch 478/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0827 - accuracy: 0.9810 - mse: 0.0827 - val_loss: 0.1849 - val_accuracy: 0.9132 - val_mse: 0.1849\n",
            "Epoch 479/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0872 - accuracy: 0.9784 - mse: 0.0872 - val_loss: 0.2660 - val_accuracy: 0.9231 - val_mse: 0.2660\n",
            "Epoch 480/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1077 - accuracy: 0.9778 - mse: 0.1077 - val_loss: 0.2553 - val_accuracy: 0.9112 - val_mse: 0.2553\n",
            "Epoch 481/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1187 - accuracy: 0.9736 - mse: 0.1187 - val_loss: 0.2419 - val_accuracy: 0.9053 - val_mse: 0.2419\n",
            "Epoch 482/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1137 - accuracy: 0.9779 - mse: 0.1137 - val_loss: 0.2368 - val_accuracy: 0.9053 - val_mse: 0.2368\n",
            "Epoch 483/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1043 - accuracy: 0.9790 - mse: 0.1043 - val_loss: 0.2083 - val_accuracy: 0.8955 - val_mse: 0.2083\n",
            "Epoch 484/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0797 - accuracy: 0.9811 - mse: 0.0797 - val_loss: 0.2070 - val_accuracy: 0.9034 - val_mse: 0.2070\n",
            "Epoch 485/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0666 - accuracy: 0.9800 - mse: 0.0666 - val_loss: 0.2601 - val_accuracy: 0.9191 - val_mse: 0.2601\n",
            "Epoch 486/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0786 - accuracy: 0.9813 - mse: 0.0786 - val_loss: 0.2332 - val_accuracy: 0.9132 - val_mse: 0.2332\n",
            "Epoch 487/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0803 - accuracy: 0.9774 - mse: 0.0803 - val_loss: 0.4003 - val_accuracy: 0.9073 - val_mse: 0.4003\n",
            "Epoch 488/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1041 - accuracy: 0.9750 - mse: 0.1041 - val_loss: 0.4270 - val_accuracy: 0.8915 - val_mse: 0.4270\n",
            "Epoch 489/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0985 - accuracy: 0.9780 - mse: 0.0985 - val_loss: 0.2107 - val_accuracy: 0.9112 - val_mse: 0.2107\n",
            "Epoch 490/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0967 - accuracy: 0.9772 - mse: 0.0967 - val_loss: 0.2811 - val_accuracy: 0.8895 - val_mse: 0.2811\n",
            "Epoch 491/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0982 - accuracy: 0.9771 - mse: 0.0982 - val_loss: 0.2488 - val_accuracy: 0.9014 - val_mse: 0.2488\n",
            "Epoch 492/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0784 - accuracy: 0.9787 - mse: 0.0784 - val_loss: 0.1910 - val_accuracy: 0.9191 - val_mse: 0.1910\n",
            "Epoch 493/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0989 - accuracy: 0.9753 - mse: 0.0989 - val_loss: 0.2633 - val_accuracy: 0.8876 - val_mse: 0.2633\n",
            "Epoch 494/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0965 - accuracy: 0.9792 - mse: 0.0965 - val_loss: 0.2427 - val_accuracy: 0.9250 - val_mse: 0.2427\n",
            "Epoch 495/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1103 - accuracy: 0.9738 - mse: 0.1103 - val_loss: 0.2372 - val_accuracy: 0.9073 - val_mse: 0.2372\n",
            "Epoch 496/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0912 - accuracy: 0.9784 - mse: 0.0912 - val_loss: 0.2389 - val_accuracy: 0.9014 - val_mse: 0.2389\n",
            "Epoch 497/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1003 - accuracy: 0.9773 - mse: 0.1003 - val_loss: 0.1903 - val_accuracy: 0.9329 - val_mse: 0.1903\n",
            "Epoch 498/500\n",
            "97/97 [==============================] - 17s 171ms/step - loss: 0.0864 - accuracy: 0.9760 - mse: 0.0864 - val_loss: 0.3134 - val_accuracy: 0.9093 - val_mse: 0.3134\n",
            "Epoch 499/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.1013 - accuracy: 0.9802 - mse: 0.1013 - val_loss: 0.2254 - val_accuracy: 0.8876 - val_mse: 0.2254\n",
            "Epoch 500/500\n",
            "97/97 [==============================] - 17s 172ms/step - loss: 0.0777 - accuracy: 0.9764 - mse: 0.0777 - val_loss: 0.1840 - val_accuracy: 0.8935 - val_mse: 0.1840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Affine Transformations \n",
        "\n",
        "### Setting up Images & Landmarks "
      ],
      "metadata": {
        "id": "gKA6nBmKTXHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for using images without scaling them down\n",
        "def im_setup(img_path, width, height):\n",
        "    im = cv2.imread(img_path, -1)\n",
        "    (h, w) = im.shape[:2]\n",
        "    im = cv2.resize(im, (width,height), interpolation = cv2.INTER_AREA)\n",
        "    im_uint8 = ((im - np.min(im)) * (1/(np.max(im) - np.min(im)) * 255)).astype('uint8')\n",
        "    RGB_im = cv2.cvtColor(im_uint8, cv2.COLOR_BGR2RGBA)\n",
        "    return RGB_im\n",
        "\n",
        "#for using images without scaling them down\n",
        "def im_setup2(img_path, width, height):\n",
        "    im = cv2.imread(img_path, -1)\n",
        "    (h, w) = im.shape[:2]\n",
        "    im = cv2.resize(im, (width,height), interpolation = cv2.INTER_AREA)\n",
        "    im_uint8 = ((im - np.min(im)) * (1/(np.max(im) - np.min(im)) * 255)).astype('uint8')\n",
        "    gray_im = cv2.cvtColor(im_uint8, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_im"
      ],
      "metadata": {
        "id": "6eDlnHBWJtUS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createLandMarks(img_type, width,height):\n",
        "    #landmarks, to be hard set on certain filters\n",
        "    landmarks = []\n",
        "    mark_vals = []\n",
        "    if(img_type == 'nose'):\n",
        "        #nose \n",
        "        landmarks.append((width//2,height *.4))\n",
        "        \n",
        "        #left lip\n",
        "        landmarks.append((.25 * width,height* .7))\n",
        "        \n",
        "        #right lip \n",
        "        landmarks.append((width - .25 * width ,height* .7 ))\n",
        "        \n",
        "        mark_vals = [10,11,12]\n",
        "        #upper lip\n",
        "        #xs.append(width//2 )\n",
        "        #ys.append(height* .7 )\n",
        "    elif(img_type == 'glasses'):\n",
        "        #left brow\n",
        "        landmarks.append((width * .15 ,height * .25 ))\n",
        "        \n",
        "        #right brow\n",
        "        landmarks.append((width * .85 ,height * .25 ))\n",
        "        \n",
        "        #nose\n",
        "        landmarks.append((width * .5 ,height ))\n",
        "        \n",
        "        mark_vals = [7,9,10]\n",
        "    elif(img_type == 'eyes'):\n",
        "        #left brow\n",
        "        landmarks.append((width * .05 ,height *.2 ))\n",
        "        \n",
        "        #outer eye left\n",
        "        landmarks.append((width * .1 ,height *.63 ))\n",
        "        \n",
        "        #inner eye left\n",
        "        landmarks.append((width * .36 ,height *.63 ))\n",
        "        \n",
        "        #inner eye right\n",
        "        landmarks.append((width * .64 ,height *.63 ))\n",
        "        \n",
        "        #outer eye right \n",
        "        landmarks.append((width * .9 ,height *.63 ))\n",
        "        \n",
        "        #right brow\n",
        "        landmarks.append((width * .95 ,height *.2 ))\n",
        "    \n",
        "        mark_vals = [7,3,0,1,5,9]\n",
        "    elif(img_type == 'mouth'):\n",
        "        \n",
        "        #left lip\n",
        "        landmarks.append((width * .05 ,height *.35 ))\n",
        "        \n",
        "        #nose\n",
        "        landmarks.append((width * .5 ,height *.02 ))\n",
        "        \n",
        "        #lower lip\n",
        "        landmarks.append((width * .5 ,height *.67 ))\n",
        "        \n",
        "        #right lip\n",
        "        landmarks.append((width * .95 ,height *.35 ))\n",
        "        \n",
        "        mark_vals = [11,10,14,12]\n",
        "        \n",
        "    elif(img_type == 'mhat'):\n",
        "        \n",
        "        #left brow\n",
        "        landmarks.append((width * .2 ,height *.75 ))\n",
        "        \n",
        "        #nose\n",
        "        landmarks.append((width * .5 ,height ))\n",
        "        \n",
        "        #right brow\n",
        "        landmarks.append((width * .8 ,height *.75))\n",
        "        \n",
        "        mark_vals = [7,10,9]\n",
        "        \n",
        "    elif(img_type == 'beard'):\n",
        "        \n",
        "        #left outer lip\n",
        "        landmarks.append((width * .35 ,height *.44 ))\n",
        "        \n",
        "        #nose\n",
        "        landmarks.append((width * .49 ,height *.27 ))\n",
        "        \n",
        "        #lower lip\n",
        "        landmarks.append((width * .49 ,height *.5 ))\n",
        "        \n",
        "        #right outer lip\n",
        "        landmarks.append((width * .65 ,height *.44))\n",
        "        \n",
        "        mark_vals = [11,10,14,12]\n",
        "        \n",
        "    elif(img_type == 'blush'):\n",
        "        \n",
        "        #left brow\n",
        "        landmarks.append((width * .05 ,height *.0 ))\n",
        "        \n",
        "        #nose\n",
        "        landmarks.append((width * .5 ,height *.67))\n",
        "        \n",
        "        #right brow\n",
        "        landmarks.append((width * .95 ,height *.0))\n",
        "        \n",
        "        mark_vals = [7,10,9]\n",
        "    \n",
        "    elif(img_type == 'squid'):\n",
        "        \n",
        "        #left inner eye\n",
        "        landmarks.append((width * .3 ,height *.4 ))\n",
        "        \n",
        "        #nose\n",
        "        landmarks.append((width * .5 ,height *.95))\n",
        "        \n",
        "        #right inner eye\n",
        "        landmarks.append((width * .7 ,height *.4))\n",
        "        \n",
        "        mark_vals = [2,13,4]\n",
        "        \n",
        "    elif(img_type == 'clown'):\n",
        "        \n",
        "        #left inner eye\n",
        "        landmarks.append((width * .25 ,height *0 ))\n",
        "        \n",
        "        #nose\n",
        "        landmarks.append((width * .55 ,height *.5))\n",
        "        \n",
        "        #right inner eye\n",
        "        landmarks.append((width * .85 ,height * 0))\n",
        "        \n",
        "        mark_vals = [2,10,4]\n",
        "        \n",
        "        \n",
        "    return landmarks,mark_vals"
      ],
      "metadata": {
        "id": "nSs5Fi3iTsvZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_img = im_setup('./CV_Snap_Filter/Filter_Images/clown_nose.png', 96,96)\n",
        "lm,mv = createLandMarks('clown',96,96)\n",
        "xs =[]\n",
        "ys = []\n",
        "\n",
        "for val in lm:\n",
        "    xs.append(val[0])\n",
        "    ys.append(val[1])\n",
        "    \n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.scatter(xs, ys, marker='x', color='red')\n",
        "plt.imshow(filter_img)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "qN6JwUhzT3HI",
        "outputId": "0a62b0a5-984c-4b90-908d-a7c4416748d7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Our Own Affine Transformations Function and Trying it Out"
      ],
      "metadata": {
        "id": "KCnnG_fzT5w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#take in two sets of 3 points and figure out the affine matrix\n",
        "class InvalidArraySizes(Exception):\n",
        "    pass\n",
        "def affine_transform_mat(sor,dest):\n",
        "    #errors that could be defined \n",
        "    outMat = [[0,0,0],[0,0,0]]\n",
        "    b = []\n",
        "    A = []\n",
        "    try:\n",
        "        if(len(sor) != len(dest)): #c1 and c2 must have the same amount of points\n",
        "            raise InvalidArraySizes('There must be the same amount of points in both arrays')\n",
        "        if(len(sor) < 3):\n",
        "            raise InvalidArraySizes('source array must have a size of 3 or more')\n",
        "        if(len(dest) < 3):\n",
        "            raise InvalidArraySizes('destination array must have a size of 3 or more')\n",
        "    except InvalidArraySizes as e: \n",
        "        print(\"Error\",e)\n",
        "        return 0\n",
        "    #setup matricies for Least Squares Error\n",
        "    for i in range(0, len(sor)):\n",
        "        #set up b\n",
        "        b.append([dest[i][0]])\n",
        "        b.append([dest[i][1]])\n",
        "        \n",
        "        #we can assume sor and dest have the same number of points, so set up A here as well\n",
        "        #format: [xi,yi,1,0,0,0], [0,0,0,xi,yi,1]\n",
        "        A.append([sor[i][0],sor[i][1],1,0,0,0])\n",
        "        A.append([0,0,0,sor[i][0],sor[i][1],1])\n",
        "    b_np = np.array(b)\n",
        "    A_np = np.array(A)\n",
        "    #Least Likely Square Equation\n",
        "    #Equation: affine vars = (A^t * A)^-1 * A^t  * B\n",
        "    \n",
        "    A_trans = np.transpose(A_np)\n",
        "    inter = np.matmul(A_trans,A_np)\n",
        "    inverse = np.linalg.inv(inter)\n",
        "    final = np.matmul(np.matmul(inverse,A_trans),b_np).reshape(2,3)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return final"
      ],
      "metadata": {
        "id": "aci2mBXRT4tf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting Affine Transformation & Overlay Together"
      ],
      "metadata": {
        "id": "AxZLAITUUHZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#A function that takes in original image, the facial landmarks of the original image,\n",
        "#and the type of filter to create a new image with the filters overlaying the landmarks\n",
        "\n",
        "#FORMAT OF FUNCTION: INPUT: face_image converted to RGBA format, \n",
        "#landmarks in an array with x,y tuples ex: [(x1,y1),(x2,y2)...(xn,yn)]\n",
        "#filter type is an int ranging from 0-4\n",
        "def SCFilterOverlay(face_img, face_lm, filter_type):\n",
        "    #variables \n",
        "    filter_lm = []\n",
        "    filter_img = []\n",
        "    \n",
        "    face_lm_ind = []\n",
        "    important_face_lm = []\n",
        "    \n",
        "    face_width, face_height = face_img.shape[:2]\n",
        "    filter_width,filter_height = 0,0\n",
        "    \n",
        "    final_img = face_img.copy()\n",
        "    \n",
        "    \n",
        "    if(filter_type == 0): #nose\n",
        "        filter_img = im_setup('./CV_Snap_Filter/Filter_Images/Luigi_Stache.png', face_width,face_height)\n",
        "        filter_width,filter_height = filter_img.shape[:2]\n",
        "        filter_lm,face_lm_ind = createLandMarks('nose',filter_width, filter_height)\n",
        "    \n",
        "    elif(filter_type == 1): #glasses\n",
        "        filter_img = im_setup('./CV_Snap_Filter/Filter_Images/HP_Glasses.png', face_width,face_height)\n",
        "        filter_width,filter_height = filter_img.shape[:2]\n",
        "        filter_lm,face_lm_ind = createLandMarks('glasses',filter_width, filter_height)\n",
        "    \n",
        "    elif(filter_type == 2): #eyes\n",
        "        filter_img = im_setup('./CV_Snap_Filter/Filter_Images/Eyes.png', face_width,face_height)\n",
        "        filter_width,filter_height = filter_img.shape[:2]\n",
        "        filter_lm,face_lm_ind = createLandMarks('eyes',filter_width, filter_height)\n",
        "    \n",
        "    elif(filter_type == 3): #mouth\n",
        "        filter_img = im_setup('./CV_Snap_Filter/Filter_Images/Binky.png', face_width,face_height)\n",
        "        filter_width,filter_height = filter_img.shape[:2]\n",
        "        filter_lm,face_lm_ind = createLandMarks('mouth',filter_width, filter_height)\n",
        "    \n",
        "    elif(filter_type == 4): #hat\n",
        "        filter_img = im_setup('./CV_Snap_Filter/Filter_Images/Mario_Hat.png', face_width,face_height)\n",
        "        filter_width,filter_height = filter_img.shape[:2]\n",
        "        filter_lm,face_lm_ind = createLandMarks('mhat',filter_width, filter_height)\n",
        "        \n",
        "    elif(filter_type == 5): #beard\n",
        "        filter_img = im_setup('./CV_Snap_Filter/Filter_Images/beard.png', face_width,face_height)\n",
        "        filter_width,filter_height = filter_img.shape[:2]\n",
        "        filter_lm,face_lm_ind = createLandMarks('beard',filter_width, filter_height)\n",
        "        \n",
        "    elif(filter_type == 6): #blush\n",
        "        filter_img = im_setup('./CV_Snap_Filter/Filter_Images/blush.png', face_width,face_height)\n",
        "        filter_width,filter_height = filter_img.shape[:2]\n",
        "        filter_lm,face_lm_ind = createLandMarks('blush',filter_width, filter_height)\n",
        "    \n",
        "    elif(filter_type == 7): #squid\n",
        "        filter_img = im_setup('./CV_Snap_Filter/Filter_Images/squidward_nose.png', face_width,face_height)\n",
        "        filter_width,filter_height = filter_img.shape[:2]\n",
        "        filter_lm,face_lm_ind = createLandMarks('squid',filter_width, filter_height)\n",
        "        \n",
        "    elif(filter_type == 8): #clown\n",
        "        filter_img = im_setup('./CV_Snap_Filter/Filter_Images/clown_nose.png', face_width,face_height)\n",
        "        filter_width,filter_height = filter_img.shape[:2]\n",
        "        filter_lm,face_lm_ind = createLandMarks('clown',filter_width, filter_height)\n",
        "        \n",
        "    #fill in important face landmarks array using array\n",
        "    \n",
        "    for ind in face_lm_ind:\n",
        "        important_face_lm.append( (face_lm[ind][0],face_lm[ind][1]) ) \n",
        "    \n",
        "    #find affine transformation of two landmarks\n",
        "    trans_mat = affine_transform_mat(filter_lm,important_face_lm)\n",
        "    \n",
        "    #warp filter image\n",
        "    new_filt_img = cv2.warpAffine(filter_img, trans_mat, (face_width,face_height))\n",
        "    \n",
        "    #overlay image\n",
        "    # normalize alpha channels\n",
        "    background = final_img[:,:,3] / 255.0\n",
        "    foreground = new_filt_img[:,:,3] / 255.0\n",
        "        \n",
        "    # set adjusted colors\n",
        "    for color in range(0, 3):\n",
        "        final_img[:,:,color] = foreground * new_filt_img[:,:,color] + \\\n",
        "        background * final_img[:,:,color] * (1 - foreground)\n",
        "    # set adjusted alpha and denormalize back to 0-255\n",
        "    final_img[:,:,3] = (1 - (1 - foreground) * (1 - background)) * 255\n",
        "        \n",
        "    \n",
        "    return final_img"
      ],
      "metadata": {
        "id": "JSFBPCcEUGil"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing out SCFilterOverlay() Function\n",
        "\n",
        "# Show Filter on Image\n"
      ],
      "metadata": {
        "id": "mB9U8UahUPZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(image, model_path='./Best_weights.hdf5'):\n",
        "  img = im_setup2(image, 96, 96)\n",
        "  test_new = img.reshape(-1, 96, 96, 1)\n",
        "\n",
        "  model_best = tf.keras.models.load_model(model_path)\n",
        "  test_pred = model_best.predict(test_new)\n",
        "\n",
        "  return test_new, test_pred"
      ],
      "metadata": {
        "id": "wjbNF2ZNUO0k"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, pred = get_predictions('tom_holland.jpeg')\n",
        "plt.figure(figsize=(7,7))\n",
        "\n",
        "plt.imshow(img[0].reshape(96,96),cmap='gray')\n",
        "xs = pred[0][0::2]\n",
        "ys = pred[0][1::2]\n",
        "plt.scatter(xs, ys, marker='x', color='blue')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "OI9Jo61q38Jo",
        "outputId": "9ca48334-4209-41a9-de1f-1fcaecc9075d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oMoDpIvQ4gX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}